// Targeted by JavaCPP version 1.5.3-SNAPSHOT: DO NOT EDIT THIS FILE

package org.bytedeco.cudf.global;

import org.bytedeco.cudf.*;

import java.nio.*;
import org.bytedeco.javacpp.*;
import org.bytedeco.javacpp.annotation.*;

public class cudf extends org.bytedeco.cudf.presets.cudf {
    static { Loader.load(); }

// Targeting ../MapStringString.java


// Targeting ../PairOfRmmDeviceVectorCharRmmDeviceVectorSizeType.java


// Targeting ../PairOfCharUtf8CharUtf8.java


// Targeting ../PairOfUniquePtrRmmDeviceBufferCudfSizeType.java


// Parsed from <cudf/types.h>

// #pragma once

// #include <stdint.h>

// TODO: Update to use fixed width types when CFFI goes away
/** Limits the maximum size of a gdf_column to 2^31-1 */     /*< Storage type for Boolean values. 
                                        char is used to guarantee 8-bit storage. 
                                        zero == false, nonzero == true. */


 /**
 * \brief  These enums indicate the possible data types for a gdf_column
 */
/** enum gdf_dtype */
public static final int
    GDF_invalid = 0,
    GDF_INT8 = 1,
    GDF_INT16 = 2,
    GDF_INT32 = 3,
    GDF_INT64 = 4,
    GDF_FLOAT32 = 5,
    GDF_FLOAT64 = 6,
    /** Boolean stored in 8 bits per Boolean. zero==false, nonzero==true. */
    GDF_BOOL8 = 7,
    /** int32_t days since the UNIX epoch */
    GDF_DATE32 = 8,
    /** int64_t milliseconds since the UNIX epoch */
    GDF_DATE64 = 9,
    /** Exact timestamp encoded with int64 since UNIX epoch (Default unit millisecond) */
    GDF_TIMESTAMP = 10,
    GDF_CATEGORY = 11,
    GDF_STRING = 12,
    /** Stores indices of an NVCategory in data and in extra col info a reference to the nv_category */
    GDF_STRING_CATEGORY = 13,
    /** additional types should go BEFORE N_GDF_TYPES */
    N_GDF_TYPES = 14;


/**
 * \brief  These are all possible gdf error codes that can be returned from
 * a libgdf function. ANY NEW ERROR CODE MUST ALSO BE ADDED TO {@code gdf_error_get_name}
 * AS WELL
 */
/** enum gdf_error */
public static final int
    GDF_SUCCESS = 0,                
    /** Error occured in a CUDA call */
    GDF_CUDA_ERROR = 1,
    /** The datatype of the gdf_column is unsupported */
    GDF_UNSUPPORTED_DTYPE = 2,
    /** Two columns that should be the same size aren't the same size */
    GDF_COLUMN_SIZE_MISMATCH = 3,
    /** Size of column is larger than the max supported size */
    GDF_COLUMN_SIZE_TOO_BIG = 4,
    /** Input dataset is either null or has size 0 when it shouldn't */
    GDF_DATASET_EMPTY = 5,
    /** gdf_column's validity bitmask is null */
    GDF_VALIDITY_MISSING = 6,
    /** The requested gdf operation does not support validity bitmask handling, and one of the input columns has the valid bits enabled */
    GDF_VALIDITY_UNSUPPORTED = 7,
    /** The arguments passed into the function were invalid */
    GDF_INVALID_API_CALL = 8,
    /** Datatype mismatch between corresponding columns in  left/right tables in the Join function */
    GDF_JOIN_DTYPE_MISMATCH = 9,
    /** Too many columns were passed in for the requested join operation */
    GDF_JOIN_TOO_MANY_COLUMNS = 10,
    /** Type mismatch between columns that should be the same type */
    GDF_DTYPE_MISMATCH = 11,
    /** The method requested to perform an operation was invalid or unsupported (e.g., hash vs. sort) */
    GDF_UNSUPPORTED_METHOD = 12,
    /** Invalid aggregator was specified for a groupby */
    GDF_INVALID_AGGREGATOR = 13,
    /** Invalid hash function was selected */
    GDF_INVALID_HASH_FUNCTION = 14,
    /** Datatype mismatch between columns of input/output in the hash partition function */
    GDF_PARTITION_DTYPE_MISMATCH = 15,
    /** Failed to insert to hash table, likely because its full */
    GDF_HASH_TABLE_INSERT_FAILURE = 16,
    /** The type of join requested is unsupported */
    GDF_UNSUPPORTED_JOIN_TYPE = 17,
    /** C error not related to CUDA */
    GDF_C_ERROR = 18,
    /** error processing sepcified file */
    GDF_FILE_ERROR = 19,
    /** Memory manager error (see memory.h) */
    GDF_MEMORYMANAGER_ERROR = 20,
    /** The requested color used to define an NVTX range is not defined */
    GDF_UNDEFINED_NVTX_COLOR = 21,
    /** The requested name for an NVTX range cannot be nullptr */
    GDF_NULL_NVTX_NAME = 22,
    /** Resolution mismatch between two columns of GDF_TIMESTAMP */
    GDF_TIMESTAMP_RESOLUTION_MISMATCH = 23,
    /** A feature is not implemented */
    GDF_NOTIMPLEMENTED_ERROR = 24,
    /** Two tables that should have the same number of columns have different numbers of columns */
    GDF_TABLES_SIZE_MISMATCH = 25,
    N_GDF_ERRORS = 26;

/** enum gdf_hash_func */
public static final int
    /** Murmur3 hash function */
    GDF_HASH_MURMUR3 = 0,
    /** Identity hash function that simply returns the key to be hashed */
    GDF_HASH_IDENTITY = 1;


/**
 * \brief Defines the unit of time that an algoithm or structure is storing.
 *
 * There are time types in cudf. Those time types can have different resolutions.
 * The types included are nanosecond, microsecond, millisecond, and second.
 */
/** enum gdf_time_unit */
public static final int
  /** The default time unit type. */
  TIME_UNIT_NONE = 0,
  /** Second resolution time unit type */
  TIME_UNIT_s = 1,
  /** Millisecond resolution time unit type */
  TIME_UNIT_ms = 2,
  /** Microsecond resolution time unit type */
  TIME_UNIT_us = 3,
  /** Nanosecond resolution time unit type */
  TIME_UNIT_ns = 4;
// Targeting ../gdf_dtype_extra_info.java


// Targeting ../gdf_data.java


// Targeting ../gdf_scalar.java


// Targeting ../gdf_column.java




/** 
 * \brief  These enums indicate which method is to be used for an operation.
 * For example, it is used to select between the hash-based vs. sort-based implementations
 * of the Join operation.
 */
/** enum gdf_method */
public static final int
  /** Window Variance Indicates that the sort-based implementation of the function will be used */
  GDF_SORT = 0,
  /** Window Variance Indicates that the hash-based implementation of the function will be used */
  GDF_HASH = 1,
  /** Window Variance additional methods should go BEFORE N_GDF_METHODS */
  N_GDF_METHODS = 2;


/** 
 * \brief These enums indicate the supported aggregation operations that can be
 * performed on a set of aggregation columns as part of a GroupBy operation
 */
/** enum gdf_agg_op */
public static final int
  /** Computes the sum of all values in the aggregation column */
  GDF_SUM = 0,
  /** Computes minimum value in the aggregation column */
  GDF_MIN = 1,
  /** Computes maximum value in the aggregation column */
  GDF_MAX = 2,
  /** Computes arithmetic mean of all values in the aggregation column */
  GDF_AVG = 3,
  /** Computes histogram of the occurance of each key in the GroupBy Columns */
  GDF_COUNT = 4,
  /** Counts the number of distinct keys in the GroupBy columns */
  GDF_COUNT_DISTINCT = 5,
  /** Perform a generic aggregation operation detailed in a PTX code generated by {@code numba} */
  GDF_NUMBA_GENERIC_AGG_OPS = 6,
  /** Perform a generic aggregation operation detailed in a CUDA code */
  GDF_CUDA_GENERIC_AGG_OPS = 7,
  /** The total number of aggregation operations. ALL NEW OPERATIONS SHOULD BE ADDED ABOVE THIS LINE */
  N_GDF_AGG_OPS = 8;


/** 
 * \brief  Colors for use with NVTX ranges.
 *
 * These enumerations are the available pre-defined colors for use with
 * user-defined NVTX ranges.
 */
/** enum gdf_color */
public static final int
  GDF_GREEN = 0, 
  GDF_BLUE = 1,
  GDF_YELLOW = 2,
  GDF_PURPLE = 3,
  GDF_CYAN = 4,
  GDF_RED = 5,
  GDF_WHITE = 6,
  GDF_DARK_GREEN = 7,
  GDF_ORANGE = 8,
  /** Add new colors above this line */
  GDF_NUM_COLORS = 9;


/**
 * \brief Options for how nulls are treated in group_by/order_by operations.
 */
/** enum gdf_null_sort_behavior */
public static final int
  /** NULLS are treated as the largest number in comparisons */
  GDF_NULL_AS_LARGEST = 0,
  /** NULLS are treated as the smallest number in comparisons   */
  GDF_NULL_AS_SMALLEST = 1;
// Targeting ../gdf_context.java


// Targeting ../_OpaqueSegmentedRadixsortPlan.java


// Targeting ../gdf_segmented_radixsort_plan_type.java



/** enum order_by_type */
public static final int
  GDF_ORDER_ASC = 0,
  GDF_ORDER_DESC = 1;


// Parsed from <cudf/wrappers/timestamps.hpp>

/*
 * Copyright (c) 2019, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

// #pragma once

// #include <limits>

// #define _LIBCUDACXX_USE_CXX20_CHRONO
// #define _LIBCUDACXX_USE_CXX17_TYPE_TRAITS

// #include <simt/chrono>

/**---------------------------------------------------------------------------*
 * \file timestamps.hpp
 * \brief Concrete type definitions for int32_t and int64_t timestamps in
 * varying resolutions as durations since the UNIX epoch.
 *---------------------------------------------------------------------------**/

// TODO: Use chrono::utc_clock when available in libcu++?
  // namespace detail

/**---------------------------------------------------------------------------*
 * \brief Type alias representing an int32_t duration of days since the unix
 * epoch.
 *---------------------------------------------------------------------------**/
/**---------------------------------------------------------------------------*
 * \brief Type alias representing an int64_t duration of seconds since the
 * unix epoch.
 *---------------------------------------------------------------------------**/
/**---------------------------------------------------------------------------*
 * \brief Type alias representing an int64_t duration of milliseconds since
 * the unix epoch.
 *---------------------------------------------------------------------------**/
/**---------------------------------------------------------------------------*
 * \brief Type alias representing an int64_t duration of microseconds since
 * the unix epoch.
 *---------------------------------------------------------------------------**/
/**---------------------------------------------------------------------------*
 * \brief Type alias representing an int64_t duration of nanoseconds since
 * the unix epoch.
 *---------------------------------------------------------------------------**/

  // namespace cudf
/**---------------------------------------------------------------------------*
 * \brief Specialization of std::numeric_limits for cudf::detail::timestamp
 *
 * Pass through to return the limits of the underlying numeric representation.
 *--------------------------------------------------------------------------**/
// #define TIMESTAMP_LIMITS(TypeName)
//   template <>
//   struct numeric_limits<TypeName> {
//     static constexpr TypeName max() noexcept {
//       return std::numeric_limits<typename TypeName::rep>::max();
//     }
//     static constexpr TypeName lowest() noexcept {
//       return std::numeric_limits<typename TypeName::rep>::lowest();
//     }
//     static constexpr TypeName min() noexcept {
//       return std::numeric_limits<typename TypeName::rep>::min();
//     }
//   }
// Targeting ../std::numeric_limits<cudf::timestamp_D>.java



// #undef TIMESTAMP_LIMITS

  // namespace std


// Parsed from <cudf/replace.hpp>

/*
 * Copyright (c) 2018-2020, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

// #pragma once

// #include <cudf/types.hpp>
// #include <memory>
  /**
   * \brief Replaces all null values in a column with corresponding values of another column
   *
   * If {@code input[i]} is NULL, then {@code output[i]} will contain {@code replacement[i]}. 
   * {@code input} and {@code replacement} must be of the same type and size.
   * must be of the same type and same size as the first.
   *
   * @param input [in] A column whose null values will be replaced
   * @param replacement [in] A cudf::column whose values will replace null values in input
   * @param mr [in] Optional device_memory_resource to use for allocations.
   *
   * @return A copy of {@code input} with the null values replaced with corresponding values from {@code replacement}.
   */
@Namespace("cudf::experimental") public static native @UniquePtr column replace_nulls(@Const @ByRef column_view input,
                                      @Const @ByRef column_view replacement,
                                      device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::experimental") public static native @UniquePtr column replace_nulls(@Const @ByRef column_view input,
                                      @Const @ByRef column_view replacement);

/**
  * \brief Replaces all null values in a column with a scalar.
  *
  * If {@code input[i]} is NULL, then {@code output[i]} will contain {@code replacement}.
  * {@code input} and {@code replacement} must have the same type.
  * a cudf::scalar of the same data type as the column.
  *
  *
  * @param input [in] A column whose null values will be replaced
  * @param replacement [in] Scalar used to replace null values in {@code input}.
  * @param mr [in] Optional device_memory_resource to use for allocations.
  *
  * @return Copy of {@code input} with null values replaced by {@code replacement}.
  */
@Namespace("cudf::experimental") public static native @UniquePtr column replace_nulls(@Const @ByRef column_view input,
                                      @Const @ByRef scalar replacement,
                                      device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::experimental") public static native @UniquePtr column replace_nulls(@Const @ByRef column_view input,
                                      @Const @ByRef scalar replacement);


/**
 * \brief Replace elements from {@code input_col} according to the mapping {@code old_values} to
 *  \brief Return a copy of {@code input_col} replacing all {@code old_values[i]} present with {@code new_values[i]}.
 *
 * @param input_col The column to find and replace values in.
 * @param values_to_replace The values to replace
 * @param replacement_values The values to replace with
 * @param mr Optional device_memory_resource to use for allocations.
 *
 * @return Copy of {@code input} with specified values replaced.
 */
@Namespace("cudf::experimental") public static native @UniquePtr column find_and_replace_all(@Const @ByRef column_view input_col,
                                             @Const @ByRef column_view values_to_replace,
                                             @Const @ByRef column_view replacement_values,
                                             device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::experimental") public static native @UniquePtr column find_and_replace_all(@Const @ByRef column_view input_col,
                                             @Const @ByRef column_view values_to_replace,
                                             @Const @ByRef column_view replacement_values);

/**
 * \brief Replaces values less than {@code lo} in {@code input} with {@code lo_replace},
 * and values greater than {@code hi} with {@code hi_replace}.
 *
 * if {@code lo} is invalid, then lo will not be considered while
 * evaluating the input (Essentially considered minimum value of that type).
 * if {@code hi} is invalid, then hi will not be considered while
 * evaluating the input (Essentially considered maximum value of that type).
 *
 * \note: If {@code lo} is valid then {@code lo_replace} should be valid
 *        If {@code hi} is valid then {@code hi_replace} should be valid
 *
 * <pre>{@code
 * Example:
 *    input: {1, 2, 3, NULL, 5, 6, 7}
 *
 *    valid lo and hi
 *    lo: 3, hi: 5, lo_replace : 0, hi_replace : 16
 *    output:{0, 0, 3, NULL, 5, 16, 16}
 *
 *    invalid lo
 *    lo: NULL, hi: 5, lo_replace : 0, hi_replace : 16
 *    output:{1, 2, 3, NULL, 5, 16, 16}
 *
 *    invalid hi
 *    lo: 3, hi: NULL, lo_replace : 0, hi_replace : 16
 *    output:{0, 0, 3, NULL, 5, 6, 7}
 * }</pre>
 *
 * @throws cudf::logic_error if {@code lo.type() != hi.type()}
 * @throws cudf::logic_error if {@code lo_replace.type() != hi_replace.type()}
 * @throws cudf::logic_error if {@code lo.type() != lo_replace.type()}
 * @throws cudf::logic_error if {@code lo.type() != input.type()}
 *
 * @param input [in] Column whose elements will be clamped
 * @param lo [in] Minimum clamp value. All elements less than {@code lo} will be replaced by {@code lo_replace}. Ignored if null.
 * @param lo_replace [in] All elements less than {@code lo} will be replaced by {@code lo_replace}.
 * @param hi [in] Maximum clamp value. All elements greater than {@code hi} will be replaced by {@code hi_replace}. Ignored if null.
 * @param hi_replace [in] All elements greater than {@code hi} will be replaced by {@code hi_replace}.
 * @param mr [in] Optional resource to use for device memory
 *           allocation of the returned result column.
 *
 * @return Returns a clamped column as per {@code lo} and {@code hi} boundaries
 */
@Namespace("cudf::experimental") public static native @UniquePtr column clamp(@Const @ByRef column_view input,
                              @Const @ByRef scalar lo,
                              @Const @ByRef scalar lo_replace,
                              @Const @ByRef scalar hi,
                              @Const @ByRef scalar hi_replace,
                              device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::experimental") public static native @UniquePtr column clamp(@Const @ByRef column_view input,
                              @Const @ByRef scalar lo,
                              @Const @ByRef scalar lo_replace,
                              @Const @ByRef scalar hi,
                              @Const @ByRef scalar hi_replace);

/**
 * \brief Replaces values less than {@code lo} in {@code input} with {@code lo}, 
 * and values greater than {@code hi} with {@code hi}.
 *
 * if {@code lo} is invalid, then lo will not be considered while
 * evaluating the input (Essentially considered minimum value of that type).
 * if {@code hi} is invalid, then hi will not be considered while
 * evaluating the input (Essentially considered maximum value of that type).
 *
 * <pre>{@code
 * Example:
 *    input: {1, 2, 3, NULL, 5, 6, 7}
 *
 *    valid lo and hi
 *    lo: 3, hi: 5
 *    output:{3, 3, 3, NULL, 5, 5, 5}
 *
 *    invalid lo
 *    lo: NULL, hi:5
 *    output:{1, 2, 3, NULL, 5, 5, 5}
 *
 *    invalid hi
 *    lo: 3, hi:NULL
 *    output:{3, 3, 3, NULL, 5, 6, 7}
 * }</pre>
 *
 * @throws cudf::logic_error if {@code lo.type() != hi.type()}
 * @throws cudf::logic_error if {@code lo.type() != input.type()}
 *
 * @param input [in] Column whose elements will be clamped
 * @param lo [in] Minimum clamp value. All elements less than {@code lo} will be replaced by {@code lo}. Ignored if null.
 * @param hi [in] Maximum clamp value. All elements greater than {@code hi} will be replaced by {@code hi}. Ignored if null.
 * @param mr [in] Optional resource to use for device memory
 *           allocation of the returned result column.
 *
 * @return Returns a clamped column as per {@code lo} and {@code hi} boundaries
 */
@Namespace("cudf::experimental") public static native @UniquePtr column clamp(@Const @ByRef column_view input,
                              @Const @ByRef scalar lo,
                              @Const @ByRef scalar hi,
                              device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::experimental") public static native @UniquePtr column clamp(@Const @ByRef column_view input,
                              @Const @ByRef scalar lo,
                              @Const @ByRef scalar hi);

 // namespace experimental

/**
 * \brief Copies from a column of floating-point elements and replaces {@code -NaN} and {@code -0.0} with {@code +NaN} and {@code +0.0}, respectively.
 *
 * Converts floating point values from \p input using the following rules:
 *        Convert  -NaN  -> NaN
 *        Convert  -0.0  -> 0.0
 *
 * @throws cudf::logic_error if column does not have floating point data type.
 * @param Column [in] of floating-point elements to copy and normalize
 * @param device_memory_resource [in] allocator for allocating output data
 *
 * @return new column with the modified data
 */
@Namespace("cudf") public static native @UniquePtr column normalize_nans_and_zeros( @Const @ByRef column_view input,
                                                  device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf") public static native @UniquePtr column normalize_nans_and_zeros( @Const @ByRef column_view input);

/**
 * \brief Modifies a column of floating-point elements to replace all {@code -NaN} and {@code -0.0} with {@code +NaN} and {@code +0.0}, respectively.
 *
 * Converts floating point values from \p in_out using the following rules:
 *        Convert  -NaN  -> NaN
 *        Convert  -0.0  -> 0.0
 *
 * @throws cudf::logic_error if column does not have floating point data type.
 * @param Column [in, out] of floating-point elements to normalize
 */
@Namespace("cudf") public static native void normalize_nans_and_zeros(@ByRef mutable_column_view in_out);
 // namespace cudf


// Parsed from <cudf/scalar/scalar_device_view.cuh>

/*
 * Copyright (c) 2019, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
// #pragma once

// #include <cudf/scalar/scalar.hpp>
// #include <cudf/strings/string_view.ch>
// #include <cudf/types.hpp>
// Targeting ../scalar_device_view_base.java



/**
 * \brief A type of scalar_device_view where the value is a fixed width type
 */

  // namespace detail

/**
 * \brief A type of scalar_device_view that stores a pointer to a numerical value
 */
// Targeting ../string_scalar_device_view.java



/**
 * \brief A type of scalar_device_view that stores a pointer to a timestamp value
 */

/**
 * \brief Get the device view of a numeric_scalar
 */


/**
 * \brief Get the device view of a string_scalar
 */


/**
 * \brief Get the device view of a timestamp_scalar
 */


  // namespace cudf


// Parsed from <cudf/scalar/scalar.hpp>

/*
 * Copyright (c) 2019, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
// #pragma once

// #include <cudf/types.hpp>
// #include <cudf/utilities/type_dispatcher.hpp>
// #include <cudf/utilities/traits.hpp>

// #include <rmm/device_buffer.hpp>
// #include <rmm/device_scalar.hpp>
// #include <rmm/thrust_rmm_allocator.h>
// #include <rmm/mr/device_memory_resource.hpp>

// #include <memory>
// #include <type_traits>
// #include <utility>
// #include <vector>
// Targeting ../scalar.java



 // namespace detail


/**
 * \brief An owning class to represent a numerical value in device memory
 * 
 * \tparam T the data type of the numerical value
 */
// Targeting ../string_scalar.java



/**
 * \brief An owning class to represent a timestamp value in device memory
 * 
 * \tparam T the data type of the timestamp value
 * @see cudf/wrappers/timestamps.hpp for a list of allowed types
 */

  // namespace cudf


// Parsed from <cudf/scalar/scalar_factories.hpp>

/*
 * Copyright (c) 2019, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
// #pragma once

// #include <cudf/null_mask.hpp>
// #include <cudf/types.hpp>
// #include "scalar.hpp"
/**
 * \brief Construct scalar with uninitialized storage to hold a value of the
 * specified numeric {@code data_type} and a validity bool.
 * 
 * @throws std::bad_alloc if device memory allocation fails
 * @throws cudf::logic_error if {@code type} is not a numeric type
 *
 * @param type The desired numeric element type
 * @param stream Optional stream on which to issue all memory allocations
 * @param mr Optional resource to use for device memory
 *           allocation of the scalar's {@code data} and {@code is_valid} bool.
 */
@Namespace("cudf") public static native @MoveUniquePtr scalar make_numeric_scalar(
    @ByVal data_type type,
    @ByVal(nullValue = "cudaStream_t(0)") cudaStream_t stream,
    device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf") public static native @MoveUniquePtr scalar make_numeric_scalar(
    @ByVal data_type type);

/**
 * \brief Construct scalar with uninitialized storage to hold a value of the
 * specified timestamp {@code data_type} and a validity bool.
 * 
 * @throws std::bad_alloc if device memory allocation fails
 * @throws cudf::logic_error if {@code type} is not a timestamp type
 *
 * @param type The desired timestamp element type
 * @param stream Optional stream on which to issue all memory allocations
 * @param mr Optional resource to use for device memory
 *           allocation of the scalar's {@code data} and {@code is_valid} bool.
 */
@Namespace("cudf") public static native @MoveUniquePtr scalar make_timestamp_scalar(
    @ByVal data_type type,
    @ByVal(nullValue = "cudaStream_t(0)") cudaStream_t stream,
    device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf") public static native @MoveUniquePtr scalar make_timestamp_scalar(
    @ByVal data_type type);

/**
 * \brief Construct STRING type scalar given a {@code std::string}.
 * The size of the {@code std::string} must not exceed the maximum size of size_type.
 * The string characters are expected to be UTF-8 encoded sequence of char bytes.
 *
 * @throws std::bad_alloc if device memory allocation fails
 *
 * @param string The {@code std::string} to copy to device
 * @param stream Optional stream for use with all memory allocations
 * @param mr Optional resource to use for device memory
 *           allocation of the scalar's {@code data} and {@code is_valid}.
 */
@Namespace("cudf") public static native @MoveUniquePtr scalar make_string_scalar(
    @StdString BytePointer string,
    @ByVal(nullValue = "cudaStream_t(0)") cudaStream_t stream,
    device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf") public static native @MoveUniquePtr scalar make_string_scalar(
    @StdString BytePointer string);
@Namespace("cudf") public static native @MoveUniquePtr scalar make_string_scalar(
    @StdString String string,
    @ByVal(nullValue = "cudaStream_t(0)") cudaStream_t stream,
    device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf") public static native @MoveUniquePtr scalar make_string_scalar(
    @StdString String string);

/**
 * \brief Constructs default constructed scalar of type {@code type} 
 *
 * @throws std::bad_alloc if device memory allocation fails
 *
 * @param type The desired element type
 */
@Namespace("cudf") public static native @MoveUniquePtr scalar make_default_constructed_scalar(@ByVal data_type type);
  // namespace cudf


// Parsed from <cudf/copying.hpp>

/*
 * Copyright (c) 2018-2019, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

// #pragma once

// #include <cudf/types.hpp>
// #include <cudf/scalar/scalar.hpp>
// #include <cudf/column/column_view.hpp>
// #include <cudf/table/table.hpp>

// #include <memory>

/**
 * \brief Gathers the specified rows (including null values) of a set of columns.
 *
 * Gathers the rows of the source columns according to {@code gather_map} such that row "i"
 * in the resulting table's columns will contain row "gather_map[i]" from the source columns.
 * The number of rows in the result table will be equal to the number of elements in
 * {@code gather_map}.
 *
 * A negative value {@code i} in the {@code gather_map} is interpreted as {@code i+n}, where
 * {@code n} is the number of rows in the {@code source_table}.
 *
 * @throws {@code cudf::logic_error} if {@code check_bounds == true} and an index exists in
 * {@code gather_map} outside the range {@code [-n, n)}, where {@code n} is the number of rows in
 * the source table. If {@code check_bounds == false}, the behavior is undefined.
 *
 * @param source_table [in] The input columns whose rows will be gathered
 * @param gather_map [in] View into a non-nullable column of integral indices that maps the
 * rows in the source columns to rows in the destination columns.
 * @param check_bounds [in] Optionally perform bounds checking on the values
 * of {@code gather_map} and throw an error if any of its values are out of bounds.
 * @param mr [in] The resource to use for all allocations
 * @return std::unique_ptr<table> Result of the gather
 */
@Namespace("cudf::experimental") public static native @MoveUniquePtr table gather(@Const @ByRef table_view source_table, @Const @ByRef column_view gather_map,
                              @Cast("bool") boolean check_bounds/*=false*/,
                              device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::experimental") public static native @MoveUniquePtr table gather(@Const @ByRef table_view source_table, @Const @ByRef column_view gather_map);

/**
 * \brief Scatters the rows of the source table into a copy of the target table
 * according to a scatter map.
 *
 * Scatters values from the source table into the target table out-of-place,
 * returning a "destination table". The scatter is performed according to a
 * scatter map such that row {@code scatter_map[i]} of the destination table gets row
 * {@code i} of the source table. All other rows of the destination table equal
 * corresponding rows of the target table.
 *
 * The number of columns in source must match the number of columns in target
 * and their corresponding datatypes must be the same.
 * 
 * If the same index appears more than once in the scatter map, the result is
 * undefined.
 *
 * A negative value {@code i} in the {@code scatter_map} is interpreted as {@code i+n}, where {@code n}
 * is the number of rows in the {@code target} table.
 *
 * @throws {@code cudf::logic_error} if {@code check_bounds == true} and an index exists in
 * {@code scatter_map} outside the range {@code [-n, n)}, where {@code n} is the number of rows in
 * the target table. If {@code check_bounds == false}, the behavior is undefined.
 *
 * @param source The input columns containing values to be scattered into the
 * target columns
 * @param scatter_map A non-nullable column of integral indices that maps the
 * rows in the source table to rows in the target table. The size must be equal
 * to or less than the number of elements in the source columns.
 * @param target The set of columns into which values from the source_table
 * are to be scattered
 * @param check_bounds Optionally perform bounds checking on the values of
 * {@code scatter_map} and throw an error if any of its values are out of bounds.
 * @param mr The resource to use for all allocations
 * @return Result of scattering values from source to target
 *---------------------------------------------------------------------------**/
@Namespace("cudf::experimental") public static native @MoveUniquePtr table scatter(
    @Const @ByRef table_view source, @Const @ByRef column_view scatter_map,
    @Const @ByRef table_view target, @Cast("bool") boolean check_bounds/*=false*/,
    device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::experimental") public static native @MoveUniquePtr table scatter(
    @Const @ByRef table_view source, @Const @ByRef column_view scatter_map,
    @Const @ByRef table_view target);

/**
 * \brief Scatters a row of scalar values into a copy of the target table
 * according to a scatter map.
 *
 * Scatters values from the source row into the target table out-of-place,
 * returning a "destination table". The scatter is performed according to a
 * scatter map such that row {@code scatter_map[i]} of the destination table is
 * replaced by the source row. All other rows of the destination table equal
 * corresponding rows of the target table.
 *
 * The number of elements in source must match the number of columns in target
 * and their corresponding datatypes must be the same.
 * 
 * If the same index appears more than once in the scatter map, the result is
 * undefined.
 *
 * @throws {@code cudf::logic_error} if {@code check_bounds == true} and an index exists in
 * {@code scatter_map} outside the range {@code [-n, n)}, where {@code n} is the number of rows in
 * the target table. If {@code check_bounds == false}, the behavior is undefined.
 *
 * @param source The input scalars containing values to be scattered into the
 * target columns
 * @param indices A non-nullable column of integral indices that indicate
 * the rows in the target table to be replaced by source.
 * @param target The set of columns into which values from the source_table
 * are to be scattered
 * @param check_bounds Optionally perform bounds checking on the values of
 * {@code scatter_map} and throw an error if any of its values are out of bounds.
 * @param mr The resource to use for all allocations
 * @return Result of scattering values from source to target
 *---------------------------------------------------------------------------**/
@Namespace("cudf::experimental") public static native @MoveUniquePtr table scatter(
    @StdVector @UniquePtr scalar source, @Const @ByRef column_view indices,
    @Const @ByRef table_view target, @Cast("bool") boolean check_bounds/*=false*/,
    device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::experimental") public static native @MoveUniquePtr table scatter(
    @StdVector @UniquePtr scalar source, @Const @ByRef column_view indices,
    @Const @ByRef table_view target);

/**
 * \brief Scatters the rows of a table to {@code n} tables according to a partition map
 *
 * Copies the rows from the input table to new tables according to the table
 * indices given by partition_map. The number of output tables is one more than
 * the maximum value in {@code partition_map}.
 * 
 * Output table {@code i} in [0, n] is empty if {@code i} does not appear in partition_map.
 * output table will be empty.
 *
 * @throws cudf::logic_error when partition_map is a non-integer type
 * @throws cudf::logic_error when partition_map is larger than input
 * @throws cudf::logic_error when partition_map has nulls
 *
 * Example:
 * input:         [{10, 12, 14, 16, 18, 20, 22, 24, 26, 28},
 *                 { 1,  2,  3,  4, null, 0, 2,  4,  6,  2}]
 * partition_map: {3,  4,  3,  1,  4,  4,  0,  1,  1,  1}
 * output:     {[{22}, {2}], 
 *              [{16, 24, 26, 28}, {4, 4, 6, 2}],
 *              [{}, {}],
 *              [{10, 14}, {1, 3}],
 *              [{12, 18, 20}, {2, null, 0}]}
 *
 * @param input Table of rows to be partitioned into a set of tables
 * tables according to {@code partition_map}
 * @param partition_map  Non-null column of integer values that map
 * each row in {@code input} table into one of the output tables
 * @param mr The resource to use for all allocations
 *
 * @return A vector of tables containing the scattered rows of {@code input}.
 * {@code table} {@code i} contains all rows {@code j} from {@code input} where {@code partition_map[j] == i}.
 */
@Namespace("cudf::experimental") public static native @StdVector @UniquePtr table scatter_to_tables(
    @Const @ByRef table_view input, @Const @ByRef column_view partition_map,
    device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::experimental") public static native @StdVector @UniquePtr table scatter_to_tables(
    @Const @ByRef table_view input, @Const @ByRef column_view partition_map);

/** ---------------------------------------------------------------------------*
* \brief Indicates when to allocate a mask, based on an existing mask.
* ---------------------------------------------------------------------------**/
/** enum class cudf::experimental::mask_allocation_policy */
public static final int
    /** Do not allocate a null mask, regardless of input */
    NEVER = 0,
    /** Allocate a null mask if the input contains one */
    RETAIN = 1,
    /** Allocate a null mask, regardless of input */
    ALWAYS = 2;

/*
 * Initializes and returns an empty column of the same type as the `input`.
 *
 * @param[in] input Immutable view of input column to emulate
 * @return std::unique_ptr<column> An empty column of same type as `input`
 */
@Namespace("cudf::experimental") public static native @UniquePtr column empty_like(@Const @ByRef column_view input);

/**
 * \brief Creates an uninitialized new column of the same size and type as the {@code input}.
 * Supports only fixed-width types.
 *
 * @param input [in] Immutable view of input column to emulate
 * @param mask_alloc [in] Optional, Policy for allocating null mask. Defaults to RETAIN.
 * @param mr [in] Optional, The resource to use for all allocations
 * @return std::unique_ptr<column> A column with sufficient uninitialized capacity to hold the same number of elements as {@code input} of the same type as {@code input.type()}
 */
@Namespace("cudf::experimental") public static native @UniquePtr column allocate_like(@Const @ByRef column_view input,
                                      @Cast("cudf::experimental::mask_allocation_policy") int mask_alloc/*=cudf::experimental::mask_allocation_policy::RETAIN*/,
                                      device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::experimental") public static native @UniquePtr column allocate_like(@Const @ByRef column_view input);

/**
 * \brief Creates an uninitialized new column of the specified size and same type as the {@code input}.
 * Supports only fixed-width types.
 *
 * @param input [in] Immutable view of input column to emulate
 * @param size [in] The desired number of elements that the new column should have capacity for
 * @param mask_alloc [in] Optional, Policy for allocating null mask. Defaults to RETAIN.
 * @param mr [in] Optional, The resource to use for all allocations
 * @return std::unique_ptr<column> A column with sufficient uninitialized capacity to hold the specified number of elements as {@code input} of the same type as {@code input.type()}
 */
@Namespace("cudf::experimental") public static native @UniquePtr column allocate_like(@Const @ByRef column_view input, @ByVal size_type size,
                                      @Cast("cudf::experimental::mask_allocation_policy") int mask_alloc/*=cudf::experimental::mask_allocation_policy::RETAIN*/,
                                      device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::experimental") public static native @UniquePtr column allocate_like(@Const @ByRef column_view input, @ByVal size_type size);

/**
 * \brief Creates a table of empty columns with the same types as the {@code input_table}
 *
 * Creates the {@code cudf::column} objects, but does not allocate any underlying device
 * memory for the column's data or bitmask.
 *
 * @param input_table [in] Immutable view of input table to emulate
 * @return std::unique_ptr<table> A table of empty columns with the same types as the columns in {@code input_table}
 */
@Namespace("cudf::experimental") public static native @MoveUniquePtr table empty_like(@Const @ByRef table_view input_table);

/**
 * \brief Copies a range of elements in-place from one column to another.
 *
 * Overwrites the range of elements in \p target indicated by the indices
 * [\p target_begin, \p target_begin + N) with the elements from \p source
 * indicated by the indices [\p source_begin, \p source_end) (where N =
 * (\p source_end - \p source_begin)). Use the out-of-place copy function
 * returning std::unique_ptr<column> for uses cases requiring memory
 * reallocation. For example for strings columns and other variable-width types.
 *
 * If \p source and \p target refer to the same elements and the ranges overlap,
 * the behavior is undefined.
 *
 * @throws {@code cudf::logic_error} if memory reallocation is required (e.g. for
 * variable width types).
 * @throws {@code cudf::logic_error} for invalid range (if
 * \p source_begin > \p source_end, \p source_begin < 0,
 * \p source_begin >= \p source.size(), \p source_end > \p source.size(),
 * \p target_begin < 0, target_begin >= \p target.size(), or
 * \p target_begin + (\p source_end - \p source_begin) > \p target.size()).
 * @throws {@code cudf::logic_error} if \p target and \p source have different types.
 * @throws {@code cudf::logic_error} if \p source has null values and \p target is not
 * nullable.
 *
 * @param source The column to copy from
 * @param target The preallocated column to copy into
 * @param source_begin The starting index of the source range (inclusive)
 * @param source_end The index of the last element in the source range
 * (exclusive)
 * @param target_begin The starting index of the target range (inclusive)
 * @return void
 */
@Namespace("cudf::experimental") public static native void copy_range(@Const @ByRef column_view source,
                @ByRef mutable_column_view target,
                @ByVal size_type source_begin, @ByVal size_type source_end,
                @ByVal size_type target_begin);

/**
 * \brief Copies a range of elements out-of-place from one column to another.
 *
 * Creates a new column as if an in-place copy was performed into \p target.
 * A copy of \p target is created first and then the elements indicated by the
 * indices [\p target_begin, \p target_begin + N) were copied from the elements
 * indicated by the indices [\p source_begin, \p source_end) of \p source
 * (where N = (\p source_end - \p source_begin)). Elements outside the range are
 * copied from \p target into the returned new column target.
 *
 * If \p source and \p target refer to the same elements and the ranges overlap,
 * the behavior is undefined.
 *
 * @throws {@code cudf::logic_error} for invalid range (if
 * \p source_begin > \p source_end, \p source_begin < 0,
 * \p source_begin >= \p source.size(), \p source_end > \p source.size(),
 * \p target_begin < 0, target_begin >= \p target.size(), or
 * \p target_begin + (\p source_end - \p source_begin) > \p target.size()).
 * @throws {@code cudf::logic_error} if \p target and \p source have different types.
 *
 * @param source The column to copy from inside the range.
 * @param target The column to copy from outside the range.
 * @param source_begin The starting index of the source range (inclusive)
 * @param source_end The index of the last element in the source range
 * (exclusive)
 * @param target_begin The starting index of the target range (inclusive)
 * @param mr Memory resource to allocate the result target column.
 * @return std::unique_ptr<column> The result target column
 */
@Namespace("cudf::experimental") public static native @UniquePtr column copy_range(@Const @ByRef column_view source,
                                   @Const @ByRef column_view target,
                                   @ByVal size_type source_begin, @ByVal size_type source_end,
                                   @ByVal size_type target_begin,
                                   device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::experimental") public static native @UniquePtr column copy_range(@Const @ByRef column_view source,
                                   @Const @ByRef column_view target,
                                   @ByVal size_type source_begin, @ByVal size_type source_end,
                                   @ByVal size_type target_begin);

/**
 * \brief Slices a {@code column_view} into a set of {@code column_view}s according to a set of indices.
 * The returned views of {@code input} are constructed from an even number indices where
 * the {@code i}th returned {@code column_view} views the elements in {@code input} indicated by the range
 * {@code [indices[2*i], indices[(2*i)+1])}.
 *
 * For all {@code i} it is expected {@code indices[i] <= input.size()}
 * For all {@code i%2==0}, it is expected that {@code indices[i] <= indices[i+1]}
 *
 * \note It is the caller's responsibility to ensure that the returned views
 * do not outlive the viewed device memory.
 *
 * \example:
 * input:   {10, 12, 14, 16, 18, 20, 22, 24, 26, 28}
 * indices: {1, 3, 5, 9, 2, 4, 8, 8}
 * output:  {{12, 14}, {20, 22, 24, 26}, {14, 16}, {}}
 *
 * @throws {@code cudf::logic_error} if {@code indices} size is not even.
 * @throws {@code cudf::logic_error} When the values in the pair are strictly decreasing.
 * @throws {@code cudf::logic_error} When any of the values in the pair don't belong to
 * the range [0, input.size()).
 *
 * @param input View of column to slice
 * @param indices A vector of indices used to take slices of {@code input}.
 * @return Vector of views of {@code input} indicated by the ranges in {@code indices}.
 */
@Namespace("cudf::experimental") public static native @StdVector column_view slice(@Const @ByRef column_view input,
                               @StdVector size_type indices);

/**
 * \brief Slices a {@code table_view} into a set of {@code table_view}s according to a set of indices.
 * 
 * The returned views of {@code input} are constructed from an even number indices where
 * the {@code i}th returned {@code table_view} views the elements in {@code input} indicated by the range
 * {@code [indices[2*i], indices[(2*i)+1])}.
 *
 * For all {@code i} it is expected {@code indices[i] <= input.size()}
 * For all {@code i%2==0}, it is expected that {@code indices[i] <= indices[i+1]}
 *
 * \note It is the caller's responsibility to ensure that the returned views
 * do not outlive the viewed device memory.
 *
 * \example:
 * input:   [{10, 12, 14, 16, 18, 20, 22, 24, 26, 28},
 *           {50, 52, 54, 56, 58, 60, 62, 64, 66, 68}]
 * indices: {1, 3, 5, 9, 2, 4, 8, 8}
 * output:  [{{12, 14}, {20, 22, 24, 26}, {14, 16}, {}},
 *           {{52, 54}, {60, 22, 24, 26}, {14, 16}, {}}]
 *
 * @throws {@code cudf::logic_error} if {@code indices} size is not even.
 * @throws {@code cudf::logic_error} When the values in the pair are strictly decreasing.
 * @throws {@code cudf::logic_error} When any of the values in the pair don't belong to
 * the range [0, input.size()).
 *
 * @param input View of table to slice
 * @param indices A vector of indices used to take slices of {@code input}.
 * @return Vector of views of {@code input} indicated by the ranges in {@code indices}.
 */
@Namespace("cudf::experimental") public static native @StdVector table_view slice(@Const @ByRef table_view input,
                               @StdVector size_type indices);

/**
 * \brief Splits a {@code column_view} into a set of {@code column_view}s according to a set of indices
 * derived from expected splits.
 *
 * The returned view's of {@code input} are constructed from vector of splits, which indicates
 * where the split should occur. The {@code i}th returned {@code column_view} is sliced as
 * {@code [0, splits[i])} if {@code i}=0, else {@code [splits[i], input.size())} if {@code i} is the last view and
 * {@code splits[i] != input.size()}, or {@code [splits[i-1], splits[i]]} otherwise.
 *
 * For all {@code i} it is expected {@code splits[i] <= splits[i+1] <= input.size()}
 *
 * \note It is the caller's responsibility to ensure that the returned views
 * do not outlive the viewed device memory.
 *
 * Example:
 * input:   {10, 12, 14, 16, 18, 20, 22, 24, 26, 28}
 * splits:  {2, 5, 9}
 * output:  {{10, 12}, {14, 16, 18}, {20, 22, 24, 26}, {28}}
 *
 * @throws {@code cudf::logic_error} if {@code splits} has end index > size of {@code input}.
 * @throws {@code cudf::logic_error} When the value in {@code splits} is not in the range [0, input.size()).
 * @throws {@code cudf::logic_error} When the values in the {@code splits} are 'strictly decreasing'.
 *
 * @param input View of column to split
 * @param splits A vector of indices where the view will be split
 * @return The set of requested views of {@code input} indicated by the {@code splits}.
 */
@Namespace("cudf::experimental") public static native @StdVector column_view split(@Const @ByRef column_view input,
                               @StdVector size_type splits);

/**
 * \brief Splits a {@code table_view} into a set of {@code table_view}s according to a set of indices
 * derived from expected splits.
 *
 * The returned views of {@code input} are constructed from vector of splits, which indicates
 * where the split should occur. The {@code i}th returned {@code table_view} is sliced as
 * {@code [0, splits[i])} if {@code i}=0, else {@code [splits[i], input.size())} if {@code i} is the last view and
 * {@code splits[i] != input.size()}, or {@code [splits[i-1], splits[i]]} otherwise.
 *
 * For all {@code i} it is expected {@code splits[i] <= splits[i+1] <= input.size()}
 *
 * \note It is the caller's responsibility to ensure that the returned views
 * do not outlive the viewed device memory.
 *
 * Example:
 * input:   [{10, 12, 14, 16, 18, 20, 22, 24, 26, 28},
 *           {50, 52, 54, 56, 58, 60, 62, 64, 66, 68}]
 * splits:  {2, 5, 9}
 * output:  [{{10, 12}, {14, 16, 18}, {20, 22, 24, 26}, {28}},
 *           {{50, 52}, {54, 56, 58}, {60, 62, 64, 66}, {68}}]
 *           
 *
 * @throws {@code cudf::logic_error} if {@code splits} has end index > size of {@code input}.
 * @throws {@code cudf::logic_error} When the value in {@code splits} is not in the range [0, input.size()).
 * @throws {@code cudf::logic_error} When the values in the {@code splits} are 'strictly decreasing'.
 *
 * @param input View of a table to split
 * @param splits A vector of indices where the view will be split
 * @return The set of requested views of {@code input} indicated by the {@code splits}.
 */
@Namespace("cudf::experimental") public static native @StdVector table_view split(@Const @ByRef table_view input,
                               @StdVector size_type splits);
// Targeting ../contiguous_split_result.java



/**
 * \brief Performs a deep-copy split of a {@code table_view} into a set of {@code table_view}s into a single 
 * contiguous block of memory.
 *
 * The memory for the output views is allocated in a single contiguous {@code rmm::device_buffer} returned
 * in the {@code contiguous_split_result}. There is no top-level owning table.
 *
 * The returned views of {@code input} are constructed from a vector of indices, that indicate
 * where each split should occur. The {@code i}th returned {@code table_view} is sliced as
 * {@code [0, splits[i])} if {@code i}=0, else {@code [splits[i], input.size())} if {@code i} is the last view and
 * {@code splits[i] != input.size()}, or {@code [splits[i-1], splits[i]]} otherwise.
 *
 * For all {@code i} it is expected {@code splits[i] <= splits[i+1] <= input.size()}
 *
 * \note It is the caller's responsibility to ensure that the returned views
 * do not outlive the viewed device memory contained in the {@code all_data} field of the
 * returned contiguous_split_result.   
 *
 * Example:
 * input:   [{10, 12, 14, 16, 18, 20, 22, 24, 26, 28},
 *           {50, 52, 54, 56, 58, 60, 62, 64, 66, 68}]
 * splits:  {2, 5, 9}
 * output:  [{{10, 12}, {14, 16, 18}, {20, 22, 24, 26}, {28}},
 *           {{50, 52}, {54, 56, 58}, {60, 62, 64, 66}, {68}}]
 *           
 *
 * @throws {@code cudf::logic_error} if {@code splits} has end index > size of {@code input}.
 * @throws {@code cudf::logic_error} When the value in {@code splits} is not in the range [0, input.size()).
 * @throws {@code cudf::logic_error} When the values in the {@code splits} are 'strictly decreasing'.
 *
 * @param input View of a table to split
 * @param splits A vector of indices where the view will be split
 * @param mr [in] Optional, The resource to use for all returned allocations
 * @param stream [in] Optional CUDA stream on which to execute kernels
 * @return The set of requested views of {@code input} indicated by the {@code splits} and the viewed memory buffer.
 */
@Namespace("cudf::experimental") public static native @StdVector contiguous_split_result contiguous_split(@Const @ByRef table_view input,
                                                      @StdVector size_type splits,
                                                      device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::experimental") public static native @StdVector contiguous_split_result contiguous_split(@Const @ByRef table_view input,
                                                      @StdVector size_type splits);

/**
 * \brief   Returns a new column, where each element is selected from either \p lhs or 
 *          \p rhs based on the value of the corresponding element in \p boolean_mask
 *
 * Selects each element i in the output column from either \p rhs or \p lhs using the following rule:
 *          output[i] = (boolean_mask.valid(i) and boolean_mask[i]) ? lhs[i] : rhs[i]
 *          
 * @throws cudf::logic_error if lhs and rhs are not of the same type
 * @throws cudf::logic_error if lhs and rhs are not of the same length 
 * @throws cudf::logic_error if boolean mask is not of type bool8
 * @throws cudf::logic_error if boolean mask is not of the same length as lhs and rhs  
 * @param left [in] -hand column_view
 * @param right [in] -hand column_view
 * @param column [in] of {@code BOOL8} representing "left (true) / right (false)" boolean for each element and
 *            null element represents false.
 * @param mr [in] resource for allocating device memory
 *
 * @return new column with the selected elements
 */
@Namespace("cudf::experimental") public static native @UniquePtr column copy_if_else(@Const @ByRef column_view lhs, @Const @ByRef column_view rhs, @Const @ByRef column_view boolean_mask,
                                    device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::experimental") public static native @UniquePtr column copy_if_else(@Const @ByRef column_view lhs, @Const @ByRef column_view rhs, @Const @ByRef column_view boolean_mask);

/**
 * \brief   Returns a new column, where each element is selected from either \p lhs or 
 *          \p rhs based on the value of the corresponding element in \p boolean_mask
 *
 * Selects each element i in the output column from either \p rhs or \p lhs using the following rule:
 *          output[i] = (boolean_mask.valid(i) and boolean_mask[i]) ? lhs : rhs[i]
 *         
 * @throws cudf::logic_error if lhs and rhs are not of the same type 
 * @throws cudf::logic_error if boolean mask is not of type bool8
 * @throws cudf::logic_error if boolean mask is not of the same length as rhs  
 * @param left [in] -hand scalar
 * @param right [in] -hand column_view
 * @param column [in] of {@code BOOL8} representing "left (true) / right (false)" boolean for each element and
 *            null element represents false.
 * @param mr [in] resource for allocating device memory 
 *
 * @return new column with the selected elements
 */
@Namespace("cudf::experimental") public static native @UniquePtr column copy_if_else(@Const @ByRef scalar lhs, @Const @ByRef column_view rhs, @Const @ByRef column_view boolean_mask,
                                    device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::experimental") public static native @UniquePtr column copy_if_else(@Const @ByRef scalar lhs, @Const @ByRef column_view rhs, @Const @ByRef column_view boolean_mask);

/**
 * \brief   Returns a new column, where each element is selected from either \p lhs or 
 *          \p rhs based on the value of the corresponding element in \p boolean_mask
 *
 * Selects each element i in the output column from either \p rhs or \p lhs using the following rule:
 *          output[i] = (boolean_mask.valid(i) and boolean_mask[i]) ? lhs[i] : rhs
 *         
 * @throws cudf::logic_error if lhs and rhs are not of the same type 
 * @throws cudf::logic_error if boolean mask is not of type bool8
 * @throws cudf::logic_error if boolean mask is not of the same length as lhs  
 * @param left [in] -hand column_view
 * @param right [in] -hand scalar
 * @param column [in] of {@code BOOL8} representing "left (true) / right (false)" boolean for each element and
 *            null element represents false.
 * @param mr [in] resource for allocating device memory 
 *
 * @return new column with the selected elements
 */
@Namespace("cudf::experimental") public static native @UniquePtr column copy_if_else(@Const @ByRef column_view lhs, @Const @ByRef scalar rhs, @Const @ByRef column_view boolean_mask,
                                    device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::experimental") public static native @UniquePtr column copy_if_else(@Const @ByRef column_view lhs, @Const @ByRef scalar rhs, @Const @ByRef column_view boolean_mask);
                                    
/**
 * \brief   Returns a new column, where each element is selected from either \p lhs or 
 *          \p rhs based on the value of the corresponding element in \p boolean_mask
 *
 * Selects each element i in the output column from either \p rhs or \p lhs using the following rule:
 *          output[i] = (boolean_mask.valid(i) and boolean_mask[i]) ? lhs : rhs
 *          
 * @throws cudf::logic_error if boolean mask is not of type bool8 
 * @param left [in] -hand scalar
 * @param right [in] -hand scalar
 * @param column [in] of {@code BOOL8} representing "left (true) / right (false)" boolean for each element and
 *            null element represents false.
 * @param mr [in] resource for allocating device memory 
 *
 * @return new column with the selected elements
 */
@Namespace("cudf::experimental") public static native @UniquePtr column copy_if_else( @Const @ByRef scalar lhs, @Const @ByRef scalar rhs, @Const @ByRef column_view boolean_mask,
                                    device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::experimental") public static native @UniquePtr column copy_if_else( @Const @ByRef scalar lhs, @Const @ByRef scalar rhs, @Const @ByRef column_view boolean_mask);

  // namespace experimental
  // namespace cudf


// Parsed from <cudf/quantiles.hpp>

/*
 * Copyright (c) 2019, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

// #pragma once

// #include <cudf/scalar/scalar.hpp>
// #include <cudf/table/table_view.hpp>
// #include <cudf/types.hpp>

/* @brief For each column, computes a value for a quantile by interpolating
 *        between the values on either side of the desired quantile.
 *
 * @param[in] input        Table containing columns used to compute quantile
 *                         values.
 * @param[in] q            Desired quantile in range [0, 1].
 * @param[in] interp       Strategy used to interpolate between the two values
 *                         on either side of the desired quantile.
 * @param[in] column_order Indicates the sortedness of columns.
 *
 * @returns Value of the desired quantile for each column, or null if the column
 *          has no valid elements.
 */

@Namespace("cudf::experimental") public static native @StdVector @UniquePtr scalar quantiles(@Const @ByRef table_view input,
          double q,
          @ByVal(nullValue = "interpolation::LINEAR") interpolation interp,
          @StdVector order_info column_order/*={}*/);
@Namespace("cudf::experimental") public static native @StdVector @UniquePtr scalar quantiles(@Const @ByRef table_view input,
          double q);

 // namespace experimental
 // namespace cudf


// Parsed from <cudf/transpose.hpp>

/*
 * Copyright (c) 2019, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
// #pragma once

// #include <cudf/table/table.hpp>
// #include <cudf/table/table_view.hpp>

/**
 * \brief Returns a new table transposed from the input table
 *
 * @throws cudf::logic_error if column types are non-homogenous
 * @throws cudf::logic_error if column types are non-fixed-width
 * 
 * @param input [in] Input table of (ncols) number of columns each of size (nrows)
 * @return Newly allocated output table with (nrows) columns each of size (ncols)
 */
@Namespace("cudf") public static native @UniquePtr table transpose(@Const @ByRef table_view input,
                                 device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf") public static native @UniquePtr table transpose(@Const @ByRef table_view input);

  // namespace cudf


// Parsed from <cudf/cudf.h>

// #ifndef GDF_GDF_H
// #define GDF_GDF_H

// #include <cstdlib>
// #include <cstdint>
// #include "types.h"
// #include "types.hpp"
// #include "convert_types.h"
// #include "legacy/io_types.hpp"
// #include "legacy/io_functions.hpp"
// #include "legacy/io_readers.hpp"
// #include "legacy/io_writers.hpp"
// #include "legacy/column.hpp"

@MemberGetter public static native @Cast("const size_t") long GDF_VALID_BITSIZE();
// #include "legacy/functions.h"
// #include "legacy/io_types.h"
// #include "legacy/io_functions.h"

// #endif /* GDF_GDF_H */


// Parsed from <cudf/strings/combine.hpp>

/*
 * Copyright (c) 2019, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
// #pragma once

// #include <cudf/strings/strings_column_view.hpp>
// #include <cudf/column/column.hpp>
// #include <cudf/table/table_view.hpp>
// #include <cudf/scalar/scalar.hpp>

/**
 * \brief Row-wise concatenates the given list of strings columns and
 * returns a single strings column result.
 *
 * Each new string is created by concatenating the strings from the same
 * row delimited by the separator provided.
 *
 * Any row with a null entry will result in the corresponding output
 * row to be null entry unless a narep string is specified to be used
 * in its place.
 *
 * The number of strings in the columns provided must be the same.
 *
 * <pre>{@code
 * s1 = ['aa', null, '', 'aa']
 * s2 = ['', 'bb', 'bb', null]
 * r1 = concatenate([s1,s2])
 * r1 is ['aa', null, 'bb', null]
 * r2 = concatenate([s1,s2],':','_')
 * r2 is ['aa:', '_:bb', ':bb', 'aa:_']
 * }</pre>
 *
 * @throws cudf::logic_error if input columns are not all strings columns.
 * @throws cudf::logic_error if separator is not valid.
 *
 * @param strings_columns List of string columns to concatenate.
 * @param separator String that should inserted between each string from each row.
 *        Default is an empty string.
 * @param narep String that should be used in place of any null strings
 *        found in any column. Default of invalid-scalar means any null entry in any column will
 *        produces a null result for that row.
 * @param mr Resource for allocating device memory.
 * @return New column with concatenated results.
 */
@Namespace("cudf::strings") public static native @UniquePtr column concatenate( @Const @ByRef table_view strings_columns,
                                     @Const @ByRef(nullValue = "cudf::string_scalar(\"\")") string_scalar separator,
                                     @Const @ByRef(nullValue = "cudf::string_scalar(\"\",false)") string_scalar narep,
                                     device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::strings") public static native @UniquePtr column concatenate( @Const @ByRef table_view strings_columns);

/**
 * \brief Concatenates all strings in the column into one new string delimited
 * by an optional separator string.
 *
 * This returns a column with one string. Any null entries are ignored unless
 * the narep parameter specifies a replacement string.
 *
 * <pre>{@code
 * s = ['aa', null, '', 'zz' ]
 * r = join_strings(s,':','_')
 * r is ['aa:_::zz']
 * }</pre>
 *
 * @throws cudf::logic_error if separator is not valid.
 *
 * @param strings Strings for this operation.
 * @param separator String that should inserted between each string.
 *        Default is an empty string.
 * @param narep String that should represent any null strings found.
 *        Default of invalid-scalar will ignore any null entries.
 * @param mr Resource for allocating device memory.
 * @return New column containing one string.
 */
@Namespace("cudf::strings") public static native @UniquePtr column join_strings( @Const @ByRef strings_column_view strings,
                                      @Const @ByRef(nullValue = "cudf::string_scalar(\"\")") string_scalar separator,
                                      @Const @ByRef(nullValue = "cudf::string_scalar(\"\",false)") string_scalar narep,
                                      device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::strings") public static native @UniquePtr column join_strings( @Const @ByRef strings_column_view strings);

 // namespace strings
 // namespace cudf


// Parsed from <cudf/strings/replace.hpp>

/*
 * Copyright (c) 2019, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
// #pragma once

// #include <cudf/strings/strings_column_view.hpp>
// #include <cudf/column/column.hpp>
// #include <cudf/scalar/scalar.hpp>

/**
 * \brief Replaces target string within each string with the specified
 * replacement string.
 *
 * This function searches each string in the column for the target string.
 * If found, the target string is replaced by the repl string within the
 * input string. If not found, the output entry is just a copy of the
 * corresponding input string.
 *
 * Specifing an empty string for repl will essentially remove the target
 * string if found in each string.
 *
 * Null string entries will return null output string entries.
 *
 * <pre>{@code
 * s = ["hello", "goodbye"]
 * r1 = replace(s,"o","OOO")
 * r1 is now ["hellOOO","gOOOOOOdbye"]
 * r2 = replace(s,"oo","")
 * r2 is now ["hello","gdbye"]
 * }</pre>
 *
 * @throws cudf::logic_error if target is an empty string.
 *
 * @param strings Strings column for this operation.
 * @param target String to search for within each string.
 * @param repl Replacement string if target is found.
 * @param maxrepl Maximum times to replace if target appears multiple times in the input string.
 *        Default of -1 specifies replace all occurrences of target in each string.
 * @param mr Resource for allocating device memory.
 * @return New strings column.
 */
@Namespace("cudf::strings") public static native @UniquePtr column replace( @Const @ByRef strings_column_view strings,
                                 @Const @ByRef string_scalar target,
                                 @Const @ByRef string_scalar repl,
                                 int maxrepl/*=-1*/,
                                 device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::strings") public static native @UniquePtr column replace( @Const @ByRef strings_column_view strings,
                                 @Const @ByRef string_scalar target,
                                 @Const @ByRef string_scalar repl);

/**
 * \brief This function replaces each string in the column with the provided
 * repl string within the [start,stop) character position range.
 *
 * Null string entries will return null output string entries.
 *
 * Position values are 0-based meaning position 0 is the first character
 * of each string.
 *
 * This function can be used to insert a string into specific position
 * by specifying the same position value for start and stop. The repl
 * string can be appended to each string by specifying -1 for both
 * start and stop.
 *
 * <pre>{@code
 * s = ["abcdefghij","0123456789"]
 * r = s.replace_slice(s,2,5,"z")
 * r is now ["abzfghij", "01z56789"]
 * }</pre>
 *
 * @throws cudf::logic_error if start is greater than stop.
 *
 * @param strings Strings column for this operation.
 * @param repl Replacement string for specified positions found.
 *        Default is empty string.
 * @param start Start position where repl will be added.
 *        Default is 0, first character position.
 * @param stop End position (exclusive) to use for replacement.
 *        Default of -1 specifies the end of each string.
 * @param mr Resource for allocating device memory.
 * @return New strings column.
 */
@Namespace("cudf::strings") public static native @UniquePtr column replace_slice( @Const @ByRef strings_column_view strings,
                                       @Const @ByRef(nullValue = "cudf::string_scalar(\"\")") string_scalar repl,
                                       @ByVal(nullValue = "size_type(0)") size_type start, @ByVal(nullValue = "size_type(-1)") size_type stop,
                                       device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::strings") public static native @UniquePtr column replace_slice( @Const @ByRef strings_column_view strings);

/**
 * \brief Replaces substrings matching a list of targets with the corresponding
 * replacement strings.
 *
 * For each string in strings, the list of targets is searched within that string.
 * If a target string is found, it is replaced by the corresponding entry in the repls column.
 * All occurrences found in each string are replaced.
 *
 * This does not use regex to match targets in the string.
 *
 * Null string entries will return null output string entries.
 *
 * The repls argument can optionally contain a single string. In this case, all
 * matching target substrings will be replaced by that single string.
 *
 * <pre>{@code
 * s = ["hello", "goodbye"]
 * tgts = ["e","o"]
 * repls = ["EE","OO"]
 * r1 = replace(s,tgts,repls)
 * r1 is now ["hEEllO", "gOOOOdbyEE"]
 * tgts = ["e","oo"]
 * repls = ["33",""]
 * r2 = replace(s,tgts,repls)
 * r2 is now ["h33llo", "gdby33"]
 * }</pre>
 *
 * @throws cudf::logic_error if targets and repls are different sizes except
 * if repls is a single string.
 * @throws cudf::logic_error if targets or repls contain null entries.
 *
 * @param strings Strings column for this operation.
 * @param targets Strings to search for in each string.
 * @param repls Corresponding replacement strings for target strings.
 * @param mr Resource for allocating device memory.
 * @return New strings column.
 */
@Namespace("cudf::strings") public static native @UniquePtr column replace( @Const @ByRef strings_column_view strings,
                                 @Const @ByRef strings_column_view targets,
                                 @Const @ByRef strings_column_view repls,
                                 device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::strings") public static native @UniquePtr column replace( @Const @ByRef strings_column_view strings,
                                 @Const @ByRef strings_column_view targets,
                                 @Const @ByRef strings_column_view repls);

/**
 * \brief Replaces any null string entries with the given string.
 *
 * This returns a strings column with no null entries.
 *
 * <pre>{@code
 * s = ["hello", nullptr, "goodbye"]
 * r = replace_nulls(s,"**")
 * r is now ["hello", "**", "goodbye"]
 * }</pre>
 *
 * @param strings Strings column for this operation.
 * @param repl Replacement string for null entries. Default is empty string.
 * @param mr Resource for allocating device memory.
 * @return New strings column.
 */
@Namespace("cudf::strings") public static native @UniquePtr column replace_nulls( @Const @ByRef strings_column_view strings,
                                       @Const @ByRef(nullValue = "cudf::string_scalar(\"\")") string_scalar repl,
                                       device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::strings") public static native @UniquePtr column replace_nulls( @Const @ByRef strings_column_view strings);


 // namespace strings
 // namespace cudf


// Parsed from <cudf/strings/replace_re.hpp>

/*
 * Copyright (c) 2019, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
// #pragma once

// #include <cudf/strings/strings_column_view.hpp>
// #include <cudf/column/column.hpp>
// #include <cudf/scalar/scalar.hpp>

/**
 * \brief For each string, replaces any character sequence matching the given pattern
 * with the provided replacement string.
 *
 * Any null string entries return corresponding null output column entries.
 *
 * @param strings Strings instance for this operation.
 * @param pattern The regular expression pattern to search within each string.
 * @param repl The string used to replace the matched sequence in each string.
 *        Default is an empty string.
 * @param maxrepl The maximum number of times to replace the matched pattern within each string.
 * @param mr Resource for allocating device memory.
 * @return New strings column.
 */
@Namespace("cudf::strings") public static native @UniquePtr column replace_re( @Const @ByRef strings_column_view strings,
                                    @StdString BytePointer pattern,
                                    @Const @ByRef(nullValue = "cudf::string_scalar(\"\")") string_scalar repl,
                                    @ByVal(nullValue = "size_type(-1)") size_type maxrepl,
                                    device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::strings") public static native @UniquePtr column replace_re( @Const @ByRef strings_column_view strings,
                                    @StdString BytePointer pattern);
@Namespace("cudf::strings") public static native @UniquePtr column replace_re( @Const @ByRef strings_column_view strings,
                                    @StdString String pattern,
                                    @Const @ByRef(nullValue = "cudf::string_scalar(\"\")") string_scalar repl,
                                    @ByVal(nullValue = "size_type(-1)") size_type maxrepl,
                                    device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::strings") public static native @UniquePtr column replace_re( @Const @ByRef strings_column_view strings,
                                    @StdString String pattern);

/**
 * \brief For each string, replaces any character sequence matching the given patterns
 * with the corresponding string in the repls column.
 *
 * Any null string entries return corresponding null output column entries.
 *
 * @param strings Strings instance for this operation.
 * @param pattern The regular expression patterns to search within each string.
 * @param repls The strings used for replacement.
 * @param mr Resource for allocating device memory.
 * @return New strings column.
 */
@Namespace("cudf::strings") public static native @UniquePtr column replace_re( @Const @ByRef strings_column_view strings,
                                    @StdString @StdVector BytePointer patterns,
                                    @Const @ByRef strings_column_view repls,
                                    device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::strings") public static native @UniquePtr column replace_re( @Const @ByRef strings_column_view strings,
                                    @StdString @StdVector BytePointer patterns,
                                    @Const @ByRef strings_column_view repls);

/**
 * \brief For each string, replaces any character sequence matching the given pattern
 * using the repl template for back-references.
 *
 * Any null string entries return corresponding null output column entries.
 *
 * @param strings Strings instance for this operation.
 * @param pattern The regular expression patterns to search within each string.
 * @param repl The replacement template for creating the output string.
 * @param mr Resource for allocating device memory.
 * @return New strings column.
 */
@Namespace("cudf::strings") public static native @UniquePtr column replace_with_backrefs( @Const @ByRef strings_column_view strings,
                                               @StdString BytePointer pattern,
                                               @StdString BytePointer repl,
                                               device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::strings") public static native @UniquePtr column replace_with_backrefs( @Const @ByRef strings_column_view strings,
                                               @StdString BytePointer pattern,
                                               @StdString BytePointer repl);
@Namespace("cudf::strings") public static native @UniquePtr column replace_with_backrefs( @Const @ByRef strings_column_view strings,
                                               @StdString String pattern,
                                               @StdString String repl,
                                               device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::strings") public static native @UniquePtr column replace_with_backrefs( @Const @ByRef strings_column_view strings,
                                               @StdString String pattern,
                                               @StdString String repl);

 // namespace strings
 // namespace cudf


// Parsed from <cudf/strings/copying.hpp>

/*
 * Copyright (c) 2019, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
// #pragma once

// #include <cudf/strings/strings_column_view.hpp>
// #include <cudf/column/column.hpp>

/**
 * \brief Returns a new strings column created from a subset of
 * of the strings column. The subset of strings selected is between
 * start (inclusive) and end (exclusive) with incrememnts of step.
 *
 * <pre>{@code
 * s1 = ["a", "b", "c", "d", "e", "f"]
 * s2 = slice( s1, 2 )
 * s2 is ["c", "d", "e", "f"]
 * s3 = slice( s1, 1, 2 )
 * s3 is ["b", "d", "f"]
 * }</pre>
 *
 * @param strings Strings instance for this operation.
 * @param start Index to first string to select in the column (inclusive).
 * @param end Index to last string to select in the column (exclusive).
 *            Default -1 indicates the last element.
 * @param step Increment value between indices.
 *             Default step is 1.
 * @param stream CUDA stream to use kernels in this method.
 * @param mr Resource for allocating device memory.
 * @return New strings column of size (end-start)/step.
 */
@Namespace("cudf::strings::detail") public static native @MoveUniquePtr column slice( @Const @ByRef strings_column_view strings,
                                     @ByVal size_type start, @ByVal(nullValue = "size_type(-1)") size_type end,
                                     @ByVal(nullValue = "size_type(1)") size_type step,
                                     @ByVal(nullValue = "cudaStream_t(0)") cudaStream_t stream,
                                     device_memory_resource mr/*=rmm::mr::get_default_resource()*/ );
@Namespace("cudf::strings::detail") public static native @MoveUniquePtr column slice( @Const @ByRef strings_column_view strings,
                                     @ByVal size_type start );

/**
 * \brief Returns a new strings column using the specified indices to select
 * elements from the {@code strings} column.
 *
 * <pre>{@code
 * s1 = ["a", "b", "c", "d", "e", "f"]
 * map = [0, 2]
 * s2 = gather( s1, map )
 * s2 is ["a", "c"]
 * }</pre>
 *
 * @param strings Strings instance for this operation.
 * @param gather_map The indices with which to select strings for the new column.
 *        Values must be within [0,size()) range.
 * @param stream CUDA stream to use kernels in this method.
 * @param mr Resource for allocating device memory.
 * @return New strings column of size indices.size()
 */
@Namespace("cudf::strings::detail") public static native @MoveUniquePtr column gather( @Const @ByRef strings_column_view strings,
                                      @ByVal column_view gather_map,
                                      @ByVal(nullValue = "cudaStream_t(0)") cudaStream_t stream,
                                      device_memory_resource mr/*=rmm::mr::get_default_resource()*/ );
@Namespace("cudf::strings::detail") public static native @MoveUniquePtr column gather( @Const @ByRef strings_column_view strings,
                                      @ByVal column_view gather_map );


 // namespace detail
 // namespace strings
 // namespace cudf


// Parsed from <cudf/strings/char_types/char_types.hpp>

/*
 * Copyright (c) 2019, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
// #pragma once

// #include <cudf/strings/strings_column_view.hpp>
// #include <cudf/column/column.hpp>

/**
 * \brief Character type values.
 * These types can be or'd to check for any combination of types.
 */
/** enum cudf::strings::string_character_types */
public static final int
    DECIMAL  = 1 << 0,                            // binary 00000001
    NUMERIC  = 1 << 1,                            // binary 00000010
    DIGIT    = 1 << 2,                            // binary 00000100
    ALPHA    = 1 << 3,                            // binary 00001000
    SPACE    = 1 << 4,                            // binary 00010000
    UPPER    = 1 << 5,                            // binary 00100000
    LOWER    = 1 << 6,                            // binary 01000000
    ALPHANUM = DECIMAL | NUMERIC | DIGIT | ALPHA;  // binary 00001111

/**
 * \brief Returns a boolean column identifying strings entries in which all
 * characters are of the type specified.
 *
 * The output row entry will be set to false if the corresponding string element
 * is empty or has at least one character not of the specified type. If all
 * characters fit the type then true is set in that output row entry.
 *
 * Any null string results in a null entry for that row in the output column.
 *
 * @param strings Strings instance for this operation.
 * @param types The character types to check in each string.
 * @param mr Resource for allocating device memory.
 * @return New column of boolean results for each string.
 */
@Namespace("cudf::strings") public static native @UniquePtr column all_characters_of_type( @Const @ByRef strings_column_view strings,
                                                @Cast("cudf::strings::string_character_types") int types,
                                                device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::strings") public static native @UniquePtr column all_characters_of_type( @Const @ByRef strings_column_view strings,
                                                @Cast("cudf::strings::string_character_types") int types);

 // namespace strings
 // namespace cudf


// Parsed from <cudf/strings/strings_column_view.hpp>

/*
 * Copyright (c) 2019, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
// #pragma once

// #include <cudf/column/column_view.hpp>
// #include <cudf/column/column.hpp>

// #include <rmm/thrust_rmm_allocator.h>

/**
 * \file strings_column_view.hpp
 * \brief Class definition for cudf::strings_column_view
 */
// Targeting ../strings_column_view.java



/**
 * \brief Prints the strings to stdout.
 *
 * @param strings Strings instance for this operation.
 * @param start Index of first string to print.
 * @param end Index of last string to print. Specify -1 for all strings.
 * @param max_width Maximum number of characters to print per string.
 *        Specify -1 to print all characters.
 * @param delimiter The chars to print between each string.
 *        Default is new-line character.
 */
@Namespace("cudf::strings") public static native void print( @Const @ByRef strings_column_view strings,
            @ByVal(nullValue = "size_type(0)") size_type start, @ByVal(nullValue = "size_type(-1)") size_type end,
            @ByVal(nullValue = "size_type(-1)") size_type max_width, @Cast("const char*") BytePointer delimiter/*="\n"*/ );
@Namespace("cudf::strings") public static native void print( @Const @ByRef strings_column_view strings );
@Namespace("cudf::strings") public static native void print( @Const @ByRef strings_column_view strings,
            @ByVal(nullValue = "size_type(0)") size_type start, @ByVal(nullValue = "size_type(-1)") size_type end,
            @ByVal(nullValue = "size_type(-1)") size_type max_width, String delimiter/*="\n"*/ );

/**
 * \brief Create output per Arrow strings format.
 *
 * The return pair is the vector of chars and the vector of offsets.
 *
 * @param strings Strings instance for this operation.
 * @param stream CUDA stream to use kernels in this method.
 * @param mr Resource for allocating device memory.
 * @return Pair containing a vector of chars and a vector of offsets.
 */
@Namespace("cudf::strings") public static native @ByVal PairOfRmmDeviceVectorCharRmmDeviceVectorSizeType create_offsets( @Const @ByRef strings_column_view strings,
                    @ByVal(nullValue = "cudaStream_t(0)") cudaStream_t stream,
                    device_memory_resource mr/*=rmm::mr::get_default_resource()*/ );
@Namespace("cudf::strings") public static native @ByVal PairOfRmmDeviceVectorCharRmmDeviceVectorSizeType create_offsets( @Const @ByRef strings_column_view strings );

 // namespace strings
 // namespace cudf


// Parsed from <cudf/strings/strip.hpp>

/*
 * Copyright (c) 2019, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
// #pragma once

// #include <cudf/strings/strings_column_view.hpp>
// #include <cudf/column/column.hpp>
// #include <cudf/scalar/scalar.hpp>

/** enum class cudf::strings::strip_type */
public static final int
    LEFT = 0,   //<< strip characters from the beginning of the string
    RIGHT = 1,  //<< strip characters from the end of the string
    BOTH = 2;    //<< strip characters from the beginning and end of the string

/**
 * \brief Removes the specified characters from the beginning or end
 * (or both) of each string.
 *
 * The to_strip parameter can contain one or more characters.
 * All characters in {@code to_strip} are removed from the input strings.
 *
 * If {@code to_strip} is the empty string, whitespace characters are removed.
 * Whitespace is considered the space character plus control characters
 * like tab and line feed.
 *
 * Any null string entries return corresponding null output column entries.
 *
 * <pre>{@code
 * s = [" aaa ", "_bbbb ", "__cccc  ", "ddd", " ee _ff gg_"]
 * r = strip(s,both," _")
 * r is now ["aaa", "bbbb", "cccc", "ddd", "ee _ff gg"]
 * }</pre>
 *
 * @throws cudf::logic_error if {@code to_strip} is invalid.
 *
 * @param strings Strings column for this operation.
 * @param stype Indicates characters are to be stripped from the beginning, end, or both of each string.
 *        Default is both.
 * @param to_strip UTF-8 encoded characters to strip from each string.
 *        Default is empty string which indicates strip whitespace characters.
 * @param mr Resource for allocating device memory.
 * @return New strings column.
 */
@Namespace("cudf::strings") public static native @UniquePtr column strip( @Const @ByRef strings_column_view strings,
                               @Cast("cudf::strings::strip_type") int stype/*=cudf::strings::strip_type::BOTH*/,
                               @Const @ByRef(nullValue = "cudf::string_scalar(\"\")") string_scalar to_strip,
                               device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::strings") public static native @UniquePtr column strip( @Const @ByRef strings_column_view strings);


 // namespace strings
 // namespace cudf


// Parsed from <cudf/strings/translate.hpp>

/*
 * Copyright (c) 2019, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
// #pragma once

// #include <cudf/column/column.hpp>
// #include <cudf/strings/strings_column_view.hpp>

/**
 * \brief Translates individual characters within each string.
 *
 * This can also be used to remove a character by specifying 0 for the corresponding table entry.
 *
 * Null string entries result in null entries in the output column.
 *
 * <pre>{@code
 * s = ["aa","bbb","cccc","abcd"]
 * t = [['a','A'],['b',''],['d':'Q']]
 * r = translate(s,t)
 * r is now ["AA", "", "cccc", "AcQ"]
 * }</pre>
 *
 * @param strings Strings instance for this operation.
 * @param chars_table Table of UTF-8 character mappings.
 * @return New column with padded strings.
 */
@Namespace("cudf::strings") public static native @UniquePtr column translate( @Const @ByRef strings_column_view strings,
                                   @StdVector PairOfCharUtf8CharUtf8 chars_table,
                                   device_memory_resource mr/*=rmm::mr::get_default_resource()*/ );
@Namespace("cudf::strings") public static native @UniquePtr column translate( @Const @ByRef strings_column_view strings,
                                   @StdVector PairOfCharUtf8CharUtf8 chars_table );

 // namespace strings
 // namespace cudf


// Parsed from <cudf/strings/find_multiple.hpp>

/*
 * Copyright (c) 2019, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
// #pragma once

// #include <cudf/strings/strings_column_view.hpp>
// #include <cudf/column/column.hpp>

/**
 * \brief Returns a column with character position values where each
 * of the target strings are found in each string.
 *
 * The size of the output column is targets.size() * strings.size().
 * output[i] contains the position of target[i % targets.size()] in string[i/targets.size()]
 *
 * <pre>{@code
 * s = ["abc","def"]
 * t = ["a","c","e"]
 * r = find_multiple(s,t)
 * r is now [ 0, 2,-1,   // for "abc": "a" at pos 0, "c" at pos 2, "e" not found
 *           -1,-1, 1 ]  // for "def": "a" and "b" not found, "e" at  pos 1
 * }</pre>
 *
 * @throws cudf::logic_error targets is empty or contains nulls
 *
 * @param strings Strings instance for this operation.
 * @param targets Strings to search for in each string.
 * @param mr Resource for allocating device memory.
 * @return New integer column with character position values.
 */
@Namespace("cudf::strings") public static native @UniquePtr column find_multiple( @Const @ByRef strings_column_view strings,
                                       @Const @ByRef strings_column_view targets,
                                       device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::strings") public static native @UniquePtr column find_multiple( @Const @ByRef strings_column_view strings,
                                       @Const @ByRef strings_column_view targets);

 // namespace strings
 // namespace cudf


// Parsed from <cudf/strings/substring.hpp>

/*
 * Copyright (c) 2019, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
// #pragma once

// #include <cudf/strings/strings_column_view.hpp>
// #include <cudf/column/column.hpp>

/**
 * \brief Returns a new strings column that contains substrings of the
 * strings in the provided column.
 *
 * The character positions to retrieve in each string are [start,stop).
 * If the start position is outside a string's length, an empty
 * string is returned for that entry. If the stop position is past the
 * end of a string's length, the end of the string is used for
 * stop position for that string.
 *
 * Null string entries will return null output string entries.
 *
 * <pre>{@code
 * s = ["hello", "goodbye"]
 * r = substring(s,2,6)
 * r is now ["llo","odby"]
 * r2 = substring(s,2,5,2)
 * r2 is now ["lo","ob"]
 * }</pre>
 *
 * @throws cudf::logic_error if start position is not a positive integer or zero.
 * @throws cudf::logic_error if start is greater than stop.
 * @throws cudf::logic_error if step value is not a positive integer.
 *
 * @param strings Strings column for this operation.
 * @param start First character position to begin the substring.
 * @param stop Last character position (exclusive) to end the substring.
 *             Default of -1 indicates to use the end of each string.
 * @param step Distance between input characters retrieved.
 * @param mr Resource for allocating device memory.
 * @return New strings column with sorted elements of this instance.
 */
@Namespace("cudf::strings") public static native @UniquePtr column slice_strings( @Const @ByRef strings_column_view strings,
                                       @ByVal size_type start, @ByVal(nullValue = "size_type(-1)") size_type stop, @ByVal(nullValue = "size_type(1)") size_type step,
                                       device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::strings") public static native @UniquePtr column slice_strings( @Const @ByRef strings_column_view strings,
                                       @ByVal size_type start);


/**
 * \brief Returns a new strings column that contains substrings of the
 * strings in the provided column using unique ranges for each string.
 *
 * The character positions to retrieve in each string are [start,stop).
 * If a start position is outside a string's length, an empty
 * string is returned for that entry. If a stop position is past the
 * end of a string's length, the end of the string is used for
 * stop position for that string. Any stop position value set to -1 will
 * indicate to use the end of the string as the stop position for that
 * string.
 *
 * Null string entries will return null output string entries.
 *
 * The starts and stops column must both be the same integer type and
 * must be the same size as the strings column.
 *
 * <pre>{@code
 * s = ["hello", "goodbye"]
 * starts = [ 1, 2 ]
 * stops = [ 5, 4 ]
 * r = substring_from(s,starts,stops)
 * r is now ["ello","od"]
 * }</pre>
 *
 * @throws cudf::logic_error if starts or stops is a different size than the strings column.
 * @throws cudf::logic_error if starts and stops are not same integer type.
 * @throws cudf::logic_error if starts or stops contains nulls.
 *
 * @param strings Strings column for this operation.
 * @param starts First character positions to begin the substring.
 * @param stops Last character (exclusive) positions to end the substring.
 * @param mr Resource for allocating device memory.
 * @return New strings column with sorted elements of this instance.
 */
@Namespace("cudf::strings") public static native @UniquePtr column slice_strings( @Const @ByRef strings_column_view strings,
                                       @Const @ByRef column_view starts, @Const @ByRef column_view stops,
                                       device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::strings") public static native @UniquePtr column slice_strings( @Const @ByRef strings_column_view strings,
                                       @Const @ByRef column_view starts, @Const @ByRef column_view stops);

 // namespace strings
 // namespace cudf


// Parsed from <cudf/strings/contains.hpp>

/*
 * Copyright (c) 2019, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
// #pragma once

// #include <cudf/strings/strings_column_view.hpp>
// #include <cudf/column/column.hpp>

/**
 * \brief Returns a boolean column identifying rows which
 * match the given regex pattern.
 *
 * <pre>{@code
 * s = ["abc","123","def456"]
 * r = contains(s,"\\d+")
 * r is now [false, true, true]
 * }</pre>
 *
 * Any null string entries return corresponding null output column entries.
 *
 * @param strings Strings instance for this operation.
 * @param pattern Regex pattern to match to each string.
 * @param mr Resource for allocating device memory.
 * @return New column of boolean results for each string.
 */
@Namespace("cudf::strings") public static native @UniquePtr column contains_re( @Const @ByRef strings_column_view strings,
                                     @StdString BytePointer pattern,
                                     device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::strings") public static native @UniquePtr column contains_re( @Const @ByRef strings_column_view strings,
                                     @StdString BytePointer pattern);
@Namespace("cudf::strings") public static native @UniquePtr column contains_re( @Const @ByRef strings_column_view strings,
                                     @StdString String pattern,
                                     device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::strings") public static native @UniquePtr column contains_re( @Const @ByRef strings_column_view strings,
                                     @StdString String pattern);

/**
 * \brief Returns a boolean column identifying rows which
 * matching the given regex pattern but only at the beginning the string.
 *
 * <pre>{@code
 * s = ["abc","123","def456"]
 * r = contains(s,"\\d+")
 * r is now [false, true, false]
 * }</pre>
 *
 * Any null string entries return corresponding null output column entries.
 *
 * @param strings Strings instance for this operation.
 * @param pattern Regex pattern to match to each string.
 * @param mr Resource for allocating device memory.
 * @return New column of boolean results for each string.
 */
@Namespace("cudf::strings") public static native @UniquePtr column matches_re( @Const @ByRef strings_column_view strings,
                                    @StdString BytePointer pattern,
                                    device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::strings") public static native @UniquePtr column matches_re( @Const @ByRef strings_column_view strings,
                                    @StdString BytePointer pattern);
@Namespace("cudf::strings") public static native @UniquePtr column matches_re( @Const @ByRef strings_column_view strings,
                                    @StdString String pattern,
                                    device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::strings") public static native @UniquePtr column matches_re( @Const @ByRef strings_column_view strings,
                                    @StdString String pattern);

/**
 * \brief Returns the number of times the given regex pattern
 * matches in each string.
 *
 * <pre>{@code
 * s = ["abc","123","def45"]
 * r = contains(s,"\\d")
 * r is now [0, 3, 2]
 * }</pre>
 *
 * Any null string entries return corresponding null output column entries.
 *
 * @param strings Strings instance for this operation.
 * @param pattern Regex pattern to match within each string.
 * @param mr Resource for allocating device memory.
 * @return New INT32 column with counts for each string.
 */
@Namespace("cudf::strings") public static native @UniquePtr column count_re( @Const @ByRef strings_column_view strings,
                                  @StdString BytePointer pattern,
                                  device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::strings") public static native @UniquePtr column count_re( @Const @ByRef strings_column_view strings,
                                  @StdString BytePointer pattern);
@Namespace("cudf::strings") public static native @UniquePtr column count_re( @Const @ByRef strings_column_view strings,
                                  @StdString String pattern,
                                  device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::strings") public static native @UniquePtr column count_re( @Const @ByRef strings_column_view strings,
                                  @StdString String pattern);

 // namespace strings
 // namespace cudf


// Parsed from <cudf/strings/string_view.cuh>

/*
 * Copyright (c) 2019, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
// #pragma once

// #include <cstddef>
// #include <cuda_runtime.h>
// #include <cudf/types.hpp>
// #include <iterator>

/**
 * \file string_view.cuh
 * \brief Class definition for cudf::string_view.
 */

// UTF-8 characters are 1-4 bytes
// Targeting ../string_view.java


/**
 * \brief Returns the number of bytes in the specified character.
 *
 * @param chr Single character
 */
@Namespace("cudf::strings::detail") public static native @ByVal __host__ bytes_in_char_utf8( @Cast("cudf::char_utf8") int character );

/**
 * \brief Convert a char array into a char_utf8 value.
 *
 * @param str String containing encoded char bytes.
 * @param chr [out] Single char_utf8 value.
 * @return The number of bytes in the character
 */
@Namespace("cudf::strings::detail") public static native @ByVal __host__ to_char_utf8( @Cast("const char*") BytePointer str, @Cast("cudf::char_utf8*") @ByRef IntPointer character );
@Namespace("cudf::strings::detail") public static native @ByVal __host__ to_char_utf8( String str, @Cast("cudf::char_utf8*") @ByRef IntBuffer character );
@Namespace("cudf::strings::detail") public static native @ByVal __host__ to_char_utf8( @Cast("const char*") BytePointer str, @Cast("cudf::char_utf8*") @ByRef int[] character );
@Namespace("cudf::strings::detail") public static native @ByVal __host__ to_char_utf8( String str, @Cast("cudf::char_utf8*") @ByRef IntPointer character );
@Namespace("cudf::strings::detail") public static native @ByVal __host__ to_char_utf8( @Cast("const char*") BytePointer str, @Cast("cudf::char_utf8*") @ByRef IntBuffer character );
@Namespace("cudf::strings::detail") public static native @ByVal __host__ to_char_utf8( String str, @Cast("cudf::char_utf8*") @ByRef int[] character );

/**
 * \brief Place a char_utf8 value into a char array.
 *
 * @param chr Single character
 * @param str [out] Allocated char array with enough space to hold the encoded characer.
 * @return The number of bytes in the character
 */
@Namespace("cudf::strings::detail") public static native @ByVal __host__ from_char_utf8( @Cast("cudf::char_utf8") int character, @Cast("char*") BytePointer str );
@Namespace("cudf::strings::detail") public static native @ByVal __host__ from_char_utf8( @Cast("cudf::char_utf8") int character, @Cast("char*") ByteBuffer str );
@Namespace("cudf::strings::detail") public static native @ByVal __host__ from_char_utf8( @Cast("cudf::char_utf8") int character, @Cast("char*") byte[] str );

/**
 * \brief Return the number of UTF-8 characters in this provided char array.
 *
 * @param str String with encoded char bytes.
 * @param bytes Number of bytes in str.
 * @return The number of characters in the array.
 */
@Namespace("cudf::strings::detail") public static native @ByVal __host__ characters_in_string( @Cast("const char*") BytePointer str, @ByVal size_type bytes );
@Namespace("cudf::strings::detail") public static native @ByVal __host__ characters_in_string( String str, @ByVal size_type bytes );

 // namespace detail
 // namespace strings
 // namespace cudf

// #include "./string_view.inl"


// Parsed from <cudf/strings/detail/fill.hpp>

/*
 * Copyright (c) 2019, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
// #pragma once

// #include <cudf/strings/strings_column_view.hpp>
// #include <cudf/column/column.hpp>
// #include <cudf/table/table_view.hpp>

/**
 * \brief Returns a strings column replacing a range of rows
 * with the specified string.
 *
 * If the value parameter is invalid, the specified rows are filled with
 * null entries.
 *
 * @throws cudf::logic_error if [begin,end) is outside the range of the input column.
 *
 * @param strings Strings column to fill.
 * @param begin First row index to include the new string.
 * @param end Last row index (exclusive).
 * @param value String to use when filling the range.
 * @param mr Resource for allocating device memory.
 * @param stream CUDA stream to use for any kernels in this function.
 * @return New strings column.
 */
@Namespace("cudf::strings::detail") public static native @UniquePtr @Name("fill") column _fill( @Const @ByRef strings_column_view strings,
                              @ByVal size_type begin, @ByVal size_type end,
                              @Const @ByRef string_scalar value,
                              device_memory_resource mr/*=rmm::mr::get_default_resource()*/,
                              @ByVal(nullValue = "cudaStream_t(0)") cudaStream_t stream );
@Namespace("cudf::strings::detail") public static native @UniquePtr @Name("fill") column _fill( @Const @ByRef strings_column_view strings,
                              @ByVal size_type begin, @ByVal size_type end,
                              @Const @ByRef string_scalar value );

 // namespace detail
 // namespace strings
 // namespace cudf


// Parsed from <cudf/strings/detail/utilities.cuh>

/*
 * Copyright (c) 2019, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
// #pragma once

// #include <cuda_runtime.h>
// #include <cudf/column/column.hpp>
// #include <cudf/column/column_factories.hpp>

// #include <thrust/scan.h>
// #include <rmm/thrust_rmm_allocator.h>

/**
 * \brief Create an offsets column to be a child of a strings column.
 * This will set the offsets values by executing scan on the provided
 * Iterator.
 *
 * \tparam Iterator Used as input to scan to set the offset values.
 * @param begin The beginning of the input sequence
 * @param end The end of the input sequence
 * @param mr Memory resource to use.
 * @param stream Stream to use for any kernel calls.
 * @return offsets child column for strings column
 */

 // namespace detail
 // namespace strings
 // namespace cudf


// Parsed from <cudf/strings/detail/merge.cuh>

/*
 * Copyright (c) 2019, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

// #include <cudf/null_mask.hpp>
// #include <cudf/column/column.hpp>
// #include <cudf/column/column_factories.hpp>
// #include <cudf/column/column_device_view.ch>
// #include <cudf/strings/string_view.ch>
// #include <cudf/strings/strings_column_view.hpp>
// #include <cudf/merge.hpp>
// #include <strings/utilities.hpp>
// #include <strings/utilities.ch>

/**
 * \brief Merges two strings columns.
 *
 * Caller must set the validity mask in the output column.
 *
 * \tparam row_order_iterator This must be an iterator for type thrust::tuple<side,size_type>.
 * 
 * @param lhs First column.
 * @param rhs Second column.
 * @param row_order Indexes for each column.
 * @param mr Resource for allocating device memory.
 * @param stream CUDA stream to use for any kernels in this function.
 * @return New strings column.
 */

 // namespace detail
 // namespace strings
 // namespace cudf


// Parsed from <cudf/strings/detail/gather.cuh>

/*
 * Copyright (c) 2019, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
// #pragma once

// #include <cudf/detail/copy.hpp>
// #include <cudf/strings/strings_column_view.hpp>
// #include <cudf/column/column.hpp>
// #include <cudf/column/column_device_view.ch>
// #include <cudf/detail/valid_if.ch>
// #include <cudf/strings/detail/utilities.hpp>
// #include <cudf/strings/detail/utilities.ch>

/**
 * \brief Returns a new strings column using the specified indices to select
 * elements from the {@code strings} column.
 *
 * Caller must update the validity mask in the output column.
 *
 * <pre>{@code
 * s1 = ["a", "b", "c", "d", "e", "f"]
 * map = [0, 2]
 * s2 = gather<true>( s1, map.begin(), map.end() )
 * s2 is ["a", "c"]
 * }</pre>
 *
 * \tparam NullifyOutOfBounds If true, indices outside the column's range are nullified.
 * \tparam MapIterator Iterator for retrieving integer indices of the column.
 *
 * @param strings Strings instance for this operation.
 * @param begin Start of index iterator.
 * @param end End of index iterator.
 * @param mr Resource for allocating device memory.
 * @param stream CUDA stream to use kernels in this method.
 * @return New strings column containing the gathered strings.
 */

/**
 * \brief Returns a new strings column using the specified indices to select
 * elements from the {@code strings} column.
 *
 * Caller must update the validity mask in the output column.
 *
 * <pre>{@code
 * s1 = ["a", "b", "c", "d", "e", "f"]
 * map = [0, 2]
 * s2 = gather( s1, map.begin(), map.end(), true )
 * s2 is ["a", "c"]
 * }</pre>
 *
 * \tparam MapIterator Iterator for retrieving integer indices of the column.
 *
 * @param strings Strings instance for this operation.
 * @param begin Start of index iterator.
 * @param end End of index iterator.
 * @param nullify_out_of_bounds If true, indices outside the column's range are nullified.
 * @param mr Resource for allocating device memory.
 * @param stream CUDA stream to use kernels in this method.
 * @return New strings column containing the gathered strings.
 */


 // namespace detail
 // namespace strings
 // namespace cudf


// Parsed from <cudf/strings/detail/utilities.hpp>

/*
 * Copyright (c) 2019, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
// #pragma once

// #include <cuda_runtime.h>
// #include <cudf/column/column.hpp>
// #include <rmm/thrust_rmm_allocator.h>

/**
 * \brief Create a chars column to be a child of a strings column.
 * This will return the properly sized column to be filled in by the caller.
 *
 * @param strings_count Number of strings in the column.
 * @param null_count Number of null string entries in the column.
 * @param bytes Number of bytes for the chars column.
 * @param mr Memory resource to use.
 * @param stream Stream to use for any kernel calls.
 * @return The chars child column for a strings column.
 */
@Namespace("cudf::strings::detail") public static native @UniquePtr column create_chars_child_column( @ByVal size_type strings_count,
    @ByVal size_type null_count, @ByVal size_type bytes,
    device_memory_resource mr/*=rmm::mr::get_default_resource()*/,
    @ByVal(nullValue = "cudaStream_t(0)") cudaStream_t stream);
@Namespace("cudf::strings::detail") public static native @UniquePtr column create_chars_child_column( @ByVal size_type strings_count,
    @ByVal size_type null_count, @ByVal size_type bytes);

/**
 * \brief Create a strings column with no strings.
 *
 * @param mr Memory resource to use.
 * @param stream Stream to use for any kernel calls.
 * @return Empty strings column
 */
@Namespace("cudf::strings::detail") public static native @UniquePtr column make_empty_strings_column(
    device_memory_resource mr/*=rmm::mr::get_default_resource()*/,
    @ByVal(nullValue = "cudaStream_t(0)") cudaStream_t stream);
@Namespace("cudf::strings::detail") public static native @UniquePtr column make_empty_strings_column();

/**
 * \brief Creates a string_view vector from a strings column.
 *
 * @param strings Strings column instance.
 * @param stream Stream to execute any device code against.
 * @return Device vector of string_views
 */
@Namespace("cudf::strings::detail") public static native @ByVal RmmDeviceVectorStringView create_string_vector_from_column(
    @ByVal strings_column_view strings,
    @ByVal(nullValue = "cudaStream_t(0)") cudaStream_t stream );
@Namespace("cudf::strings::detail") public static native @ByVal RmmDeviceVectorStringView create_string_vector_from_column(
    @ByVal strings_column_view strings );

/**
 * \brief Creates an offsets column from a string_view vector.
 *
 * @param strings Strings column
 * @param mr Memory resource to use create the output column.
 * @param stream Stream to execute any device code against.
 * @return Child offsets column
 */
@Namespace("cudf::strings::detail") public static native @MoveUniquePtr column child_offsets_from_string_vector(
    @Const @ByRef RmmDeviceVectorStringView strings,
    device_memory_resource mr/*=rmm::mr::get_default_resource()*/,
    @ByVal(nullValue = "cudaStream_t(0)") cudaStream_t stream );
@Namespace("cudf::strings::detail") public static native @MoveUniquePtr column child_offsets_from_string_vector(
    @Const @ByRef RmmDeviceVectorStringView strings );

/**
 * \brief Creates a chars column from a string_view vector.
 *
 * @param strings Strings vector
 * @param d_offsets Offsets vector for placing strings into column's memory.
 * @param null_count Number of null strings.
 * @param mr Memory resource to use create the output column.
 * @param stream Stream to execute any device code against.
 * @return Child chars column
 */
@Namespace("cudf::strings::detail") public static native @MoveUniquePtr column child_chars_from_string_vector(
    @Const @ByRef RmmDeviceVectorStringView strings,
    @Const IntPointer d_offsets, @ByVal size_type null_count,
    device_memory_resource mr/*=rmm::mr::get_default_resource()*/,
    @ByVal(nullValue = "cudaStream_t(0)") cudaStream_t stream );
@Namespace("cudf::strings::detail") public static native @MoveUniquePtr column child_chars_from_string_vector(
    @Const @ByRef RmmDeviceVectorStringView strings,
    @Const IntPointer d_offsets, @ByVal size_type null_count );
@Namespace("cudf::strings::detail") public static native @MoveUniquePtr column child_chars_from_string_vector(
    @Const @ByRef RmmDeviceVectorStringView strings,
    @Const IntBuffer d_offsets, @ByVal size_type null_count,
    device_memory_resource mr/*=rmm::mr::get_default_resource()*/,
    @ByVal(nullValue = "cudaStream_t(0)") cudaStream_t stream );
@Namespace("cudf::strings::detail") public static native @MoveUniquePtr column child_chars_from_string_vector(
    @Const @ByRef RmmDeviceVectorStringView strings,
    @Const IntBuffer d_offsets, @ByVal size_type null_count );
@Namespace("cudf::strings::detail") public static native @MoveUniquePtr column child_chars_from_string_vector(
    @Const @ByRef RmmDeviceVectorStringView strings,
    @Const int[] d_offsets, @ByVal size_type null_count,
    device_memory_resource mr/*=rmm::mr::get_default_resource()*/,
    @ByVal(nullValue = "cudaStream_t(0)") cudaStream_t stream );
@Namespace("cudf::strings::detail") public static native @MoveUniquePtr column child_chars_from_string_vector(
    @Const @ByRef RmmDeviceVectorStringView strings,
    @Const int[] d_offsets, @ByVal size_type null_count );


 // namespace detail
 // namespace strings
 // namespace cudf


// Parsed from <cudf/strings/detail/copy_if_else.cuh>

/*
 * Copyright (c) 2019, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
// #pragma once

// #include <cudf/strings/strings_column_view.hpp>
// #include <cudf/column/column.hpp>
// #include <cudf/column/column_device_view.ch>
// #include <cudf/detail/valid_if.ch>
// #include <cudf/strings/detail/utilities.hpp>
// #include <cudf/strings/detail/utilities.ch>

/**
 * \brief Returns a new strings column using the specified Filter to select
 * strings from the lhs iterator or the rhs iterator.
 *
 * <pre>{@code
 * output[i] = filter_fn(i) ? lhs(i).first : rhs(i).first
 * }</pre>
 *
 * \tparam StringPairIterLeft Pair iterator returning thrust::pair<string_view,bool> where the
 *         bool parameter specifies if the string_view is valid (true) or not (false).
 * \tparam StringPairIterRight Pair iterator returning thrust::pair<string_view,bool> where the
 *         bool parameter specifies if the string_view is valid (true) or not (false).
 * \tparam Filter Functor that takes an index and returns a boolean.
 *
 * @param lhs_begin Start of first set of data. Used when filter_fn returns true.
 * @param lhs_end End of first set of data.
 * @param rhs_begin Strings of second set of data. Used when filter_fn returns false.
 * @param filter_fn Called to determine which iterator (lhs or rhs) to retrieve an entry for a specific row.
 * @param mr Resource for allocating device memory.
 * @param stream CUDA stream to use kernels in this method.
 * @return New strings column.
 */

 // namespace detail
 // namespace strings
 // namespace cudf


// Parsed from <cudf/strings/detail/copy_range.cuh>

/*
 * Copyright (c) 2019, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
// #pragma once

// #include <cudf/types.hpp>
// #include <cudf/column/column_device_view.ch>
// #include <cudf/detail/valid_if.ch>
// #include <cudf/strings/strings_column_view.hpp>
// #include <cudf/strings/string_view.ch>
// #include <cudf/strings/detail/utilities.ch>
// #include <cudf/strings/detail/utilities.hpp>

// #include <thrust/for_each.h>
// #include <thrust/iterator/counting_iterator.h>
// #include <thrust/iterator/transform_iterator.h>



/**
 * \brief Internal API to copy a range of string elements out-of-place from
 * source iterators to a target column.
 *
 * Creates a new column as if an in-place copy was performed into \p target.
 * The elements indicated by the indices [\p target_begin, \p target_end) were
 * replaced with the elements retrieved from source iterators;
 * *(\p source_value_begin + idx) if *(\p source_validity_begin + idx) is true,
 * invalidate otherwise (where idx = [0, \p target_end - \p target_begin)).
 * Elements outside the range are copied from \p target into the new target
 * column to return.
 *
 * @throws {@code cudf::logic_error} for invalid range (if \p target_begin < 0,
 * target_begin >= \p target.size(), or \p target_end > \p target.size()).
 *
 * \tparam SourceValueIterator Iterator for retrieving source values
 * \tparam SourceValidityIterator Iterator for retrieving source validities
 * @param source_value_begin Start of source value iterator
 * @param source_validity_begin Start of source validity iterator
 * @param target The strings column to copy from outside the range.
 * @param target_begin The starting index of the target range (inclusive)
 * @param target_end The index of the last element in the target range
 * (exclusive)
 * @param mr Memory resource to allocate the result target column.
 * @param stream CUDA stream to run this function
 * @return std::unique_ptr<column> The result target column
 */

 // namespace detail
 // namespace strings
 // namespace cudf


// Parsed from <cudf/strings/detail/concatenate.hpp>

/*
 * Copyright (c) 2019, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
// #pragma once

// #include <cudf/strings/strings_column_view.hpp>
// #include <cudf/column/column.hpp>
// #include <cudf/table/table_view.hpp>

/**
 * \brief Returns a single column by vertically concatenating the given vector of
 * strings columns.
 *
 * The caller is required to fill in the validity mask in the output column.
 *
 * <pre>{@code
 * s1 = ['aa', 'bb', 'cc']
 * s2 = ['dd', 'ee']
 * r = concatenate_vertically([s1,s2])
 * r is now ['aa', 'bb', 'cc', 'dd', 'ee']
 * }</pre>
 *
 * @param strings_columns List of string columns to concatenate.
 * @param mr Resource for allocating device memory.
 * @param stream CUDA stream to use for any kernels in this function.
 * @return New column with concatenated results.
 */
@Namespace("cudf::strings::detail") public static native @UniquePtr column concatenate( @StdVector strings_column_view strings_columns,
                                     device_memory_resource mr/*=rmm::mr::get_default_resource()*/,
                                     @ByVal(nullValue = "cudaStream_t(0)") cudaStream_t stream );
@Namespace("cudf::strings::detail") public static native @UniquePtr column concatenate( @StdVector strings_column_view strings_columns );

 // namespace detail
 // namespace strings
 // namespace cudf


// Parsed from <cudf/strings/detail/scatter.cuh>

/*
 * Copyright (c) 2019, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
// #pragma once

// #include <cudf/strings/strings_column_view.hpp>
// #include <cudf/column/column.hpp>
// #include <cudf/column/column_device_view.ch>
// #include <cudf/strings/detail/utilities.hpp>
// #include <cudf/strings/detail/utilities.ch>

/**
 * \brief Scatters strings into a copy of the target column
 * according to a scatter map.
 *
 * The scatter is performed according to the scatter iterator such that row
 * {@code scatter_map[i]} of the output column is replaced by the source string.
 * All other rows of the output column equal corresponding rows of the target table.
 *
 * If the same index appears more than once in the scatter map, the result is
 * undefined.
 * 
 * The caller must update the null mask in the output column.
 *
 * \tparam SourceIterator must produce string_view objects
 * \tparam MapIterator must produce index values within the target column.
 *
 * @param source The iterator of source strings to scatter into the output column.
 * @param scatter_map Iterator of indices into the output column.
 * @param target The set of columns into which values from the source column
 *        are to be scattered.
 * @param mr The resource to use for all allocations
 * @param stream The stream to use for CUDA operations
 * @return New strings column.
 */


 // namespace detail
 // namespace strings
 // namespace cudf


// Parsed from <cudf/strings/findall.hpp>

/*
 * Copyright (c) 2019, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
// #pragma once

// #include <cudf/strings/strings_column_view.hpp>
// #include <cudf/table/table.hpp>

/**
 * \brief Returns a table of strings columns for each matching occurrence of the
 * regex pattern within each string.
 *
 * The number of output columns is determined by the string with the most
 * matches.
 *
 * Any null string entries return corresponding null output column entries.
 *
 * @param strings Strings instance for this operation.
 * @param pattern Regex pattern to match within each string.
 * @param mr Resource for allocating device memory.
 * @return New table of strings columns.
 */
@Namespace("cudf::strings") public static native @UniquePtr table findall_re( @Const @ByRef strings_column_view strings,
                                                 @StdString BytePointer pattern,
                                                 device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::strings") public static native @UniquePtr table findall_re( @Const @ByRef strings_column_view strings,
                                                 @StdString BytePointer pattern);
@Namespace("cudf::strings") public static native @UniquePtr table findall_re( @Const @ByRef strings_column_view strings,
                                                 @StdString String pattern,
                                                 device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::strings") public static native @UniquePtr table findall_re( @Const @ByRef strings_column_view strings,
                                                 @StdString String pattern);

 // namespace strings
 // namespace cudf


// Parsed from <cudf/strings/padding.hpp>

/*
 * Copyright (c) 2019, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
// #pragma once

// #include <cudf/column/column.hpp>
// #include <cudf/strings/strings_column_view.hpp>
// #include <cudf/scalar/scalar.hpp>

/**
 * \brief Pad types for the pad method specify where the pad
 * character should be placed.
 */
/** enum class cudf::strings::pad_side */
public static final int
    /** Add padding to the left. */
    left = 0,
    /** Add padding to the right. */
    right = 1,
    /** Add padding equally to the right and left. */
    both = 2;

/**
 * \brief Add padding to each string using a provided character.
 *
 * If the string is already width or more characters, no padding is performed.
 * No strings are truncated.
 *
 * Null string entries result in null entries in the output column.
 *
 * <pre>{@code
 * s = ['aa','bbb','cccc','ddddd']
 * r = pad(s,4)
 * r is now ['aa  ','bbb ','cccc','ddddd']
 * }</pre>
 *
 * @param strings Strings instance for this operation.
 * @param width The minimum number of characters for each string.
 * @param side Where to place the padding characters.
 *        Default is pad right (left justify).
 * @param fill_char Single UTF-8 character to use for padding.
 *        Default is the space character.
 * @return New column with padded strings.
 */
@Namespace("cudf::strings") public static native @UniquePtr column pad( @Const @ByRef strings_column_view strings,
                             @ByVal size_type width, @Cast("cudf::strings::pad_side") int side/*=cudf::strings::pad_side::right*/,
                             @StdString BytePointer fill_char/*=" "*/,
                             device_memory_resource mr/*=rmm::mr::get_default_resource()*/ );
@Namespace("cudf::strings") public static native @UniquePtr column pad( @Const @ByRef strings_column_view strings,
                             @ByVal size_type width );
@Namespace("cudf::strings") public static native @UniquePtr column pad( @Const @ByRef strings_column_view strings,
                             @ByVal size_type width, @Cast("cudf::strings::pad_side") int side/*=cudf::strings::pad_side::right*/,
                             @StdString String fill_char/*=" "*/,
                             device_memory_resource mr/*=rmm::mr::get_default_resource()*/ );

/**
 * \brief Add '0' as padding to the left of each string.
 *
 * If the string is already width or more characters, no padding is performed.
 * No strings are truncated.
 *
 * This will skip any leading '+' or '-' character encountered in each string.
 *
 * Null string entries result in null entries in the output column.
 *
 * <pre>{@code
 * s = ['1234','-9876','+0.34','-342567']
 * r = zfill(s,6)
 * r is now ['001234','-09876','+00.34','-342567']
 * }</pre>
 *
 * @param strings Strings instance for this operation.
 * @param width The minimum number of characters for each string.
 * @return New column of strings.
 */
@Namespace("cudf::strings") public static native @UniquePtr column zfill( @Const @ByRef strings_column_view strings,
                               @ByVal size_type width,
                               device_memory_resource mr/*=rmm::mr::get_default_resource()*/ );
@Namespace("cudf::strings") public static native @UniquePtr column zfill( @Const @ByRef strings_column_view strings,
                               @ByVal size_type width );

 // namespace strings
 // namespace cudf


// Parsed from <cudf/strings/split/partition.hpp>

/*
 * Copyright (c) 2019, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
// #pragma once

// #include <cudf/strings/strings_column_view.hpp>
// #include <cudf/scalar/scalar.hpp>
// #include <cudf/table/table.hpp>

/**
 * \brief Returns a set of 3 columns by splitting each string using the
 * specified delimiter.
 *
 * The number of rows in the output columns will be the same as the
 * input column. The first column will contain the first tokens of
 * each string as a result of the split. The second column will contain
 * the delimiter. The third column will contain the remaining characters
 * of each string after the delimiter.
 *
 * Any null string entries return corresponding null output columns.
 *
 * <pre>{@code
 * s = ["ab_cd","def_g_h"]
 * r = rpartition(s,"_")
 * r[0] is ["ab","def"]
 * r[1] is ["_","_"]
 * r[2] is ["cd","g_h"]
 * }</pre>
 *
 * @param strings Strings instance for this operation.
 * @param delimiter UTF-8 encoded string indentifying where to split each string.
 *        Default of empty string indicates split on whitespace.
 * @param mr Resource for allocating device memory.
 * @return New table of strings columns.
 */
@Namespace("cudf::strings") public static native @UniquePtr table partition( @Const @ByRef strings_column_view strings,
                                                @Const @ByRef(nullValue = "cudf::string_scalar(\"\")") string_scalar delimiter,
                                                device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::strings") public static native @UniquePtr table partition( @Const @ByRef strings_column_view strings);

/**
 * \brief Returns a set of 3 columns by splitting each string using the
 * specified delimiter starting from the end of each string.
 *
 * The number of rows in the output columns will be the same as the
 * input column. The first column will contain the characters of
 * each string before the last delimiter found. The second column will contain
 * the delimiter. The third column will contain the remaining characters
 * of each string after the delimiter.
 *
 * Any null string entries return corresponding null output columns.
 *
 * <pre>{@code
 * s = ["ab_cd","def_g_h"]
 * r = rpartition(s,"_")
 * r[0] is ["ab","def_g"]
 * r[1] is ["_","_"]
 * r[2] is ["cd","h"]
 * }</pre>
 *
 * @param strings Strings instance for this operation.
 * @param delimiter UTF-8 encoded string indentifying where to split each string.
 *        Default of empty string indicates split on whitespace.
 * @param mr Resource for allocating device memory.
 * @return New strings columns.
 */
@Namespace("cudf::strings") public static native @UniquePtr table rpartition( @Const @ByRef strings_column_view strings,
                                                 @Const @ByRef(nullValue = "cudf::string_scalar(\"\")") string_scalar delimiter,
                                                 device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::strings") public static native @UniquePtr table rpartition( @Const @ByRef strings_column_view strings);

 // namespace strings
 // namespace cudf


// Parsed from <cudf/strings/split/split.hpp>

/*
 * Copyright (c) 2019, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
// #pragma once

// #include <cudf/strings/strings_column_view.hpp>
// #include <cudf/scalar/scalar.hpp>
// #include <cudf/table/table.hpp>

/**
 * \brief Returns a list of columns by splitting each string using the
 * specified delimiter.
 *
 * The number of rows in the output columns will be the same as the
 * input column. The first column will contain the first tokens of
 * each string as a result of the split. Subsequent columns contain
 * the next token strings. Null entries are added for a row where
 * split results have been exhausted. The total number of columns
 * will equal the maximum number of splits encountered on any string
 * in the input column.
 *
 * Any null string entries return corresponding null output columns.
 *
 * @param strings Strings instance for this operation.
 * @param delimiter UTF-8 encoded string indentifying the split points in each string.
 *        Default of empty string indicates split on whitespace.
 * @param maxsplit Maximum number of splits to perform.
 *        Default of -1 indicates all possible splits on each string.
 * @param mr Resource for allocating device memory.
 * @return New table of strings columns.
 */
@Namespace("cudf::strings") public static native @UniquePtr table split( @Const @ByRef strings_column_view strings,
                                            @Const @ByRef(nullValue = "cudf::string_scalar(\"\")") string_scalar delimiter,
                                            @ByVal(nullValue = "size_type(-1)") size_type maxsplit,
                                            device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::strings") public static native @UniquePtr table split( @Const @ByRef strings_column_view strings);

/**
 * \brief Returns a list of columns by splitting each string using the
 * specified delimiter starting from the end of each string.
 *
 * The number of rows in the output columns will be the same as the
 * input column. The first column will contain the first tokens encountered
 * in each string as a result of the split. Subsequent columns contain
 * the next token strings. Null entries are added for a row where
 * split results have been exhausted. The total number of columns
 * will equal the maximum number of splits encountered on any string
 * in the input column.
 *
 * Any null string entries return corresponding null output columns.
 *
 * @param strings Strings instance for this operation.
 * @param delimiter UTF-8 encoded string indentifying the split points in each string.
 *        Default of empty string indicates split on whitespace.
 * @param maxsplit Maximum number of splits to perform.
 *        Default of -1 indicates all possible splits on each string.
 * @param mr Resource for allocating device memory.
 * @return New strings columns.
 */
@Namespace("cudf::strings") public static native @UniquePtr table rsplit( @Const @ByRef strings_column_view strings,
                                             @Const @ByRef(nullValue = "cudf::string_scalar(\"\")") string_scalar delimiter,
                                             @ByVal(nullValue = "size_type(-1)") size_type maxsplit,
                                             device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::strings") public static native @UniquePtr table rsplit( @Const @ByRef strings_column_view strings);

 // namespace strings
 // namespace cudf


// Parsed from <cudf/strings/sorting.hpp>

/*
 * Copyright (c) 2019, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
// #pragma once

// #include <cudf/strings/strings_column_view.hpp>
// #include <cudf/column/column.hpp>

/**---------------------------------------------------------------------------*
 * \brief Sort types for the sort method.
 *---------------------------------------------------------------------------**/
/** enum cudf::strings::detail::sort_type */
public static final int
    /** no sorting */
    none = 0,
    /** sort by string length */
    length = 1,
    /** sort by characters code-points */
    name = 2;

/**---------------------------------------------------------------------------*
 * \brief Returns a new strings column that is a sorted version of the
 * strings in this instance.
 *
 * @param strings Strings instance for this operation.
 * @param stype Specify what attribute of the string to sort on.
 * @param order Sort strings in ascending or descending order.
 * @param null_order Sort nulls to the beginning or the end of the new column.
 * @param stream CUDA stream to use kernels in this method.
 * @param mr Resource for allocating device memory.
 * @return New strings column with sorted elements of this instance.
 *---------------------------------------------------------------------------**/
@Namespace("cudf::strings::detail") public static native @MoveUniquePtr column sort( @ByVal strings_column_view strings,
                                    @Cast("cudf::strings::detail::sort_type") int stype,
                                    @ByVal(nullValue = "cudf::order::ASCENDING") order order,
                                    @ByVal(nullValue = "cudf::null_order::BEFORE") null_order null_order,
                                    @ByVal(nullValue = "cudaStream_t(0)") cudaStream_t stream,
                                    device_memory_resource mr/*=rmm::mr::get_default_resource()*/ );
@Namespace("cudf::strings::detail") public static native @MoveUniquePtr column sort( @ByVal strings_column_view strings,
                                    @Cast("cudf::strings::detail::sort_type") int stype );



 // namespace detail
 // namespace strings
 // namespace cudf


// Parsed from <cudf/strings/extract.hpp>

/*
 * Copyright (c) 2019, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
// #pragma once

// #include <cudf/strings/strings_column_view.hpp>
// #include <cudf/table/table.hpp>

/**
 * \brief Returns a vector of strings columns for each matching group specified in the given regular expression pattern.
 *
 * All the strings for the first group will go in the first output column; the second group
 * go in the second column and so on. Null entries are added if the string does match.
 *
 * Any null string entries return corresponding null output column entries.
 *
 * <pre>{@code
 * s = ["a1","b2","c3"]
 * r = extract(s,"([ab])(\\d)")
 * r is now [["a","b",null],
 *           ["1","2",null]]
 * }</pre>
 *
 * @param strings Strings instance for this operation.
 * @param pattern The regular expression pattern with group indicators.
 * @param mr Resource for allocating device memory.
 * @return Columns of strings extracted from the input column.
 */
@Namespace("cudf::strings") public static native @UniquePtr table extract( @Const @ByRef strings_column_view strings,
                                              @StdString BytePointer pattern,
                                              device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::strings") public static native @UniquePtr table extract( @Const @ByRef strings_column_view strings,
                                              @StdString BytePointer pattern);
@Namespace("cudf::strings") public static native @UniquePtr table extract( @Const @ByRef strings_column_view strings,
                                              @StdString String pattern,
                                              device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::strings") public static native @UniquePtr table extract( @Const @ByRef strings_column_view strings,
                                              @StdString String pattern);


 // namespace strings
 // namespace cudf


// Parsed from <cudf/strings/find.hpp>

/*
 * Copyright (c) 2019, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
// #pragma once

// #include <cudf/strings/strings_column_view.hpp>
// #include <cudf/column/column.hpp>
// #include <cudf/scalar/scalar.hpp>

/**
 * \brief Returns a column of character position values where the target
 * string is first found in each string of the provided column.
 *
 * If the string is not found, -1 is returned for that row entry.
 *
 * The target string is searched within each string in the character
 * position range [start,stop). If the stop parameter is -1, then the
 * end of each string becomes the final position to include in the search.
 *
 * Any null string entries return corresponding null output column entries.
 *
 * @throws cudf::logic_error if start position is greater than stop position.
 *
 * @param strings Strings instance for this operation.
 * @param target UTF-8 encoded string to search for in each string.
 * @param start First character position to include in the search.
 * @param stop Last position (exclusive) to include in the search.
 *             Default of -1 will search to the end of the string.
 * @param mr Resource for allocating device memory.
 * @return New integer column with character position values.
 */
@Namespace("cudf::strings") public static native @UniquePtr column find( @Const @ByRef strings_column_view strings,
                              @Const @ByRef string_scalar target,
                              @ByVal(nullValue = "size_type(0)") size_type start, @ByVal(nullValue = "size_type(-1)") size_type stop,
                              device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::strings") public static native @UniquePtr column find( @Const @ByRef strings_column_view strings,
                              @Const @ByRef string_scalar target);

/**
 * \brief Returns a column of character position values where the target
 * string is first found searching from the end of each string.
 *
 * If the string is not found, -1 is returned for that entry.
 *
 * The target string is searched within each string in the character
 * position range [start,stop). If the stop parameter is -1, then the
 * end of each string becomes the final position to include in the search.
 *
 * Any null string entries return corresponding null output column entries.
 *
 * @throws cudf::logic_error if start position is greater than stop position.
 *
 * @param strings Strings instance for this operation.
 * @param target UTF-8 encoded string to search for in each string.
 * @param start First position to include in the search.
 * @param stop Last position (exclusive) to include in the search.
 *             Default of -1 will search starting at the end of the string.
 * @param mr Resource for allocating device memory.
 * @return New integer column with character position values.
 */
@Namespace("cudf::strings") public static native @UniquePtr column rfind( @Const @ByRef strings_column_view strings,
                               @Const @ByRef string_scalar target,
                               @ByVal(nullValue = "size_type(0)") size_type start, @ByVal(nullValue = "size_type(-1)") size_type stop,
                               device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::strings") public static native @UniquePtr column rfind( @Const @ByRef strings_column_view strings,
                               @Const @ByRef string_scalar target);
/**
 * \brief Returns a column of boolean values for each string where true indicates
 * the target string was found within that string in the provided column.
 *
 * If a target string is not found, false is returned for that entry for that column.
 *
 * Any null string entries return corresponding null entries in the output columns.
 *
 * @param strings Strings instance for this operation.
 * @param target UTF-8 encoded string to search for in each string.
 * @param mr Resource for allocating device memory.
 * @return New BOOL8 column.
 */
@Namespace("cudf::strings") public static native @UniquePtr column contains( @Const @ByRef strings_column_view strings,
                                  @Const @ByRef string_scalar target,
                                  device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::strings") public static native @UniquePtr column contains( @Const @ByRef strings_column_view strings,
                                  @Const @ByRef string_scalar target);

/**
 * \brief Returns a column of boolean values for each string where true indicates
 * the target string was found at the beginning of that string in the provided column.
 *
 * If a target string is not found at the beginning of the string, false is set for
 * that row entry in the output column.
 *
 * Any null string entries return corresponding null entries in the output columns.
 *
 * @param strings Strings instance for this operation.
 * @param target UTF-8 encoded string to search for in each string.
 * @param mr Resource for allocating device memory.
 * @return New BOOL8 column.
 */
@Namespace("cudf::strings") public static native @UniquePtr column starts_with( @Const @ByRef strings_column_view strings,
                                     @Const @ByRef string_scalar target,
                                     device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::strings") public static native @UniquePtr column starts_with( @Const @ByRef strings_column_view strings,
                                     @Const @ByRef string_scalar target);

/**
 * \brief Returns a column of boolean values for each string where true indicates
 * the target string was found at the end of that string in the provided column.
 *
 * If a target string is not found at the end of the string, false is set for
 * that row entry in the output column.
 *
 * Any null string entries return corresponding null entries in the output columns.
 *
 * @param strings Strings instance for this operation.
 * @param target UTF-8 encoded string to search for in each string.
 * @param mr Resource for allocating device memory.
 * @return New BOOL8 column.
 */
@Namespace("cudf::strings") public static native @UniquePtr column ends_with( @Const @ByRef strings_column_view strings,
                                   @Const @ByRef string_scalar target,
                                   device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::strings") public static native @UniquePtr column ends_with( @Const @ByRef strings_column_view strings,
                                   @Const @ByRef string_scalar target);

 // namespace strings
 // namespace cudf


// Parsed from <cudf/strings/case.hpp>

/*
 * Copyright (c) 2019, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
// #pragma once

// #include <cudf/strings/strings_column_view.hpp>
// #include <cudf/column/column.hpp>

/**
 * \brief Converts a column of strings to lower case.
 *
 * Only upper case alphabetical characters are converted. All other characters are copied.
 * Case conversion may result in strings that are longer or shorter than the
 * original string in bytes.
 *
 * Any null entries create null entries in the output column.
 *
 * @param strings Strings instance for this operation.
 * @param mr Resource for allocating device memory.
 * @return New column of strings with characters converted.
 */
@Namespace("cudf::strings") public static native @UniquePtr column to_lower( @Const @ByRef strings_column_view strings,
                                  device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::strings") public static native @UniquePtr column to_lower( @Const @ByRef strings_column_view strings);

/**
 * \brief Converts a column of strings to upper case.
 *
 * Only lower case alphabetical characters are converted. All other characters are copied.
 * Case conversion may result in strings that are longer or shorter than the
 * original string in bytes.
 *
 * Any null entries create null entries in the output column.
 *
 * @param strings Strings instance for this operation.
 * @param mr Resource for allocating device memory.
 * @return New column of strings with characters converted.
 */
@Namespace("cudf::strings") public static native @UniquePtr column to_upper( @Const @ByRef strings_column_view strings,
                                  device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::strings") public static native @UniquePtr column to_upper( @Const @ByRef strings_column_view strings);

/**
 * \brief Returns a column of strings converting lower case characters to
 * upper case and vice versa.
 *
 * Only upper or lower case alphabetical characters are converted. All other characters are copied.
 * Case conversion may result in strings that are longer or shorter than the
 * original string in bytes.
 *
 * Any null entries create null entries in the output column.
 *
 * @param strings Strings instance for this operation.
 * @param mr Resource for allocating device memory.
 * @return New column of strings with characters converted.
 */
@Namespace("cudf::strings") public static native @UniquePtr column swapcase( @Const @ByRef strings_column_view strings,
                                  device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::strings") public static native @UniquePtr column swapcase( @Const @ByRef strings_column_view strings);

 // namespace strings
 // namespace cudf


// Parsed from <cudf/strings/attributes.hpp>

/*
 * Copyright (c) 2019, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
// #pragma once

// #include <cudf/strings/strings_column_view.hpp>
// #include <cudf/column/column.hpp>

/**
 * \brief Returns an integer numeric column containing the length of each string in
 * characters.
 *
 * The output column will have the same number of rows as the
 * specified strings column. Each row value will be the number of
 * characters in the corresponding string.
 *
 * Any null string will result in a null entry for that row in the output column.
 *
 * @param strings Strings instance for this operation.
 * @param mr Resource for allocating device memory.
 * @return New INT32 column with lengths for each string.
 */
@Namespace("cudf::strings") public static native @UniquePtr column count_characters( @Const @ByRef strings_column_view strings,
                                          device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::strings") public static native @UniquePtr column count_characters( @Const @ByRef strings_column_view strings);

/**
 * \brief Returns a numeric column containing the length of each string in
 * bytes.
 *
 * The output column will have the same number of rows as the
 * specified strings column. Each row value will be the number of
 * bytes in the corresponding string.
 *
 * Any null string will result in a null entry for that row in the output column.
 *
 * @param strings Strings instance for this operation.
 * @param mr Resource for allocating device memory.
 * @return New INT32 column with the number of bytes for each string.
 */
@Namespace("cudf::strings") public static native @UniquePtr column count_bytes( @Const @ByRef strings_column_view strings,
                                     device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::strings") public static native @UniquePtr column count_bytes( @Const @ByRef strings_column_view strings);

/**
 * \brief Creates a numeric column with code point values (integers) for each
 * character of each string.
 *
 * A code point is the integer value representation of a character.
 * For example, the code point value for the character 'A' in UTF-8 is 65.
 *
 * The size of the output column will be the total number of characters in the
 * strings column.
 *
 * Any null string is ignored. No null entries will appear in the output column.
 *
 * @param strings Strings instance for this operation.
 * @param mr Resource for allocating device memory.
 * @return New INT32 column with code point integer values for each character.
 */
@Namespace("cudf::strings") public static native @UniquePtr column code_points( @Const @ByRef strings_column_view strings,
                                     device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::strings") public static native @UniquePtr column code_points( @Const @ByRef strings_column_view strings);

 // namespace strings
 // namespace cudf


// Parsed from <cudf/strings/convert/convert_floats.hpp>

/*
 * Copyright (c) 2019, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
// #pragma once

// #include <cudf/strings/strings_column_view.hpp>
// #include <cudf/column/column.hpp>

/**
 * \brief Returns a new numeric column by parsing float values from each string
 * in the provided strings column.
 *
 * Any null entries will result in corresponding null entries in the output column.
 *
 * Only characters [0-9] plus a prefix '-' and '+' and decimal '.' are recognized.
 * Additionally, scientific notation is also supported (e.g. "-1.78e+5").
 *
 * @throws cudf::logic_error if output_type is not float type.
 *
 * @param strings Strings instance for this operation.
 * @param output_type Type of float numeric column to return.
 * @param mr Resource for allocating device memory.
 * @return New column with floats converted from strings.
 */
@Namespace("cudf::strings") public static native @UniquePtr column to_floats( @Const @ByRef strings_column_view strings,
                                   @ByVal data_type output_type,
                                   device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::strings") public static native @UniquePtr column to_floats( @Const @ByRef strings_column_view strings,
                                   @ByVal data_type output_type);

/**
 * \brief Returns a new strings column converting the float values from the
 * provided column into strings.
 *
 * Any null entries will result in corresponding null entries in the output column.
 *
 * For each float, a string is created in base-10 decimal.
 * Negative numbers will include a '-' prefix.
 * Numbers producing more than 10 significant digits will produce a string that
 * includes scientific notation (e.g. "-1.78e+15").
 *
 * @throws cudf::logic_error if floats column is not float type.
 *
 * @param column Numeric column to convert.
 * @param mr Resource for allocating device memory.
 * @param stream Stream to use for any kernels in this function.
 * @return New strings column with floats as strings.
 */
@Namespace("cudf::strings") public static native @UniquePtr column from_floats( @Const @ByRef column_view floats,
                                     device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::strings") public static native @UniquePtr column from_floats( @Const @ByRef column_view floats);

 // namespace strings
 // namespace cudf


// Parsed from <cudf/strings/convert/convert_booleans.hpp>

/*
 * Copyright (c) 2019, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
// #pragma once

// #include <cudf/strings/strings_column_view.hpp>
// #include <cudf/column/column.hpp>
// #include <cudf/scalar/scalar.hpp>

/**
 * \brief Returns a new BOOL8 column by parsing boolean values from the strings
 * in the provided strings column.
 *
 * Any null entries will result in corresponding null entries in the output column.
 *
 * @param strings Strings instance for this operation.
 * @param true_string String to expect for true. Non-matching strings are false.
 * @param mr Resource for allocating device memory.
 * @return New BOOL8 column converted from strings.
 */
@Namespace("cudf::strings") public static native @UniquePtr column to_booleans( @Const @ByRef strings_column_view strings,
                                     @Const @ByRef(nullValue = "cudf::string_scalar(\"true\")") string_scalar true_string,
                                     device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::strings") public static native @UniquePtr column to_booleans( @Const @ByRef strings_column_view strings);

/**
 * \brief Returns a new strings column converting the boolean values from the
 * provided column into strings.
 *
 * Any null entries will result in corresponding null entries in the output column.
 *
 * @throws cudf::logic_error if the input column is not BOOL8 type.
 *
 * @param column Boolean column to convert.
 * @param true_string String to use for true in the output column.
 * @param false_string String to use for false in the output column.
 * @param mr Resource for allocating device memory.
 * @return New strings column.
 */
@Namespace("cudf::strings") public static native @UniquePtr column from_booleans( @Const @ByRef column_view booleans,
                                       @Const @ByRef(nullValue = "cudf::string_scalar(\"true\")") string_scalar true_string,
                                       @Const @ByRef(nullValue = "cudf::string_scalar(\"false\")") string_scalar false_string,
                                       device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::strings") public static native @UniquePtr column from_booleans( @Const @ByRef column_view booleans);

 // namespace strings
 // namespace cudf


// Parsed from <cudf/strings/convert/convert_integers.hpp>

/*
 * Copyright (c) 2019, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
// #pragma once

// #include <cudf/strings/strings_column_view.hpp>
// #include <cudf/column/column.hpp>

/**
 * \brief Returns a new integer numeric column parsing integer values from the
 * provided strings column.
 *
 * Any null entries will result in corresponding null entries in the output column.
 *
 * Only characters [0-9] plus a prefix '-' and '+' are recognized.
 * When any other character is encountered, the parsing ends for that string
 * and the current digits are converted into an integer.
 *
 * Overflow of the resulting integer type is not checked.
 * Each string is converted using an int64 type and then cast to the
 * target integer type before storing it into the output column.
 * If the resulting integer type is too small to hold the value,
 * the stored value will be undefined.
 *
 * @throws cudf::logic_error if output_type is not integral type.
 *
 * @param strings Strings instance for this operation.
 * @param output_type Type of integer numeric column to return.
 * @param mr Resource for allocating device memory.
 * @return New column with integers converted from strings.
 */
@Namespace("cudf::strings") public static native @UniquePtr column to_integers( @Const @ByRef strings_column_view strings,
                                     @ByVal data_type output_type,
                                     device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::strings") public static native @UniquePtr column to_integers( @Const @ByRef strings_column_view strings,
                                     @ByVal data_type output_type);

/**
 * \brief Returns a new strings column converting the integer values from the
 * provided column into strings.
 *
 * Any null entries will result in corresponding null entries in the output column.
 *
 * For each integer, a string is created in base-10 decimal.
 * Negative numbers will include a '-' prefix.
 *
 * @throws cudf::logic_error if integers column is not integral type.
 *
 * @param column Numeric column to convert.
 * @param mr Resource for allocating device memory.
 * @param stream Stream to use for any kernels in this function.
 * @return New strings column with integers as strings.
 */
@Namespace("cudf::strings") public static native @UniquePtr column from_integers( @Const @ByRef column_view integers,
                                       device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::strings") public static native @UniquePtr column from_integers( @Const @ByRef column_view integers);

/**
 * \brief Returns a new integer numeric column parsing hexadecimal values from the
 * provided strings column.
 *
 * Any null entries will result in corresponding null entries in the output column.
 *
 * Only characters [0-9] and [A-F] are recognized.
 * When any other character is encountered, the parsing ends for that string.
 * No interpretation is made on the sign of the integer.
 *
 * Overflow of the resulting integer type is not checked.
 * Each string is converted using an int64 type and then cast to the
 * target integer type before storing it into the output column.
 * If the resulting integer type is too small to hold the value,
 * the stored value will be undefined.
 *
 * @throws cudf::logic_error if output_type is not integral type.
 *
 * @param strings Strings instance for this operation.
 * @param output_type Type of integer numeric column to return.
 * @param mr Resource for allocating device memory.
 * @return New column with integers converted from strings.
 */
@Namespace("cudf::strings") public static native @UniquePtr column hex_to_integers( @Const @ByRef strings_column_view strings,
                                         @ByVal data_type output_type,
                                         device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::strings") public static native @UniquePtr column hex_to_integers( @Const @ByRef strings_column_view strings,
                                         @ByVal data_type output_type);

 // namespace strings
 // namespace cudf


// Parsed from <cudf/strings/convert/convert_urls.hpp>

/*
 * Copyright (c) 2019, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
// #pragma once

// #include <cudf/strings/strings_column_view.hpp>
// #include <cudf/column/column.hpp>

/**
 * \brief Decodes each string using URL encoding.
 *
 * Converts mostly non-ascii characters and control characters into UTF-8 hex code-points
 * prefixed with '%'. For example, the space character must be converted to characters '%20' where the
 * '20' indicates the hex value for space in UTF-8. Likewise, multi-byte characters are converted to
 * multiple hex charactes. For example, the é character is converted to characters '%C3%A9' where 'C3A9'
 * is the UTF-8 bytes 0xC3A9 for this character.
 *
 * Any null entries will result in corresponding null entries in the output column.
 *
 * @param strings Strings instance for this operation.
 * @param mr Resource for allocating device memory.
 * @return New strings column.
 */
@Namespace("cudf::strings") public static native @UniquePtr column url_encode( @Const @ByRef strings_column_view strings,
                                    device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::strings") public static native @UniquePtr column url_encode( @Const @ByRef strings_column_view strings);

/**
 * \brief Encodes each string using URL encoding.
 *
 * Converts all character sequences starting with '%' into character code-points
 * interpreting the 2 following characters as hex values to create the code-point.
 * For example, the sequence '%20' is converted into byte (0x20) which is a single
 * space character. Another example converts '%C3%A9' into 2 sequential bytes
 * (0xc3 and 0xa9 respectively). Overall, 3 characters are converted into one char byte
 * whenever a '%' character is encountered in the string.
 *
 * Any null entries will result in corresponding null entries in the output column.
 *
 * @param strings Strings instance for this operation.
 * @param mr Resource for allocating device memory.
 * @return New strings column.
 */
@Namespace("cudf::strings") public static native @UniquePtr column url_decode( @Const @ByRef strings_column_view strings,
                                    device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::strings") public static native @UniquePtr column url_decode( @Const @ByRef strings_column_view strings);

 // namespace strings
 // namespace cudf


// Parsed from <cudf/strings/convert/convert_datetime.hpp>

/*
 * Copyright (c) 2019, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
// #pragma once

// #include <cudf/strings/strings_column_view.hpp>
// #include <cudf/column/column.hpp>

/**
 * \brief Returns a new datetime column converting a string column into
 * timestamps using the provided format string.
 *
 * The format must include strptime format specifiers though only the
 * following are supported: %Y,%y,%m,%d,%H,%I,%p,%M,%S,%f,%z
 * Reference:  http://man7.org/linux/man-pages/man3/strptime.3.html
 *
 * No checking is done for invalid formats.
 * Negative timestamp are not currently supported. These would have
 * dates before 1970-01-01.
 *
 * Any null string entry will result in a null entry in the output column.
 *
 * @throws cudf::logic_error if timestamp_type is not a timestamp type.
 *
 * @param strings Strings instance for this operation.
 * @param timestamp_type The timestamp type used for creating the output column.
 * @param format String specifying the timestamp format in strings.
 * @param mr Resource for allocating device memory.
 * @return New datetime column.
 */
@Namespace("cudf::strings") public static native @UniquePtr column to_timestamps( @Const @ByRef strings_column_view strings,
                                       @ByVal data_type timestamp_type,
                                       @StdString BytePointer format,
                                       device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::strings") public static native @UniquePtr column to_timestamps( @Const @ByRef strings_column_view strings,
                                       @ByVal data_type timestamp_type,
                                       @StdString BytePointer format);
@Namespace("cudf::strings") public static native @UniquePtr column to_timestamps( @Const @ByRef strings_column_view strings,
                                       @ByVal data_type timestamp_type,
                                       @StdString String format,
                                       device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::strings") public static native @UniquePtr column to_timestamps( @Const @ByRef strings_column_view strings,
                                       @ByVal data_type timestamp_type,
                                       @StdString String format);


/**
 * \brief Returns a new strings column converting a datetime column into
 * strings using the provided format string.
 *
 * The format must include strftime format specifiers though only the
 * following are supported: %Y,%y,%m,%d,%H,%I,%p,%M,%S,%f,%z
 * Reference:  http://man7.org/linux/man-pages/man3/strftime.3.html
 *
 * No checking is done for invalid formats or invalid timestamp units.
 * Negative timestamp values are not currently supported.
 *
 * Any null input entry will result in a corresponding null entry in the output column.
 *
 * @throws cudf::logic_error if timestamps column parameter is not a timestamp type.
 *
 * @param timestamps Timestamp values to convert.
 * @param format The String specifying output format.
 *        Default format is "%Y-%m-%dT%H:%M:%SZ".
 * @param mr Resource for allocating device memory.
 * @return New strings column with formatted timestamps.
 */
@Namespace("cudf::strings") public static native @UniquePtr column from_timestamps( @Const @ByRef column_view timestamps,
                                         @StdString BytePointer format/*="%Y-%m-%dT%H:%M:%SZ"*/,
                                         device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::strings") public static native @UniquePtr column from_timestamps( @Const @ByRef column_view timestamps);
@Namespace("cudf::strings") public static native @UniquePtr column from_timestamps( @Const @ByRef column_view timestamps,
                                         @StdString String format/*="%Y-%m-%dT%H:%M:%SZ"*/,
                                         device_memory_resource mr/*=rmm::mr::get_default_resource()*/);


 // namespace strings
 // namespace cudf


// Parsed from <cudf/strings/convert/convert_ipv4.hpp>

/*
 * Copyright (c) 2019, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
// #pragma once

// #include <cudf/strings/strings_column_view.hpp>
// #include <cudf/column/column.hpp>

/**
 * \brief Converts IPv4 addresses into integers.
 *
 * The IPv4 format is 1-3 character digits [0-9] between 3 dots
 * (e.g. 123.45.67.890). Each section can have a value between [0-255].
 *
 * The four sets of digits are converted to integers and placed in 8-bit fields inside
 * the resulting integer.
 * <pre>{@code
 *   i0.i1.i2.i3 -> (i0 << 24) | (i1 << 16) | (i2 << 8) | (i3)
 * }</pre>
 *
 * No checking is done on the format. If a string is not in IPv4 format, the resulting
 * integer is undefined.
 *
 * The resulting 32-bit integer is placed in an int64_t to avoid setting the sign-bit
 * in a int32_t type. This could be changed if cudf supported a UINT32 type in the future.
 *
 * Any null entries will result in corresponding null entries in the output column.
 *
 * @param strings Strings instance for this operation.
 * @param mr Resource for allocating device memory.
 * @return New INT64 column converted from strings.
 */
@Namespace("cudf::strings") public static native @UniquePtr column ipv4_to_integers( @Const @ByRef strings_column_view strings,
                                          device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::strings") public static native @UniquePtr column ipv4_to_integers( @Const @ByRef strings_column_view strings);

/**
 * \brief Converts integers into IPv4 addresses as strings.
 *
 * The IPv4 format is 1-3 character digits [0-9] between 3 dots
 * (e.g. 123.45.67.890). Each section can have a value between [0-255].
 *
 * Each input integer is dissected into four integers by dividing the input into 8-bit sections.
 * These sub-integers are then converted into [0-9] characters and placed between '.' characters.
 *
 * No checking is done on the input integer value. Only the lower 32-bits are used.
 *
 * Any null entries will result in corresponding null entries in the output column.
 *
 * @throws cudf::logic_error if the input column is not INT64 type.
 *
 * @param column Integer (INT64) column to convert.
 * @param mr Resource for allocating device memory.
 * @return New strings column.
 */
@Namespace("cudf::strings") public static native @UniquePtr column integers_to_ipv4( @Const @ByRef column_view integers,
                                          device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::strings") public static native @UniquePtr column integers_to_ipv4( @Const @ByRef column_view integers);

 // namespace strings
 // namespace cudf


// Parsed from <cudf/groupby.hpp>

/*
 * Copyright (c) 2019, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

// #pragma once

// #include <cudf/aggregation.hpp>
// #include <cudf/table/table_view.hpp>
// #include <cudf/types.hpp>

// #include <utility>
// #include <vector>
    
 // namespace sort  

// Targeting ../aggregation_request.java


// Targeting ../aggregation_result.java


// Targeting ../groupby.java


  // namespace groupby
  // namespace experimental
  // namespace cudf


// Parsed from <cudf/dlpack.hpp>

/*
 * Copyright (c) 2019, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
// #pragma once

// #include <cudf/table/table.hpp>
// #include <cudf/table/table_view.hpp>
// Targeting ../DLManagedTensor.java



/**
 * \brief Convert a DLPack DLTensor into a cudf table
 *
 * The {@code device_type} of the DLTensor must be {@code kDLGPU}, {@code kDLCPU}, or
 * {@code kDLCPUPinned}, and {@code device_id} must match the current device. The {@code ndim}
 * must be set to 1 or 2. The {@code dtype} must have 1 lane and the bitsize must
 * match a supported {@code cudf::data_type}.
 *
 * \note The managed tensor is not deleted by this function.
 *
 * @throws cudf::logic_error if the any of the DLTensor fields are unsupported
 *
 * @param managed_tensor a 1D or 2D column-major (Fortran order) tensor
 * @param mr Optional resource to use for device memory allocation
 *
 * @return Table with a copy of the tensor data
 */
@Namespace("cudf") public static native @UniquePtr table from_dlpack(
    @Const DLManagedTensor managed_tensor,
    device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf") public static native @UniquePtr table from_dlpack(
    @Const DLManagedTensor managed_tensor);

/**
 * \brief Convert a cudf table into a DLPack DLTensor
 * 
 * All columns must have the same data type and this type must be numeric. The
 * columns may be nullable, but the null count must be zero. If the input table
 * is empty or has zero rows, the result will be nullptr.
 * 
 * \note The {@code deleter} method of the returned {@code DLManagedTensor} must be used to
 * free the memory allocated for the tensor.
 * 
 * @throws cudf::logic_error if the data types are not equal or not numeric,
 * or if any of columns have non-zero null count
 * 
 * @param input Table to convert to DLPack
 * @param mr Optional resource to use for device memory allocation
 * 
 * @return 1D or 2D DLPack tensor with a copy of the table data, or nullptr
 */
@Namespace("cudf") public static native DLManagedTensor to_dlpack(@Const @ByRef table_view input,
    device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf") public static native DLManagedTensor to_dlpack(@Const @ByRef table_view input);

  // namespace cudf


// Parsed from <cudf/detail/fill.hpp>

/*
 * Copyright (c) 2019, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

// #pragma once

// #include <cudf/filling.hpp>
// #include <cudf/types.hpp>
// #include <rmm/mr/device_memory_resource.hpp>

// #include <cuda_runtime.h>

// #include <memory>

/**---------------------------------------------------------------------------*
 * \brief Internal API to fill a range of elements in-place in a column with a
 * scalar value.
 * 
 * Fills N elements of \p destination starting at \p begin with \p value, where
 * N = (\p end - \p begin).
 *
 * Overwrites the range of elements in \p destination indicated by the indices
 * [\p begin, \p end) with \p value. Use the out-of-place fill function
 * returning std::unique_ptr<column> for use cases requiring memory
 * reallocation.
 *
 * @throws {@code cudf::logic_error} if memory reallocation is required (e.g. for
 * variable width types).
 * @throws {@code cudf::logic_error} for invalid range (if \p begin < 0,
 * \p begin > \p end, \p begin >= \p destination.size(), or
 * \p end > \p destination.size()).
 * @throws {@code cudf::logic_error} if \p destination and \p value have different
 * types.
 * @throws {@code cudf::logic_error} if \p value is invalid but \p destination is not
 * nullable.
 *
 * @param destination The preallocated column to fill into
 * @param begin The starting index of the fill range (inclusive)
 * @param end The index of the last element in the fill range (exclusive)
 * @param value The scalar value to fill
 * @param stream CUDA stream to run this function
 * @return void
 *---------------------------------------------------------------------------**/
@Namespace("cudf::experimental::detail") public static native @Name("fill") void _fill(@ByRef mutable_column_view destination, @ByVal size_type begin, @ByVal size_type end,
          @Const @ByRef scalar value, @ByVal(nullValue = "cudaStream_t(0)") cudaStream_t stream);
@Namespace("cudf::experimental::detail") public static native @Name("fill") void _fill(@ByRef mutable_column_view destination, @ByVal size_type begin, @ByVal size_type end,
          @Const @ByRef scalar value);

/**---------------------------------------------------------------------------*
 * \brief Internal API to fill a range of elements in a column out-of-place with
 a scalar value.
 * 
 * Creates a new column as-if an in-place fill was performed into \p input;
 * i.e. it is as if a copy of \p input was created first and then the elements
 * indicated by the indices [\p begin, \p end) were overwritten by \p value.
 *
 * @throws {@code cudf::logic_error} for invalid range (if \p begin < 0,
 * \p begin > \p end, \p begin >= \p destination.size(), or
 * \p end > \p destination.size()).
 * @throws {@code cudf::logic_error} if \p destination and \p value have different
 * types.
 *
 * @param input The input column used to create a new column. The new column
 * is created by replacing the values of \p input in the specified range with
 * \p value.
 * @param begin The starting index of the fill range (inclusive)
 * @param end The index of the last element in the fill range (exclusive)
 * @param value The scalar value to fill
 * @param mr Memory resource to allocate the result output column
 * @param stream CUDA stream to run this function
 * @return std::unique_ptr<column> The result output column
 *---------------------------------------------------------------------------**/
@Namespace("cudf::experimental::detail") public static native @UniquePtr @Name("fill") column _fill(
    @Const @ByRef column_view input, @ByVal size_type begin, @ByVal size_type end,
    @Const @ByRef scalar value,
    device_memory_resource mr/*=rmm::mr::get_default_resource()*/,
    @ByVal(nullValue = "cudaStream_t(0)") cudaStream_t stream);
@Namespace("cudf::experimental::detail") public static native @UniquePtr @Name("fill") column _fill(
    @Const @ByRef column_view input, @ByVal size_type begin, @ByVal size_type end,
    @Const @ByRef scalar value);
                            
  // namespace detail
  // namespace experimental
  // namespace cudf


// Parsed from <cudf/detail/replace.hpp>

/*
 * Copyright (c) 2018-2019, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

// #pragma once

// #include <cudf/types.hpp>
// #include <memory>

// Forward declaration

/**
 * \brief Replaces all null values in a column with corresponding values of another column
 *
 * {@code input} and {@code replacement} must be of the same type and size.
 * must be of the same type and same size as the first.
 *
 * @param input [in] A column whose null values will be replaced
 * @param replacement [in] A cudf::column whose values will replace null values in input
 * @param mr [in] A rmm::mr::device_memory_resource pointer to be used for allocations.
 * @param stream [in] Optional stream in which to perform allocations
 *
 * @return A copy of {@code input} with the null values replaced with corresponding values from {@code replacement}.
 */
@Namespace("cudf::detail") public static native @UniquePtr column replace_nulls(@Const @ByRef column_view input,
                                            @Const @ByRef column_view replacement,
                                            device_memory_resource mr/*=rmm::mr::get_default_resource()*/,
                                            @ByVal(nullValue = "cudaStream_t(0)") cudaStream_t stream);

/**
  * \brief Replaces all null values in a column with a scalar.
  *
  * {@code input} and {@code replacement} must have the same type.
  * a cudf::scalar of the same data type as the column.
  *
  *
  * @param input [in] A column whose null values will be replaced
  * @param replacement [in] Scalar used to replace null values in {@code input}.
  * @param mr [in] A rmm::mr::device_memory_resource pointer to be used for allocations.
  * @param stream [in] Optional stream in which to perform allocations
  *
  * @return Copy of {@code input} with null values replaced by {@code replacement}.
  */
@Namespace("cudf::detail") public static native @UniquePtr column replace_nulls(@Const @ByRef column_view input,
                                            @Const scalar replacement,
                                            device_memory_resource mr/*=rmm::mr::get_default_resource()*/,
                                            @ByVal(nullValue = "cudaStream_t(0)") cudaStream_t stream);

/**
 *  \brief Replace all {@code old_values[i]} present in {@code input_col} with {@code new_values[i]}.
 *        with {@code new_values[i]}.
 *
 * @param input_col The column to find and replace values in.
 * @param values_to_replace The values to replace
 * @param replacement_values The values to replace with
 * @param mr [in] A rmm::mr::device_memory_resource pointer to be used for allocations.
 * @param stream The CUDA stream to use for operations
 *
 * @return Copy of {@code input} with specified values replaced.
 */
@Namespace("cudf::detail") public static native @UniquePtr column find_and_replace_all(@Const @ByRef column_view input_col,
                                                   @Const @ByRef column_view values_to_replace,
                                                   @Const @ByRef column_view replacement_values,
                                                   device_memory_resource mr/*=rmm::mr::get_default_resource()*/,
                                                   @ByVal(nullValue = "cudaStream_t(0)") cudaStream_t stream);
  // namespace detail
 // namespace cudf


// Parsed from <cudf/detail/copy_if.cuh>

/*
 * Copyright (c) 2019, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

// #pragma once

// #include <cudf/types.hpp>
// #include <cudf/utilities/traits.hpp>
// #include <cudf/table/table.hpp>
// #include <cudf/table/table_view.hpp>
// #include <cudf/detail/copy.hpp>
// #include <cudf/detail/gather.ch>
// #include <cudf/detail/utilities/device_atomics.ch>
// #include <cudf/utilities/error.hpp>
// #include <cudf/utilities/type_dispatcher.hpp>
// #include <cudf/null_mask.hpp>
// #include <cudf/column/column_device_view.ch>
// #include <cudf/column/column_factories.hpp>
// #include <cudf/detail/utilities/cuda.ch>

// #include <rmm/device_buffer.hpp>
// #include <rmm/device_scalar.hpp>

// #include <cub/cub.ch>
// #include <algorithm>

// Compute the count of elements that pass the mask within each block

// Compute the exclusive prefix sum of each thread's mask value within each block
 // namespace
/**
 * \brief Filters {@code input} using a Filter function object
 * 
 * \p filter must be a functor or lambda with the following signature:
 * __device__ bool operator()(cudf::size_type i);
 * It will return true if element i of \p input should be copied, 
 * false otherwise.
 *
 * \tparam Filter the filter functor type
 * @param input [in] The table_view to filter
 * @param filter [in] A function object that takes an index and returns a bool
 * @return unique_ptr<table> The table generated from filtered {@code input}.
 */

// namespace detail
// namespace experimental
// namespace cudf


// Parsed from <cudf/detail/copy.hpp>

/*
 * Copyright (c) 2018-2019, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

// #pragma once 

// #include <cudf/types.hpp>
// #include <cudf/column/column_view.hpp>
// #include <cudf/utilities/traits.hpp>
// #include <cudf/copying.hpp>
/**---------------------------------------------------------------------------*
 * \brief Constructs a zero-copy {@code column_view}/{@code mutable_column_view} of the
 * elements in the range {@code [begin,end)} in {@code input}.
 *
 * \note It is the caller's responsibility to ensure that the returned view
 * does not outlive the viewed device memory.
 *
 * @throws cudf::logic_error if {@code begin < 0}, {@code end < begin} or
 * {@code end > input.size()}.
 *
 * @param input [in] View of input column to slice
 * @param begin [in] Index of the first desired element in the slice (inclusive).
 * @param end [in] Index of the last desired element in the slice (exclusive).
 *
 * @return ColumnView View of the elements {@code [begin,end)} from {@code input}.
 *---------------------------------------------------------------------------**/

/**
 * \copydoc cudf::experimental::slice(column_view const&,std::vector<size_type> const&)
 *
 * @param stream Optional CUDA stream on which to execute kernels
 */
@Namespace("cudf::experimental::detail") public static native @StdVector column_view slice(@Const @ByRef column_view input,
                               @StdVector size_type indices,
                               @ByVal(nullValue = "cudaStream_t(0)") cudaStream_t stream);

/**
 * \copydoc cudf::experimental::contiguous_split
 *
 * @param stream Optional CUDA stream on which to execute kernels
 **/
@Namespace("cudf::experimental::detail") public static native @StdVector contiguous_split_result contiguous_split(@Const @ByRef table_view input,
                                                      @StdVector size_type splits,
                                                      device_memory_resource mr/*=rmm::mr::get_default_resource()*/,
                                                      @ByVal(nullValue = "cudaStream_t(0)") cudaStream_t stream);

/**
 * \brief Creates an uninitialized new column of the specified size and same type as the {@code input}.
 * Supports only fixed-width types.
 *
 * @param input [in] Immutable view of input column to emulate
 * @param size [in] The desired number of elements that the new column should have capacity for
 * @param mask_alloc [in] Optional, Policy for allocating null mask. Defaults to RETAIN.
 * @param mr [in] Optional, The resource to use for all allocations
 * @param stream [in] Optional CUDA stream on which to execute kernels
 * @return std::unique_ptr<column> A column with sufficient uninitialized capacity to hold the specified number of elements as {@code input} of the same type as {@code input.type()}
 */
@Namespace("cudf::experimental::detail") public static native @UniquePtr column allocate_like(@Const @ByRef column_view input, @ByVal size_type size,
                                      @Cast("cudf::experimental::mask_allocation_policy") int mask_alloc/*=cudf::experimental::mask_allocation_policy::RETAIN*/,
                                      device_memory_resource mr/*=rmm::mr::get_default_resource()*/,
                                      @ByVal(nullValue = "cudaStream_t(0)") cudaStream_t stream);


/**
 * \brief   Returns a new column, where each element is selected from either \p lhs or 
 *          \p rhs based on the value of the corresponding element in \p boolean_mask
 *
 * Selects each element i in the output column from either \p rhs or \p lhs using the following rule:
 *          output[i] = (boolean_mask[i]) ? lhs[i] : rhs[i]
 *         
 * @throws cudf::logic_error if lhs and rhs are not of the same type
 * @throws cudf::logic_error if lhs and rhs are not of the same length
 * @throws cudf::logic_error if boolean mask is not of type bool8
 * @throws cudf::logic_error if boolean mask is not of the same length as lhs and rhs  
 * @param left [in] -hand column_view
 * @param right [in] -hand column_view
 * @param column_view [in] representing "left (true) / right (false)" boolean for each element
 * @param mr [in] resource for allocating device memory
 * @param stream [in] Optional CUDA stream on which to execute kernels
 *
 * @return new column with the selected elements
 */
@Namespace("cudf::experimental::detail") public static native @UniquePtr column copy_if_else( @Const @ByRef column_view lhs, @Const @ByRef column_view rhs, @Const @ByRef column_view boolean_mask,
                                    device_memory_resource mr/*=rmm::mr::get_default_resource()*/,
                                    @ByVal(nullValue = "cudaStream_t(0)") cudaStream_t stream);

/**
 * \brief   Returns a new column, where each element is selected from either \p lhs or 
 *          \p rhs based on the value of the corresponding element in \p boolean_mask
 *
 * Selects each element i in the output column from either \p rhs or \p lhs using the following rule:
 *          output[i] = (boolean_mask[i]) ? lhs : rhs[i]
 *         
 * @throws cudf::logic_error if lhs and rhs are not of the same type 
 * @throws cudf::logic_error if boolean mask is not of type bool8
 * @throws cudf::logic_error if boolean mask is not of the same length as rhs  
 * @param left [in] -hand scalar
 * @param right [in] -hand column_view
 * @param column_view [in] representing "left (true) / right (false)" boolean for each element
 * @param mr [in] resource for allocating device memory 
 * @param stream [in] Optional CUDA stream on which to execute kernels
 *
 * @return new column with the selected elements
 */
@Namespace("cudf::experimental::detail") public static native @UniquePtr column copy_if_else(@Const @ByRef scalar lhs, @Const @ByRef column_view rhs, @Const @ByRef column_view boolean_mask,
                                    device_memory_resource mr/*=rmm::mr::get_default_resource()*/,
                                    @ByVal(nullValue = "cudaStream_t(0)") cudaStream_t stream);

/**
 * \brief   Returns a new column, where each element is selected from either \p lhs or 
 *          \p rhs based on the value of the corresponding element in \p boolean_mask
 *
 * Selects each element i in the output column from either \p rhs or \p lhs using the following rule:
 *          output[i] = (boolean_mask[i]) ? lhs[i] : rhs
 *         
 * @throws cudf::logic_error if lhs and rhs are not of the same type 
 * @throws cudf::logic_error if boolean mask is not of type bool8
 * @throws cudf::logic_error if boolean mask is not of the same length as lhs  
 * @param left [in] -hand column_view
 * @param right [in] -hand scalar
 * @param column_view [in] representing "left (true) / right (false)" boolean for each element
 * @param mr [in] resource for allocating device memory 
 * @param stream [in] Optional CUDA stream on which to execute kernels
 *
 * @return new column with the selected elements
 */
@Namespace("cudf::experimental::detail") public static native @UniquePtr column copy_if_else(@Const @ByRef column_view lhs, @Const @ByRef scalar rhs, @Const @ByRef column_view boolean_mask,
                                    device_memory_resource mr/*=rmm::mr::get_default_resource()*/,
                                    @ByVal(nullValue = "cudaStream_t(0)") cudaStream_t stream);
                                    
/**
 * \brief   Returns a new column, where each element is selected from either \p lhs or 
 *          \p rhs based on the value of the corresponding element in \p boolean_mask
 *
 * Selects each element i in the output column from either \p rhs or \p lhs using the following rule:
 *          output[i] = (boolean_mask[i]) ? lhs : rhs
 *          
 * @throws cudf::logic_error if boolean mask is not of type bool8 
 * @param left [in] -hand scalar
 * @param right [in] -hand scalar
 * @param column_view [in] representing "left (true) / right (false)" boolean for each element
 * @param mr [in] resource for allocating device memory 
 * @param stream [in] Optional CUDA stream on which to execute kernels
 *
 * @return new column with the selected elements
 */
@Namespace("cudf::experimental::detail") public static native @UniquePtr column copy_if_else( @Const @ByRef scalar lhs, @Const @ByRef scalar rhs, @Const @ByRef column_view boolean_mask,
                                    device_memory_resource mr/*=rmm::mr::get_default_resource()*/,
                                    @ByVal(nullValue = "cudaStream_t(0)") cudaStream_t stream);

  // namespace detail
  // namespace experimental
  // namespace cudf


// Parsed from <cudf/detail/transpose.hpp>

/*
 * Copyright (c) 2019, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
// #pragma once

// #include <cudf/table/table.hpp>
// #include <cudf/table/table_view.hpp>

/**
 * \brief Returns a new table transposed from the input table
 *
 * @throws cudf::logic_error if column types are non-homogenous
 * @throws cudf::logic_error if column types are non-fixed-width
 * 
 * @param input [in] Input table of (ncols) number of columns each of size (nrows)
 * @return Newly allocated output table with (nrows) columns each of size (ncols)
 */
@Namespace("cudf::detail") public static native @UniquePtr table transpose(@Const @ByRef table_view input,
                                 device_memory_resource mr/*=rmm::mr::get_default_resource()*/,
                                 @ByVal(nullValue = "cudaStream_t(0)") cudaStream_t stream);

  // namespace detail
  // namespace cudf


// Parsed from <cudf/detail/groupby.hpp>

/*
 * Copyright (c) 2019, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

// #include <cudf/groupby.hpp>
// #include <cudf/types.hpp>

// #include <memory>
// #include <utility>
/**
 * \brief Indicates if a set of aggregation requests can be satisfied with a
 * hash-based groupby implementation.
 *
 * @param keys The table of keys
 * @param requests The set of columns to aggregate and the aggregations to
 * perform
 * @return true A hash-based groupby can be used
 * @return false A hash-based groupby cannot be used
 */
@Namespace("cudf::experimental::groupby::detail::hash") public static native @Cast("bool") boolean can_use_hash_groupby(@Const @ByRef table_view keys,
                      @StdVector aggregation_request requests);

// Hash-based groupby

  // namespace hash

  // namespace detail
  // namespace groupby
  // namespace experimental
  // namespace cudf


// Parsed from <cudf/detail/dlpack.hpp>

/*
 * Copyright (c) 2019, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
// #pragma once

// #include <cudf/dlpack.hpp>

/**
 * \brief Convert a DLPack DLTensor into a cudf table
 *
 * \note The managed tensor is not deleted by this function.
 *
 * The {@code device_type} of the DLTensor must be {@code kDLGPU}, {@code kDLCPU}, or
 * {@code kDLCPUPinned}, and {@code device_id} must match the current device. The {@code ndim}
 * must be set to 1 or 2. The {@code dtype} must have 1 lane and the bitsize must
 * match a supported {@code cudf::data_type}.
 *
 * @throws cudf::logic_error if the any of the DLTensor fields are unsupported
 *
 * @param managed_tensor a 1D or 2D column-major (Fortran order) tensor
 * @param mr Optional resource to use for device memory allocation
 * @param stream Optional stream on which to execute
 *
 * @return Table with a copy of the tensor data
 */
@Namespace("cudf::detail") public static native @UniquePtr table from_dlpack(
    @Const DLManagedTensor managed_tensor,
    device_memory_resource mr/*=rmm::mr::get_default_resource()*/,
    @ByVal(nullValue = "cudaStream_t(0)") cudaStream_t stream);

/**
 * \brief Convert a cudf table into a DLPack DLTensor
 * 
 * All columns must have the same data type and this type must be numeric. The
 * columns may be nullable, but the null count must be zero. If the input table
 * is empty or has zero rows, the result will be nullptr.
 * 
 * \note The {@code deleter} method of the returned {@code DLManagedTensor} must be used to
 * free the memory allocated for the tensor.
 * 
 * @throws cudf::logic_error if the data types are not equal or not numeric,
 * or if any of columns have non-zero null count
 * 
 * @param input Table to convert to DLPack
 * @param mr Optional resource to use for device memory allocation
 * @param stream Optional stream on which to execute
 * 
 * @return 1D or 2D DLPack tensor with a copy of the table data, or nullptr
 */
@Namespace("cudf::detail") public static native DLManagedTensor to_dlpack(@Const @ByRef table_view input,
    device_memory_resource mr/*=rmm::mr::get_default_resource()*/,
    @ByVal(nullValue = "cudaStream_t(0)") cudaStream_t stream);

  // namespace detail
  // namespace cudf


// Parsed from <cudf/detail/gather.hpp>

// #pragma once

// #include <cudf/column/column_view.hpp>
// #include <cudf/table/table_view.hpp>

// #include <cudf/table/table.hpp>

// #include <memory>

/**
 * \brief Gathers the specified rows of a set of columns according to a gather map.
 *
 * Gathers the rows of the source columns according to {@code gather_map} such that row "i"
 * in the resulting table's columns will contain row "gather_map[i]" from the source columns.
 * The number of rows in the result table will be equal to the number of elements in
 * {@code gather_map}.
 *
 * A negative value {@code i} in the {@code gather_map} is interpreted as {@code i+n}, where
 * {@code n} is the number of rows in the {@code source_table}.
 *
 * @throws {@code cudf::logic_error} if {@code check_bounds == true} and an index exists in
 * {@code gather_map} outside the range {@code [-n, n)}, where {@code n} is the number of rows in
 * the source table. If {@code check_bounds == false}, the behavior is undefined.
 *
 * @param source_table [in] The input columns whose rows will be gathered
 * @param gather_map [in] View into a non-nullable column of integral indices that maps the
 * rows in the source columns to rows in the destination columns.
 * @param check_bounds [in] Optionally perform bounds checking on the values
 * of {@code gather_map} and throw an error if any of its values are out of bounds.
 * @param ignore_out_of_bounds [in] Ignore values in {@code gather_map} that are
 * out of bounds. Currently incompatible with {@code allow_negative_indices},
 * i.e., setting both to {@code true} is undefined.
 * @param allow_negative_indices [in] Interpret each negative index {@code i} in the
 * gathermap as the positive index {@code i+num_source_rows}.
 * @param mr [in] The resource to use for all allocations
 * @param stream [in] The CUDA stream on which to execute kernels
 * @return cudf::table Result of the gather
 */
@Namespace("cudf::experimental::detail") public static native @MoveUniquePtr table gather(@Const @ByRef table_view source_table, @Const @ByRef column_view gather_map,
			      @Cast("bool") boolean check_bounds/*=false*/, @Cast("bool") boolean ignore_out_of_bounds/*=false*/,
			      @Cast("bool") boolean allow_negative_indices/*=false*/,
			      device_memory_resource mr/*=rmm::mr::get_default_resource()*/,
			      @ByVal(nullValue = "cudaStream_t(0)") cudaStream_t stream);
  // namespace detail
  // namespace exp
  // namespace cudf


// Parsed from <cudf/detail/unary.hpp>

/*
 * Copyright (c) 2018-2019, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

// #pragma once

// #include <cudf/unary.hpp>
// #include <cudf/column/column_factories.hpp>

/**
 * \brief Creates a column of {@code BOOL8} elements by applying a predicate to every element between [{@code begin, }end{@code )
 * }true{@code  indicates the value is satisfies the predicate and }false{@code  indicates it doesn't.
 *
 * @tparam InputIterator Iterator type for }begin{@code  and }end{@code 
 * @tparam Predicate A predicator type which will be evaludated
 * @param begin Begining of the sequence of elements
 * @param end End of the sequence of elements
 * @param p Predicate to be applied to each element in }[begin,end){@code 
 * @param mr Optional, The resource to use for all allocations
 * @param stream Optional CUDA stream on which to execute kernels
 *
 * @returns std::unique_ptr<cudf::column> A column of type }BOOL8,{@code  with }true{@code  representing predicate is satisfied.
 */

/**
 * \brief Performs unary op on all values in column
 *
 * @param input A {@code column_view} as input
 * @param op operation to perform
 * @param mr Optional, The resource to use for all allocations
 * @param stream Optional CUDA stream on which to execute kernels
 *
 * @return std::unique_ptr<cudf::column> Result of the operation
 */
@Namespace("cudf::experimental::detail") public static native @MoveUniquePtr column unary_operation(@Const @ByRef column_view input,
                                              @ByVal unary_op op,
                                              device_memory_resource mr/*=rmm::mr::get_default_resource()*/,
                                              @ByVal(nullValue = "cudaStream_t(0)") cudaStream_t stream);
@Namespace("cudf::experimental::detail") public static native @MoveUniquePtr column unary_operation(@Const @ByRef column_view input,
                                              @ByVal unary_op op);


/**
 * \brief  Casts data from dtype specified in input to dtype specified in output.
 * Supports only fixed-width types.
 *
 * @param column_view Input column
 * @param out_type Desired datatype of output column
 * @param mr Optional, The resource to use for all allocations
 * @param stream Optional CUDA stream on which to execute kernels
 *
 * @return unique_ptr<column> Result of the cast operation
 * @throws cudf::logic_error if {@code out_type} is not a fixed-width type
 */
@Namespace("cudf::experimental::detail") public static native @UniquePtr column cast(@Const @ByRef column_view input,
                             @ByVal data_type type,
                             device_memory_resource mr/*=rmm::mr::get_default_resource()*/,
                             @ByVal(nullValue = "cudaStream_t(0)") cudaStream_t stream);
@Namespace("cudf::experimental::detail") public static native @UniquePtr column cast(@Const @ByRef column_view input,
                             @ByVal data_type type);

 // namespace detail
 // namespace experimental
 // namespace cudf


// Parsed from <cudf/detail/groupby/sort_helper.hpp>

/*
 * Copyright (c) 2019, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

// #pragma once

// #include <cudf/table/table_view.hpp>
// #include <cudf/column/column.hpp>
// #include <cudf/column/column_view.hpp>
// #include <cudf/types.hpp>

// #include <rmm/thrust_rmm_allocator.h>
// Targeting ../sort_groupby_helper.java



  // namespace sort
  // namespace detail
  // namespace groupby
  // namespace experimental
  // namespace cudf


// Parsed from <cudf/detail/reduction.cuh>

/*
 * Copyright (c) 2019, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

// #pragma once

// #include <cudf/cudf.h>
// #include <rmm/device_buffer.hpp>
// #include <rmm/device_scalar.hpp>
// #include <cudf/utilities/type_dispatcher.hpp>

// #include <cub/device/device_reduce.ch>
// #include <thrust/iterator/iterator_traits.h>
// #include <thrust/for_each.h>
// #include <rmm/thrust_rmm_allocator.h>
// #include "reduction_operators.cuh"

/** --------------------------------------------------------------------------*
 * \brief Compute the specified simple reduction over the input range of elements.
 *
 * @param d_in [in]      the begin iterator
 * @param num_items [in] the number of items
 * @param op [in]        the reduction operator
 * @param stream [in]    cuda stream
 * @return   Output scalar in device memory
 *
 * \tparam Op               the reduction operator with device binary operator
 * \tparam InputIterator    the input column iterator
 * \tparam OutputType       the output type of reduction
 * ----------------------------------------------------------------------------**/

// @brief string_view specialization of simple reduction

/** --------------------------------------------------------------------------*
 * \brief compute reduction by the compound operator (reduce and transform)
 *
 * @param d_in [in]      the begin iterator
 * @param num_items [in] the number of items
 * @param op [in]        the reduction operator 
 * @param valid_count [in]   the intermediate operator argument 1
 * @param ddof [in]      the intermediate operator argument 2
 * @param stream [in]    cuda stream
 * @return   Output scalar in device memory
 *
 * The reduction operator must have {@code intermediate::compute_result()} method.
 * This method performs reduction using binary operator {@code Op::Op} and transforms the
 * result to {@code OutputType} using {@code compute_result()} transform method.
 *
 * \tparam Op               the reduction operator with device binary operator
 * \tparam InputIterator    the input column iterator
 * \tparam OutputType       the output type of reduction
 * ----------------------------------------------------------------------------**/

 // namespace detail
 // namespace reduction
 // namespace experimental
 // namespace cudf


// Parsed from <cudf/detail/transform.hpp>

/*
 * Copyright (c) 2019, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

// #pragma once

// #include <cudf/transform.hpp>    

/**
 * \brief Creates a new column by applying a unary function against every
 * element of an input column.
 *
 * Computes:
 * {@code out[i] = F(in[i])}
 * 
 * The output null mask is the same is the input null mask so if input[i] is 
 * null then output[i] is also null
 *
 * @param input         An immutable view of the input column to transform
 * @param unary_udf     The PTX/CUDA string of the unary function to apply
 * @param outout_type   The output type that is compatible with the output type in the UDF
 * @param is_ptx        true: the UDF is treated as PTX code; false: the UDF is treated as CUDA code
 * @param mr            The memory resource to use for for all device allocations
 * @param stream        CUDA stream on which to execute kernels
 * @return cudf::column The column resulting from applying the unary function to
 *                      every element of the input
 **/
@Namespace("cudf::experimental::detail") public static native @UniquePtr column transform(
  @Const @ByRef column_view input,
  @StdString BytePointer unary_udf,
  @ByVal data_type output_type,
  @Cast("bool") boolean is_ptx,
  device_memory_resource mr/*=rmm::mr::get_default_resource()*/,
  @ByVal(nullValue = "cudaStream_t(0)") cudaStream_t stream);
@Namespace("cudf::experimental::detail") public static native @UniquePtr column transform(
  @Const @ByRef column_view input,
  @StdString BytePointer unary_udf,
  @ByVal data_type output_type,
  @Cast("bool") boolean is_ptx);
@Namespace("cudf::experimental::detail") public static native @UniquePtr column transform(
  @Const @ByRef column_view input,
  @StdString String unary_udf,
  @ByVal data_type output_type,
  @Cast("bool") boolean is_ptx,
  device_memory_resource mr/*=rmm::mr::get_default_resource()*/,
  @ByVal(nullValue = "cudaStream_t(0)") cudaStream_t stream);
@Namespace("cudf::experimental::detail") public static native @UniquePtr column transform(
  @Const @ByRef column_view input,
  @StdString String unary_udf,
  @ByVal data_type output_type,
  @Cast("bool") boolean is_ptx);

/**
 * \copydoc cudf::experimental::nans_to_nulls
 *
 * @param stream        CUDA stream on which to execute kernels
 **/
@Namespace("cudf::experimental::detail") public static native @ByVal PairOfUniquePtrRmmDeviceBufferCudfSizeType nans_to_nulls(@Const @ByRef column_view input,
              device_memory_resource mr/*=rmm::mr::get_default_resource()*/,
              @ByVal(nullValue = "cudaStream_t(0)") cudaStream_t stream);
@Namespace("cudf::experimental::detail") public static native @ByVal PairOfUniquePtrRmmDeviceBufferCudfSizeType nans_to_nulls(@Const @ByRef column_view input);


/**
 * \copydoc cudf::experimental::bools_to_mask
 *
 * @param stream        CUDA stream on which to execute kernels
 **/
@Namespace("cudf::experimental::detail") public static native @ByVal PairOfUniquePtrRmmDeviceBufferCudfSizeType bools_to_mask(@Const @ByRef column_view input,
                  device_memory_resource mr/*=rmm::mr::get_default_resource()*/,
                  @ByVal(nullValue = "cudaStream_t(0)") cudaStream_t stream);
@Namespace("cudf::experimental::detail") public static native @ByVal PairOfUniquePtrRmmDeviceBufferCudfSizeType bools_to_mask(@Const @ByRef column_view input);
 // namespace detail
 // namespace experimental
 // namespace cudf


// Parsed from <cudf/detail/repeat.hpp>

/*
 * Copyright (c) 2019, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

// #pragma once

// #include <cudf/filling.hpp>
// #include <cudf/types.hpp>
// #include <rmm/mr/device_memory_resource.hpp>

// #include <cuda_runtime.h>

// #include <memory>

/**---------------------------------------------------------------------------*
 * \brief Internal API to repeat rows of a Table.
 * 
 * Creates a new table by repeating the rows of \p input_table. The number of 
 * repetitions of each element is defined by the value at the corresponding 
 * index of \p count
 * Example:
 * <pre>{@code
 * in = [4,5,6]
 * count = [1,2,3]
 * return = [4,5,5,6,6,6]
 * }</pre>
 * \p count should not have null values; should not contain negative values;
 * and the sum of count elements should not overflow the size_type's limit.
 * It is undefined behavior if \p count has negative values or the sum overflows
 * and \p check_count is set to false.
 *
 * @throws {@code cudf::logic_error} if the data type of \p count is not size_type.
 * @throws {@code cudf::logic_error} if \p input_table and \p count have different
 * number of rows.
 * @throws {@code cudf::logic_error} if \p count has null values.
 * @throws {@code cudf::logic_error} if \p check_count is set to true and \p count
 * has negative values or the sum of \p count elements overflows.
 *
 * @param input_table Input table
 * @param count Non-nullable column of a integral type
 * @param check_count Whether to check count (negative values and overflow)
 * @param mr Memory resource to allocate the result output table
 * @param stream CUDA stream to run this function
 * @return std::unique_ptr<table> The result table containing the repetitions
 *---------------------------------------------------------------------------**/
@Namespace("cudf::experimental::detail") public static native @MoveUniquePtr table repeat(@Const @ByRef table_view input_table,
                              @Const @ByRef column_view count, @Cast("bool") boolean check_count,
                              device_memory_resource mr/*=rmm::mr::get_default_resource()*/,
                              @ByVal(nullValue = "cudaStream_t(0)") cudaStream_t stream);
@Namespace("cudf::experimental::detail") public static native @MoveUniquePtr table repeat(@Const @ByRef table_view input_table,
                              @Const @ByRef column_view count, @Cast("bool") boolean check_count);

/**---------------------------------------------------------------------------*
 * \brief Internal API to repeat rows of a Table.
 * 
 * Creates a new table by repeating \p count times the rows of \p input_table.
 * Example:
 * <pre>{@code
 * in = [4,5,6]
 * count = 2
 * return = [4,4,5,5,6,6]
 * }</pre>
 * @throws {@code cudf::logic_error} if the data type of \p count is not size_type.
 * @throws {@code cudf::logic_error} if \p count is invalid or \p count is negative.
 * @throws {@code cudf::logic_error} if \p input_table.num_rows() * \p count overflows
 * size_type.
 * 
 * @param input_table Input table
 * @param count Non-null scalar of a integral type
 * @param mr Memory resource to allocate the result output table
 * @param stream CUDA stream to run this function
 * @return std::unique_ptr<table> The result table containing the repetitions
 *---------------------------------------------------------------------------**/
@Namespace("cudf::experimental::detail") public static native @MoveUniquePtr table repeat(@Const @ByRef table_view input_table,
                              @Const @ByRef scalar count,
                              device_memory_resource mr/*=rmm::mr::get_default_resource()*/,
                              @ByVal(nullValue = "cudaStream_t(0)") cudaStream_t stream);
@Namespace("cudf::experimental::detail") public static native @MoveUniquePtr table repeat(@Const @ByRef table_view input_table,
                              @Const @ByRef scalar count);

  // namespace detail
  // namespace experimental
  // namespace cudf


// Parsed from <cudf/detail/stream_compaction.hpp>

/*
 * Copyright (c) 2019, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

// #pragma once

// #include <cudf/types.hpp>
// #include <cudf/column/column_view.hpp>
// #include <cudf/column/column_device_view.ch>

/**
 * \brief Filters a table to remove null elements.
 *
 * Filters the rows of the {@code input} considering specified columns indicated in
 * {@code keys} for validity / null values.
 *
 * Given an input table_view, row {@code i} from the input columns is copied to
 * the output if the same row {@code i} of \p keys has at least \p keep_threshold
 * non-null fields.
 *
 * This operation is stable: the input order is preserved in the output.
 *
 * Any non-nullable column in the input is treated as all non-null.
 *
 * \example input   {col1: {1, 2,    3,    null},
 *                   col2: {4, 5,    null, null},
 *                   col3: {7, null, null, null}}
 *          keys = {0, 1, 2} // All columns
 *          keep_threshold = 2
 *
 *          output {col1: {1, 2}
 *                  col2: {4, 5}
 *                  col3: {7, null}}
 *
 * \note if \p input.num_rows() is zero, or \p keys is empty or has no nulls,
 * there is no error, and an empty {@code table} is returned
 *
 * @param input [in] The input {@code table_view} to filter.
 * @param keys [in]  vector of indices representing key columns from {@code input}
 * @param keep_threshold [in] The minimum number of non-null fields in a row
 *                           required to keep the row.
 * @param mr [in] Optional, The resource to use for all allocations
 * @param stream [in] Optional CUDA stream on which to execute kernels
 * @return unique_ptr<table> Table containing all rows of the {@code input} with at least \p keep_threshold non-null fields in \p keys.
 */
@Namespace("cudf::experimental::detail") public static native @UniquePtr table drop_nulls(@Const @ByRef table_view input,
               @StdVector size_type keys,
               @ByVal size_type keep_threshold,
               device_memory_resource mr/*=rmm::mr::get_default_resource()*/,
               @ByVal(nullValue = "cudaStream_t(0)") cudaStream_t stream);
@Namespace("cudf::experimental::detail") public static native @UniquePtr table drop_nulls(@Const @ByRef table_view input,
               @StdVector size_type keys,
               @ByVal size_type keep_threshold);

/**
 * \brief Filters {@code input} using {@code boolean_mask} of boolean values as a mask.
 *
 * Given an input {@code table_view} and a mask {@code column_view}, an element {@code i} from
 * each column_view of the {@code input} is copied to the corresponding output column
 * if the corresponding element {@code i} in the mask is non-null and {@code true}.
 * This operation is stable: the input order is preserved.
 *
 * \note if \p input.num_rows() is zero, there is no error, and an empty table
 * is returned.
 *
 * @throws cudf::logic_error if The {@code input} size  and {@code boolean_mask} size mismatches.
 * @throws cudf::logic_error if {@code boolean_mask} is not {@code BOOL8} type.
 *
 * @param input [in] The input table_view to filter
 * @param boolean_mask [in] A nullable column_view of type BOOL8 used as
 * a mask to filter the {@code input}.
 * @param mr [in] Optional, The resource to use for all allocations
 * @param stream [in] Optional CUDA stream on which to execute kernels
 * @return unique_ptr<table> Table containing copy of all rows of \p input passing
 * the filter defined by \p boolean_mask.
 */
@Namespace("cudf::experimental::detail") public static native @UniquePtr table apply_boolean_mask(@Const @ByRef table_view input,
                       @Const @ByRef column_view boolean_mask,
                       device_memory_resource mr/*=rmm::mr::get_default_resource()*/,
                       @ByVal(nullValue = "cudaStream_t(0)") cudaStream_t stream);
@Namespace("cudf::experimental::detail") public static native @UniquePtr table apply_boolean_mask(@Const @ByRef table_view input,
                       @Const @ByRef column_view boolean_mask);

/**
 * \brief Create a new table without duplicate rows
 *
 * Given an {@code input} table_view, each row is copied to output table if the corresponding
 * row of {@code keys} columns is unique, where the definition of unique depends on the value of \p keep:
 * - KEEP_FIRST: only the first of a sequence of duplicate rows is copied
 * - KEEP_LAST: only the last of a sequence of duplicate rows is copied
 * - KEEP_NONE: only unique rows are kept
 *
 * @throws cudf::logic_error if The {@code input} row size mismatches with {@code keys}.
 *
 * @param input [in]           input table_view to copy only unique rows
 * @param keys [in]            vector of indices representing key columns from {@code input}
 * @param keep [in]            keep first entry, last entry, or no entries if duplicates found
 * @param nulls_are_equal [in] flag to denote nulls are equal if true,
 * nulls are not equal if false
 * @param mr [in] Optional, The resource to use for all allocations
 * @param stream [in] Optional CUDA stream on which to execute kernels
 *
 * @return unique_ptr<table> Table with unique rows as per specified {@code keep}.
 */
@Namespace("cudf::experimental::detail") public static native @UniquePtr table drop_duplicates(@Const @ByRef table_view input,
                    @StdVector size_type keys,
                    @Const @ByRef duplicate_keep_option keep,
                    @Cast("const bool") boolean nulls_are_equal/*=true*/,
                    device_memory_resource mr/*=rmm::mr::get_default_resource()*/,
                    @ByVal(nullValue = "cudaStream_t(0)") cudaStream_t stream);
@Namespace("cudf::experimental::detail") public static native @UniquePtr table drop_duplicates(@Const @ByRef table_view input,
                    @StdVector size_type keys,
                    @Const @ByRef duplicate_keep_option keep);

/**
 * \brief Count the unique elements in the column_view
 *
 * Given an input column_view, number of unique elements in this column_view is returned
 *
 * If both {@code ignore_nulls} and {@code nan_as_null} are true, both {@code NaN} and {@code null}
 * values are ignored.
 * If {@code ignor_nulls} is true and {@code nan_as_null} is false, only {@code null} is
 * ignored, {@code NaN} is considered in unique count.
 *
 * @param input [in]         The column_view whose unique elements will be counted.
 * @param ignore_nulls [in]  flag to ignore {@code null} in unique count if true
 * @param nan_as_null [in]   flag to consider {@code NaN==null} if true.
 * @param mr [in] Optional, The resource to use for all allocations
 * @param stream [in] Optional CUDA stream on which to execute kernels
 *
 * @return number of unique elements
 */

@Namespace("cudf::experimental::detail") public static native @ByVal size_type unique_count(@Const @ByRef column_view input,
                             @Cast("const bool") boolean ignore_nulls,
                             @Cast("const bool") boolean nan_as_null,
                             @ByVal(nullValue = "cudaStream_t(0)") cudaStream_t stream);
@Namespace("cudf::experimental::detail") public static native @ByVal size_type unique_count(@Const @ByRef column_view input,
                             @Cast("const bool") boolean ignore_nulls,
                             @Cast("const bool") boolean nan_as_null);

/**---------------------------------------------------------------------------*
 * \brief A structure to be used for checking {@code NAN} at an index in a 
 * {@code column_device_view}
 *
 * \tparam T The type of {@code column_device_view}
 *---------------------------------------------------------------------------**/
// Targeting ../has_nans.java



 // namespace detail
 // namespace experimental
 // namespace cudf


// Parsed from <cudf/detail/binaryop.hpp>

/*
 * Copyright (c) 2018-2019, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

// #pragma once

// #include <cudf/binaryop.hpp>

/**
 * \brief Performs a binary operation between a scalar and a column.
 *
 * The output contains the result of op(lhs, rhs[i]) for all 0 <= i < rhs.size()
 * The scalar is the left operand and the column elements are the right operand.
 * This distinction is significant in case of non-commutative binary operations
 * 
 * Regardless of the operator, the validity of the output value is the logical
 * AND of the validity of the two operands
 * 
 * @param lhs         The left operand scalar
 * @param rhs         The right operand column
 * @param output_type The desired data type of the output column
 * @param mr          Memory resource for allocating output column
 * @param stream      CUDA stream on which to execute kernels
 * @return std::unique_ptr<column> Output column
 */
@Namespace("cudf::experimental::detail") public static native @UniquePtr column binary_operation( @Const @ByRef scalar lhs,
                                          @Const @ByRef column_view rhs,
                                          @ByVal binary_operator op,
                                          @ByVal data_type output_type,
    device_memory_resource mr/*=rmm::mr::get_default_resource()*/,
    @ByVal(nullValue = "cudaStream_t(0)") cudaStream_t stream);
@Namespace("cudf::experimental::detail") public static native @UniquePtr column binary_operation( @Const @ByRef scalar lhs,
                                          @Const @ByRef column_view rhs,
                                          @ByVal binary_operator op,
                                          @ByVal data_type output_type);

/**
 * \brief Performs a binary operation between a column and a scalar.
 * 
 * The output contains the result of op(lhs[i], rhs) for all 0 <= i < lhs.size()
 * The column elements are the left operand and the scalar is the right operand.
 * This distinction is significant in case of non-commutative binary operations
 * 
 * Regardless of the operator, the validity of the output value is the logical
 * AND of the validity of the two operands
 * 
 * @param lhs         The left operand column
 * @param rhs         The right operand scalar
 * @param output_type The desired data type of the output column
 * @param mr          Memory resource for allocating output column
 * @param stream      CUDA stream on which to execute kernels
 * @return std::unique_ptr<column> Output column
 */
@Namespace("cudf::experimental::detail") public static native @UniquePtr column binary_operation( @Const @ByRef column_view lhs,
                                          @Const @ByRef scalar rhs,
                                          @ByVal binary_operator op,
                                          @ByVal data_type output_type,
    device_memory_resource mr/*=rmm::mr::get_default_resource()*/,
    @ByVal(nullValue = "cudaStream_t(0)") cudaStream_t stream);
@Namespace("cudf::experimental::detail") public static native @UniquePtr column binary_operation( @Const @ByRef column_view lhs,
                                          @Const @ByRef scalar rhs,
                                          @ByVal binary_operator op,
                                          @ByVal data_type output_type);

/**
 * \brief Performs a binary operation between two columns.
 *
 * \note The sizes of \p lhs and \p rhs should be the same
 * 
 * The output contains the result of op(lhs[i], rhs[i]) for all 0 <= i < lhs.size()
 *
 * Regardless of the operator, the validity of the output value is the logical
 * AND of the validity of the two operands
 * 
 * @param lhs         The left operand column
 * @param rhs         The right operand column
 * @param output_type The desired data type of the output column
 * @param mr          Memory resource for allocating output column
 * @param stream      CUDA stream on which to execute kernels
 * @return std::unique_ptr<column> Output column
 */
@Namespace("cudf::experimental::detail") public static native @UniquePtr column binary_operation( @Const @ByRef column_view lhs,
                                          @Const @ByRef column_view rhs,
                                          @ByVal binary_operator op,
                                          @ByVal data_type output_type,
    device_memory_resource mr/*=rmm::mr::get_default_resource()*/,
    @ByVal(nullValue = "cudaStream_t(0)") cudaStream_t stream);
@Namespace("cudf::experimental::detail") public static native @UniquePtr column binary_operation( @Const @ByRef column_view lhs,
                                          @Const @ByRef column_view rhs,
                                          @ByVal binary_operator op,
                                          @ByVal data_type output_type);

/**
 * \brief Performs a binary operation between two columns using a
 * user-defined PTX function.
 *
 * \note The sizes of \p lhs and \p rhs should be the same
 * 
 * The output contains the result of op(lhs[i], rhs[i]) for all 0 <= i < lhs.size()
 *
 * Regardless of the operator, the validity of the output value is the logical
 * AND of the validity of the two operands
 *
 * @param lhs         The left operand column
 * @param rhs         The right operand column
 * @param ptx         String containing the PTX of a binary function
 * @param output_type The desired data type of the output column. It is assumed
 *                    that output_type is compatible with the output data type
 *                    of the function in the PTX code
 * @param mr          Memory resource for allocating output column
 * @param stream      CUDA stream on which to execute kernels
 * @return std::unique_ptr<column> Output column
 */
@Namespace("cudf::experimental::detail") public static native @UniquePtr column binary_operation( @Const @ByRef column_view lhs,
                                          @Const @ByRef column_view rhs,
                                          @StdString BytePointer ptx,
                                          @ByVal data_type output_type,
    device_memory_resource mr/*=rmm::mr::get_default_resource()*/,
    @ByVal(nullValue = "cudaStream_t(0)") cudaStream_t stream);
@Namespace("cudf::experimental::detail") public static native @UniquePtr column binary_operation( @Const @ByRef column_view lhs,
                                          @Const @ByRef column_view rhs,
                                          @StdString BytePointer ptx,
                                          @ByVal data_type output_type);
@Namespace("cudf::experimental::detail") public static native @UniquePtr column binary_operation( @Const @ByRef column_view lhs,
                                          @Const @ByRef column_view rhs,
                                          @StdString String ptx,
                                          @ByVal data_type output_type,
    device_memory_resource mr/*=rmm::mr::get_default_resource()*/,
    @ByVal(nullValue = "cudaStream_t(0)") cudaStream_t stream);
@Namespace("cudf::experimental::detail") public static native @UniquePtr column binary_operation( @Const @ByRef column_view lhs,
                                          @Const @ByRef column_view rhs,
                                          @StdString String ptx,
                                          @ByVal data_type output_type);

 // namespace detail
 // namespace experimental
 // namespace cudf


// Parsed from <cudf/detail/aggregation/aggregation.cuh>

/*
 * Copyright (c) 2019-2020, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

// #pragma once

// #include <cudf/aggregation.hpp>
// #include <cudf/column/column_device_view.ch>
// #include <cudf/detail/aggregation/aggregation.hpp>
// #include <cudf/detail/utilities/device_atomics.ch>
// #include <cudf/detail/utilities/release_assert.ch>
// #include <cudf/table/table_device_view.ch>
// Targeting ../corresponding_operator.java



/**
 * \brief Function object to update a single element in a target column by
 * performing an aggregation operation with a single element from a source
 * column.
 *
 * \tparam target_has_nulls Indicates presence of null elements in {@code target}
 * \tparam source_has_nulls Indicates presence of null elements in {@code source}.
 */

/**
 * \brief Updates a row in {@code target} by performing elementwise aggregation
 * operations with a row in {@code source}.
 *
 * For the row in {@code target} specified by {@code target_index}, each element at {@code i} is
 * updated by:
 * <pre>{@code c++
 * target_row[i] = aggs[i](target_row[i], source_row[i])
 * }</pre>
 * 
 * This function only supports aggregations that can be done in a "single pass", 
 * i.e., given an initial value {@code R}, the aggregation {@code op} can be computed on a series
 * of elements {@code e[i] for i in [0,n)} by computing {@code R = op(e[i],R)} for any order 
 * of the values of {@code i}.
 * 
 * The initial value and validity of {@code R} depends on the aggregation:
 * SUM: 0 and NULL
 * COUNT: 0 and VALID
 * MIN: Max element of type and NULL
 * MAX: Min element of type and NULL
 * ARGMAX: {@code ARGMAX_SENTINEL} and NULL
 * ARGMIN: {@code ARGMIN_SENTINEL} and NULL
 * 
 * It is required that the elements of {@code target} be initialized with the corresponding
 * initial values and validity specified above.
 * 
 * Handling of null elements in both {@code source} and {@code target} depends on the aggregation:
 * SUM, MIN, MAX, ARGMIN, ARGMAX:
 *  - {@code source}: Skipped
 *  - {@code target}: Updated from null to valid upon first successful aggregation
 * COUNT:
 *  - {@code source}: Skipped
 *  - {@code target}: Cannot be null
 *
 * @param target Table containing the row to update
 * @param target_index Index of the row to update in {@code target}
 * @param source Table containing the row used to update the row in {@code target}.
 * The invariant {@code source.num_columns() >= target.num_columns()} must hold.
 * @param source_index Index of the row to use in {@code source}
 * @param aggs Array of aggregations to perform between elements of the {@code target}
 * and {@code source} rows. Must contain at least {@code target.num_columns()} valid
 * {@code aggregation::Kind} values.
 */
  // namespace detail
  // namespace experimental
  // namespace cudf


// Parsed from <cudf/detail/aggregation/aggregation.hpp>

/*
 * Copyright (c) 2019-2020, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

// #pragma once

// #include <cudf/utilities/error.hpp>
// #include <cudf/utilities/traits.hpp>
// #include <cudf/detail/utilities/release_assert.ch>
// #include <cudf/types.hpp>
// Targeting ../aggregation.java


// Targeting ../quantile_aggregation.java


// Targeting ../std_var_aggregation.java


// Targeting ../udf_aggregation.java



/**
 * \brief Sentinel value used for {@code ARGMAX} aggregation.
 *
 * The output column for an {@code ARGMAX} aggregation is initialized with the
 * sentinel value to indicate an unused element.
 */
@Namespace("cudf::experimental::detail") @MemberGetter public static native @Const @ByRef size_type ARGMAX_SENTINEL();

/**
 * \brief Sentinel value used for {@code ARGMIN} aggregation.
 *
 * The output column for an {@code ARGMIN} aggregation is initialized with the
 * sentinel value to indicate an unused element.
 */
@Namespace("cudf::experimental::detail") @MemberGetter public static native @Const @ByRef size_type ARGMIN_SENTINEL();

/**---------------------------------------------------------------------------*
 * \brief Determines accumulator type based on input type and aggregation.
 *
 * \tparam Source The type on which the aggregation is computed
 * \tparam k The aggregation performed
 *---------------------------------------------------------------------------**/

// Computing MIN of Source, use Source accumulator

// Computing MAX of Source, use Source accumulator

// Always use size_type accumulator for COUNT

// Always use `double` for MEAN
// TODO (dm): Except for timestamp where result is timestamp. (Use FloorDiv)

// Summing integers of any type, always use int64_t accumulator

// Summing float/doubles, use same type accumulator

// Summing timestamps, use same type accumulator

// Always use `double` for VARIANCE

// Always use `double` for STD

// Always use `double` for quantile

// MEDIAN is a special case of a QUANTILE

// Always use `size_type` for ARGMAX index

// Always use `size_type` for ARGMIN index

/**
 * \brief Helper alias to get the accumulator type for performing aggregation
 * {@code k} on elements of type {@code Source}
 *
 * \tparam Source The type on which the aggregation is computed
 * \tparam k The aggregation performed
 */

// #ifndef AGG_KIND_MAPPING
// #define AGG_KIND_MAPPING(k, Type)
//   template <>
//   struct kind_to_type_impl<k> {
//     using type = Type;
//   }
// Targeting ../kind_to_type_impl.java



/**
 * \brief Dispatches {@code k} as a non-type template parameter to a callable,  {@code f}.
 *
 * \tparam F Type of callable
 * @param k The {@code aggregation::Kind} value to dispatch
 * aram f The callable that accepts an {@code aggregation::Kind} non-type template
 * argument.
 * @param args Parameter pack forwarded to the {@code operator()} invocation
 * @return Forwards the return value of the callable.
 */
// #pragma nv_exec_check_disable
// Targeting ../dispatch_source.java



/**
 * \brief Dispatches both a type and {@code aggregation::Kind} template parameters to
 * a callable.
 *
 * This function expects a callable {@code f} with an {@code operator()} template accepting
 * two template parameters. The first is a type dispatched from {@code type}. The
 * second is an {@code aggregation::Kind} dispatched from {@code k}.
 *
 * @param type The {@code data_type} used to dispatch a type for the first template
 * parameter of the callable {@code F}
 * @param k The {@code aggregation::Kind} used to dispatch an {@code aggregation::Kind}
 * non-type template parameter for the second template parameter of the callable
 * @param args Parameter pack forwarded to the {@code operator()} invocation
 * {@code F}.
 */
// #pragma nv_exec_check_disable
/**
 * \brief Returns the target {@code data_type} for the specified aggregation  k
 * performed on elements of type  source_type.
 *
 * aram source_type The element type to be aggregated
 * aram k The aggregation
 * @return data_type The target_type of  k performed on  source_type
 * elements
 */
@Namespace("cudf::experimental::detail") public static native @ByVal data_type target_type(@ByVal data_type source_type, @Cast("cudf::experimental::aggregation::Kind") int k);

/**
 * \brief Indicates whether the specified aggregation {@code k} is valid to perform on
 * the type {@code Source}.
 *
 * \tparam Source Type on which the aggregation is performed
 * \tparam k The aggregation to perform
 */

/**
 * \brief Indicates whether the specified aggregation {@code k} is valid to perform on
 * the {@code data_type} {@code source}.
 *
 * @param source Source {@code data_type} on which the aggregation is performed
 * @param k The aggregation to perform
 */
@Namespace("cudf::experimental::detail") public static native @Cast("bool") boolean is_valid_aggregation(@ByVal data_type source, @Cast("cudf::experimental::aggregation::Kind") int k);

  // namespace detail
  // namespace experimental
  // namespace cudf


// Parsed from <cudf/detail/copy_range.cuh>

/*
 * Copyright (c) 2019, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

// #include <cudf/copying.hpp>
// #include <cudf/types.hpp>
// #include <cudf/column/column_view.hpp>
// #include <cudf/column/column_device_view.ch>
// #include <cudf/detail/utilities/cuda.ch>
// #include <cudf/utilities/bit.hpp>
// #include <cudf/utilities/error.hpp>
// #include <cudf/utilities/type_dispatcher.hpp>
// #include <rmm/device_scalar.hpp>
// #include <rmm/mr/device_memory_resource.hpp>

// #include <cub/cub.ch>

// #include <cuda_runtime.h>

// #include <memory>

  // namespace anonymous

/**
 * \brief Internal API to copy a range of values from source iterators to a
 * target column.
 *
 * The elements indicated by the indices [\p target_begin, \p target_end) were
 * replaced with the elements retrieved from source iterators;
 * *(\p source_value_begin + idx) if *(\p source_validity_begin + idx) is true,
 * invalidate otherwise (where idx = [0, \p target_end - \p target_begin)).
 * \p target is modified in place.
 *
 * \tparam SourceValueIterator Iterator for retrieving source values
 * \tparam SourceValidityIterator Iterator for retrieving source validities
 * @param source_value_begin Start of source value iterator
 * @param source_validity_begin Start of source validity iterator
 * @param target the column to copy into
 * @param target_begin The starting index of the target range (inclusive)
 * @param target_end The index of the last element in the target range
 * (exclusive)
 * @param stream CUDA stream to run this function
 */

/**
 * \brief Internal API to copy a range of elements in-place from one column to
 * another.
 *
 * Overwrites the range of elements in \p target indicated by the indices
 * [\p target_begin, \p target_begin + N) with the elements from \p source
 * indicated by the indices [\p source_begin, \p source_end) (where N =
 * (\p source_end - \p source_begin)). Use the out-of-place copy function
 * returning std::unique_ptr<column> for uses cases requiring memory
 * reallocation. For example for strings columns and other variable-width types.
 *
 * If \p source and \p target refer to the same elements and the ranges overlap,
 * the behavior is undefined.
 *
 * @throws {@code cudf::logic_error} if memory reallocation is required (e.g. for
 * variable width types).
 * @throws {@code cudf::logic_error} for invalid range (if
 * \p source_begin > \p source_end, \p source_begin < 0,
 * \p source_begin >= \p source.size(), \p source_end > \p source.size(),
 * \p target_begin < 0, target_begin >= \p target.size(), or
 * \p target_begin + (\p source_end - \p source_begin) > \p target.size()).
 * @throws {@code cudf::logic_error} if \p target and \p source have different types.
 * @throws {@code cudf::logic_error} if \p source has null values and \p target is not
 * nullable.
 *
 * @param source The column to copy from
 * @param target The preallocated column to copy into
 * @param source_begin The starting index of the source range (inclusive)
 * @param source_end The index of the last element in the source range
 * (exclusive)
 * @param target_begin The starting index of the target range (inclusive)
 * @return void
 */
@Namespace("cudf::experimental::detail") public static native void copy_range(@Const @ByRef column_view source, @ByRef mutable_column_view target,
                @ByVal size_type source_begin, @ByVal size_type source_end,
                @ByVal size_type target_begin,
                @ByVal(nullValue = "cudaStream_t(0)") cudaStream_t stream);

/**
 * \brief Internal API to copy a range of elements out-of-place from one column
 * to another.
 *
 * Creates a new column as if an in-place copy was performed into \p target.
 * A copy of \p target is created first and then the elements indicated by the
 * indices [\p target_begin, \p target_begin + N) were copied from the elements
 * indicated by the indices [\p source_begin, \p source_end) of \p source
 * (where N = (\p source_end - \p source_begin)). Elements outside the range are
 * copied from \p target into the returned new column target.
 *
 * If \p source and \p target refer to the same elements and the ranges overlap,
 * the behavior is undefined.
 *
 * @throws {@code cudf::logic_error} for invalid range (if
 * \p source_begin > \p source_end, \p source_begin < 0,
 * \p source_begin >= \p source.size(), \p source_end > \p source.size(),
 * \p target_begin < 0, target_begin >= \p target.size(), or
 * \p target_begin + (\p source_end - \p source_begin) > \p target.size()).
 * @throws {@code cudf::logic_error} if \p target and \p source have different types.
 *
 * @param source The column to copy from inside the range.
 * @param target The column to copy from outside the range.
 * @param source_begin The starting index of the source range (inclusive)
 * @param source_end The index of the last element in the source range
 * (exclusive)
 * @param target_begin The starting index of the target range (inclusive)
 * @param mr Memory resource to allocate the result target column.
 * @param stream CUDA stream to run this function
 * @return std::unique_ptr<column> The result target column
 */
@Namespace("cudf::experimental::detail") public static native @UniquePtr column copy_range(
  @Const @ByRef column_view source,
  @Const @ByRef column_view target,
  @ByVal size_type source_begin, @ByVal size_type source_end,
  @ByVal size_type target_begin,
  device_memory_resource mr/*=rmm::mr::get_default_resource()*/,
  @ByVal(nullValue = "cudaStream_t(0)") cudaStream_t stream);

  // namespace detail
  // namespace experimental
  // namespace cudf


// Parsed from <cudf/detail/search.hpp>

/*
 * Copyright (c) 2020, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

// #pragma once

// #include <cudf/types.hpp>
// #include <cudf/column/column.hpp>
// #include <cudf/scalar/scalar.hpp>
// #include <cudf/table/table.hpp>

// #include <vector>

/**
 * \brief Find smallest indices in a sorted table where values should be 
 *  inserted to maintain order
 * 
 * For each row v in \p values, find the first index in \p t where
 *  inserting the row will maintain the sort order of \p t
 * 
 * Example:
 * 
 *  Single column:
 *      idx      0   1   2   3   4
 *   column = { 10, 20, 20, 30, 50 }
 *   values = { 20 }
 *   result = {  1 }
 * 
 *  Multi Column:
 *      idx        0    1    2    3    4
 *   t      = {{  10,  20,  20,  20,  20 },
 *             { 5.0,  .5,  .5,  .7,  .7 },
 *             {  90,  77,  78,  61,  61 }}
 *   values = {{ 20 },
 *             { .7 },
 *             { 61 }}
 *   result =  {  3 }
 * 
 * @param t               Table to search
 * @param values          Find insert locations for these values
 * @param column_order    Vector of column sort order
 * @param null_precedence Vector of null_precedence enums values
 * @param mr              Device memory resource to use for device memory allocation
 * @param stream          Stream to use for any kernel launches.
 * @return std::unique_ptr<column> A non-nullable column of cudf::size_type elements
 * containing the insertion points.
 */
@Namespace("cudf::experimental::detail") public static native @UniquePtr column lower_bound(@Const @ByRef table_view t,
                                    @Const @ByRef table_view values,
                                    @StdVector order column_order,
                                    @StdVector null_order null_precedence,
                                    device_memory_resource mr/*=rmm::mr::get_default_resource()*/,
                                    @ByVal(nullValue = "cudaStream_t(0)") cudaStream_t steam);
@Namespace("cudf::experimental::detail") public static native @UniquePtr column lower_bound(@Const @ByRef table_view t,
                                    @Const @ByRef table_view values,
                                    @StdVector order column_order,
                                    @StdVector null_order null_precedence);

/**
 * \brief Find largest indices in a sorted table where values should be 
 *  inserted to maintain order
 * 
 * For each row v in \p values, find the last index in \p t where
 *  inserting the row will maintain the sort order of \p t
 * 
 * Example:
 * 
 *  Single Column:
 *      idx      0   1   2   3   4
 *   column = { 10, 20, 20, 30, 50 }
 *   values = { 20 }
 *   result = {  3 }
 * 
 *  Multi Column:
 *    idx        0    1    2    3    4
 *   t      = {{  10,  20,  20,  20,  20 },
 *             { 5.0,  .5,  .5,  .7,  .7 },
 *             {  90,  77,  78,  61,  61 }}
 *   values = {{ 20 },
 *             { .7 },
 *             { 61 }}
 *   result =  {  5  *   * 
 * @param column          Table to search
 * @param values          Find insert locations for these values
 * @param column_order    Vector of column sort order
 * @param null_precedence Vector of null_precedence enums values
 * @param mr              Device memory resource to use for device memory allocation
 * @param stream          Stream to use for any kernel launches.
 * @return std::unique_ptr<column> A non-nullable column of cudf::size_type elements
 * containing the insertion points.
 */
@Namespace("cudf::experimental::detail") public static native @UniquePtr column upper_bound(@Const @ByRef table_view t,
                                    @Const @ByRef table_view values,
                                    @StdVector order column_order,
                                    @StdVector null_order null_precedence,
                                    device_memory_resource mr/*=rmm::mr::get_default_resource()*/,
                                    @ByVal(nullValue = "cudaStream_t(0)") cudaStream_t stream);
@Namespace("cudf::experimental::detail") public static native @UniquePtr column upper_bound(@Const @ByRef table_view t,
                                    @Const @ByRef table_view values,
                                    @StdVector order column_order,
                                    @StdVector null_order null_precedence);

/**
 * \brief Find if the {@code value} is present in the {@code col}
 *
 * @throws cudf::logic_error
 * If {@code col.type() != values.type()}
 *
 * \example:
 *
 *  Single Column:
 *      idx      0   1   2   3   4
 *      col = { 10, 20, 20, 30, 50 }
 *  Scalar:
 *   value = { 20 }
 *   result = true
 *
 * @param col      A column object
 * @param value    A scalar value to search for in {@code col}
 * @param mr       Device memory resource to use for device memory allocation
 * @param stream   Stream to use for any kernel launches.
 * @return bool    If {@code value} is found in {@code column} true, else false.
 */
@Namespace("cudf::experimental::detail") public static native @Cast("bool") boolean contains(@Const @ByRef column_view col, @Const @ByRef scalar value,
              device_memory_resource mr/*=rmm::mr::get_default_resource()*/,
              @ByVal(nullValue = "cudaStream_t(0)") cudaStream_t stream);
@Namespace("cudf::experimental::detail") public static native @Cast("bool") boolean contains(@Const @ByRef column_view col, @Const @ByRef scalar value);

/**
 * \brief  Returns a new column of type bool8 identifying for each element of \p haystack column,
 *         if that element is contained in \p needles column.
 *
 * The new column will have the same dimension and null status as the \p haystack column.  That is,
 * any element that is invalid in the \p haystack column will be invalid in the returned column.
 *
 * @throws cudf::logic_error
 * If {@code haystack.type() != needles.type()}
 *
 * \example:
 *
 *   haystack = { 10, 20, 30, 40, 50 }
 *   needles  = { 20, 40, 60, 80 }
 *
 *   result = { false, true, false, true, false }
 *
 * @param haystack  A column object
 * @param needles   A column of values to search for in {@code col}
 * @param mr        Device memory resource to use for device memory allocation
 * @param stream    Stream to use for any kernel launches.
 * @return std::unique_ptr<column> A column of bool8 elements containing
 * true if the corresponding entry in haystack is contained in needles and false
 * if it is not.
 */
@Namespace("cudf::experimental::detail") public static native @UniquePtr column contains(@Const @ByRef column_view haystack, @Const @ByRef column_view needles,
                                 device_memory_resource mr/*=rmm::mr::get_default_resource()*/,
                                 @ByVal(nullValue = "cudaStream_t(0)") cudaStream_t stream);
@Namespace("cudf::experimental::detail") public static native @UniquePtr column contains(@Const @ByRef column_view haystack, @Const @ByRef column_view needles);

 // namespace detail
 // namespace experimental
 // namespace cudf


// Parsed from <cudf/detail/null_mask.hpp>

/*
 * Copyright (c) 2019, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
// #pragma once

// #include <cudf/types.hpp>

// #include <vector>

/**
 * \copydoc cudf::segmented_count_set_bits
 *
 * @param stream [in] Optional CUDA stream on which to execute kernels
 */
@Namespace("cudf::detail") public static native @StdVector size_type segmented_count_set_bits(@Const bitmask_type bitmask,
                         @StdVector size_type indices,
                         @ByVal(nullValue = "cudaStream_t(0)") cudaStream_t stream);
@Namespace("cudf::detail") public static native @StdVector size_type segmented_count_set_bits(@Const bitmask_type bitmask,
                         @StdVector size_type indices);

/**
 * \copydoc cudf::segmented_count_unset_bits
 *
 * @param stream [in] Optional CUDA stream on which to execute kernels
 */
@Namespace("cudf::detail") public static native @StdVector size_type segmented_count_unset_bits(@Const bitmask_type bitmask,
                           @StdVector size_type indices,
                           @ByVal(nullValue = "cudaStream_t(0)") cudaStream_t stream);
@Namespace("cudf::detail") public static native @StdVector size_type segmented_count_unset_bits(@Const bitmask_type bitmask,
                           @StdVector size_type indices);

/**---------------------------------------------------------------------------*
 * \brief Concatenates {@code views[i]}'s bitmask from the bits
 * {@code [views[i].offset(), views[i].offset() + views[i].size())} for all elements
 * views[i] in views into an array
 *
 * @param views Vector of column views whose bitmask needs to be copied
 * @param dest_mask Pointer to array that contains the combined bitmask
 * of the column views
 * @param stream stream on which all memory allocations and copies
 * will be performed
 *---------------------------------------------------------------------------**/
@Namespace("cudf::detail") public static native void concatenate_masks(@StdVector column_view views,
    bitmask_type dest_mask,
    @ByVal cudaStream_t stream);

  // namespace detail

  // namespace cudf


// Parsed from <cudf/detail/hashing.hpp>

/*
 * Copyright (c) 2019, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
// #pragma once

// #include <cudf/hashing.hpp>

/** --------------------------------------------------------------------------*
 * \brief Partitions rows from the input table into multiple output tables.
 *
 * Partitions rows of {@code input} into {@code num_partitions} bins based on the hash
 * value of the columns specified by {@code columns_to_hash}. Rows partitioned into
 * the same bin are grouped consecutively in the output table. Returns a vector
 * of row offsets to the start of each partition in the output table.
 *
 * @throws std::out_of_range if index is {@code columns_to_hash} is invalid
 *
 * @param input The table to partition
 * @param columns_to_hash Indices of input columns to hash
 * @param num_partitions The number of partitions to use
 * @param mr Optional resource to use for device memory allocation
 * @param stream Optional stream to use for allocations and copies
 *
 * @return An output table and a vector of row offsets to each partition
 * -------------------------------------------------------------------------**/
@Namespace("cudf::detail") public static native @ByVal std::pair<std::unique_ptr<experimental::table>,std::vector<cudf::size_type> > hash_partition(@Const @ByRef table_view input,
               @StdVector size_type columns_to_hash,
               int num_partitions,
               device_memory_resource mr/*=rmm::mr::get_default_resource()*/,
               @ByVal(nullValue = "cudaStream_t(0)") cudaStream_t stream);
@Namespace("cudf::detail") public static native @ByVal std::pair<std::unique_ptr<experimental::table>,std::vector<cudf::size_type> > hash_partition(@Const @ByRef table_view input,
               @StdVector size_type columns_to_hash,
               int num_partitions);

/** --------------------------------------------------------------------------*
 * \brief Computes the hash value of each row in the input set of columns.
 *
 * @param input The table of columns to hash
 * @param initial_hash Optional vector of initial hash values for each column.
 * If this vector is empty then each element will be hashed as-is.
 * @param mr Optional resource to use for device memory allocation
 * @param stream Optional stream to use for allocations and copies
 *
 * @return A column where each row is the hash of a column from the input
 * -------------------------------------------------------------------------**/
@Namespace("cudf::detail") public static native @UniquePtr column hash(@Const @ByRef table_view input,
                             @Cast("uint32_t*") @StdVector IntPointer initial_hash/*={}*/,
                             device_memory_resource mr/*=rmm::mr::get_default_resource()*/,
                             @ByVal(nullValue = "cudaStream_t(0)") cudaStream_t stream);
@Namespace("cudf::detail") public static native @UniquePtr column hash(@Const @ByRef table_view input);
@Namespace("cudf::detail") public static native @UniquePtr column hash(@Const @ByRef table_view input,
                             @Cast("uint32_t*") @StdVector IntBuffer initial_hash/*={}*/,
                             device_memory_resource mr/*=rmm::mr::get_default_resource()*/,
                             @ByVal(nullValue = "cudaStream_t(0)") cudaStream_t stream);
@Namespace("cudf::detail") public static native @UniquePtr column hash(@Const @ByRef table_view input,
                             @Cast("uint32_t*") @StdVector int[] initial_hash/*={}*/,
                             device_memory_resource mr/*=rmm::mr::get_default_resource()*/,
                             @ByVal(nullValue = "cudaStream_t(0)") cudaStream_t stream);

  // namespace detail
  // namespace cudf


// Parsed from <cudf/detail/scatter.hpp>

/*
 * Copyright (c) 2019, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
// #pragma once

// #include <cudf/column/column_view.hpp>
// #include <cudf/table/table_view.hpp>
// #include <cudf/table/table.hpp>

// #include <memory>

/**
 * \brief Scatters the rows of the source table into a copy of the target table
 * according to a scatter map.
 *
 * Scatters values from the source table into the target table out-of-place,
 * returning a "destination table". The scatter is performed according to a
 * scatter map such that row {@code scatter_map[i]} of the destination table gets row
 * {@code i} of the source table. All other rows of the destination table equal
 * corresponding rows of the target table.
 *
 * The number of columns in source must match the number of columns in target
 * and their corresponding datatypes must be the same.
 *
 * A negative value {@code i} in the {@code scatter_map} is interpreted as {@code i+n}, where {@code n}
 * is the number of rows in the {@code target} table.
 * 
 * If the same index appears more than once in the scatter map, the result is
 * undefined.
 *
 * @throws {@code cudf::logic_error} if {@code check_bounds == true} and an index exists in
 * {@code scatter_map} outside the range {@code [-n, n)}, where {@code n} is the number of rows in
 * the target table. If {@code check_bounds == false}, the behavior is undefined.
 *
 * @param source The input columns containing values to be scattered into the
 * target columns
 * @param scatter_map A non-nullable column of integral indices that maps the
 * rows in the source table to rows in the target table. The size must be equal
 * to or less than the number of elements in the source columns.
 * @param target The set of columns into which values from the source_table
 * are to be scattered
 * @param check_bounds Optionally perform bounds checking on the values of
 * {@code scatter_map} and throw an error if any of its values are out of bounds.
 * @param mr The resource to use for all allocations
 * @param stream The stream to use for CUDA operations
 * @return Result of scattering values from source to target
 *---------------------------------------------------------------------------**/
@Namespace("cudf::experimental::detail") public static native @MoveUniquePtr table scatter(
    @Const @ByRef table_view source, @Const @ByRef column_view scatter_map,
    @Const @ByRef table_view target, @Cast("bool") boolean check_bounds/*=false*/,
    device_memory_resource mr/*=rmm::mr::get_default_resource()*/,
    @ByVal(nullValue = "cudaStream_t(0)") cudaStream_t stream);

/**
 * \brief Scatters a row of scalar values into a copy of the target table
 * according to a scatter map.
 *
 * Scatters values from the source row into the target table out-of-place,
 * returning a "destination table". The scatter is performed according to a
 * scatter map such that row {@code scatter_map[i]} of the destination table is
 * replaced by the source row. All other rows of the destination table equal
 * corresponding rows of the target table.
 *
 * The number of elements in source must match the number of columns in target
 * and their corresponding datatypes must be the same.
 * 
 * If the same index appears more than once in the scatter map, the result is
 * undefined.
 *
 * @throws {@code cudf::logic_error} if {@code check_bounds == true} and an index exists in
 * {@code scatter_map} outside the range {@code [-n, n)}, where {@code n} is the number of rows in
 * the target table. If {@code check_bounds == false}, the behavior is undefined.
 *
 * @param source The input scalars containing values to be scattered into the
 * target columns
 * @param indices A non-nullable column of integral indices that indicate
 * the rows in the target table to be replaced by source.
 * @param target The set of columns into which values from the source_table
 * are to be scattered
 * @param check_bounds Optionally perform bounds checking on the values of
 * {@code scatter_map} and throw an error if any of its values are out of bounds.
 * @param mr The resource to use for all allocations
 * @param stream The stream to use for CUDA operations
 * @return Result of scattering values from source to target
 *---------------------------------------------------------------------------**/
@Namespace("cudf::experimental::detail") public static native @MoveUniquePtr table scatter(
    @StdVector @UniquePtr scalar source, @Const @ByRef column_view indices,
    @Const @ByRef table_view target, @Cast("bool") boolean check_bounds/*=false*/,
    device_memory_resource mr/*=rmm::mr::get_default_resource()*/,
    @ByVal(nullValue = "cudaStream_t(0)") cudaStream_t stream);

/**
 * \brief Scatters the rows of a table to {@code n} tables according to a partition map
 *
 * Copies the rows from the input table to new tables according to the table
 * indices given by partition_map. The number of output tables is one more than
 * the maximum value in {@code partition_map}.
 * 
 * Output table {@code i} in [0, n] is empty if {@code i} does not appear in partition_map.
 * output table will be empty.
 *
 * @throws cudf::logic_error when partition_map is a non-integer type
 * @throws cudf::logic_error when partition_map is larger than input
 * @throws cudf::logic_error when partition_map has nulls
 *
 * Example:
 * input:         [{10, 12, 14, 16, 18, 20, 22, 24, 26, 28},
 *                 { 1,  2,  3,  4, null, 0, 2,  4,  6,  2}]
 * partition_map: {3,  4,  3,  1,  4,  4,  0,  1,  1,  1}
 * output:     {[{22}, {2}], 
 *              [{16, 24, 26, 28}, {4, 4, 6, 2}],
 *              [{}, {}],
 *              [{10, 14}, {1, 3}],
 *              [{12, 18, 20}, {2, null, 0}]}
 *
 * @param input Table of rows to be partitioned into a set of tables
 * tables according to {@code partition_map}
 * @param partition_map  Non-null column of integer values that map
 * each row in {@code input} table into one of the output tables
 * @param mr The resource to use for all allocations
 * @param stream The stream to use for CUDA operations
 *
 * @return A vector of tables containing the scattered rows of {@code input}.
 * {@code table} {@code i} contains all rows {@code j} from {@code input} where {@code partition_map[j] == i}.
 */
@Namespace("cudf::experimental::detail") public static native @StdVector @UniquePtr table scatter_to_tables(
    @Const @ByRef table_view input, @Const @ByRef column_view partition_map,
    device_memory_resource mr/*=rmm::mr::get_default_resource()*/,
    @ByVal(nullValue = "cudaStream_t(0)") cudaStream_t stream);

  // namespace detail
  // namespace experimental
  // namespace cudf


// Parsed from <cudf/detail/sorting.hpp>

/*
 * Copyright (c) 2019, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

// #pragma once

// #include <cudf/types.hpp>

// #include <memory>
// #include <vector>

/**---------------------------------------------------------------------------*
 * \brief Computes the row indices that would produce {@code input}  in a
 * lexicographical sorted order.
 *
 * @param input The table to sort
 * @param column_order The desired sort order for each column. Size must be
 * equal to {@code input.num_columns()} or empty. If empty, all columns will be sorted
 * in ascending order.
 * @param null_precedence The desired order of null compared to other elements
 * for each column.  Size must be equal to {@code input.num_columns()} or empty.
 * If empty, all columns will be sorted in {@code null_order::BEFORE}.
 * @param mr [in] Optional, The resource to use for all allocations
 * @param stream [in] Optional CUDA stream on which to execute kernels
 * @return std::unique_ptr<column> A non-nullable column of INT32 elements
 * containing the permuted row indices of {@code input} if it were sorted
 *---------------------------------------------------------------------------**/
@Namespace("cudf::experimental::detail") public static native @UniquePtr column sorted_order(
    @ByVal table_view input, @StdVector order column_order/*={}*/,
    @StdVector null_order null_precedence/*={}*/,
    device_memory_resource mr/*=rmm::mr::get_default_resource()*/,
    @ByVal(nullValue = "cudaStream_t(0)") cudaStream_t stream);
@Namespace("cudf::experimental::detail") public static native @UniquePtr column sorted_order(
    @ByVal table_view input);

/**
 * \copydoc cudf::experimental::sort_by_key
 *
 * @param stream [in] Optional CUDA stream on which to execute kernels
 */
@Namespace("cudf::experimental::detail") public static native @MoveUniquePtr table sort_by_key(
    @Const @ByRef table_view values, @Const @ByRef table_view keys,
    @StdVector order column_order/*={}*/,
    @StdVector null_order null_precedence/*={}*/,
    device_memory_resource mr/*=rmm::mr::get_default_resource()*/,
    @ByVal(nullValue = "cudaStream_t(0)") cudaStream_t stream);
@Namespace("cudf::experimental::detail") public static native @MoveUniquePtr table sort_by_key(
    @Const @ByRef table_view values, @Const @ByRef table_view keys);

  // namespace detail
  // namespace experimental
  // namespace cudf


// Parsed from <cudf/detail/reduction_functions.hpp>

/*
 * Copyright (c) 2019, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

// #pragma once

// #include <cudf/column/column_view.hpp>
// #include <cudf/scalar/scalar.hpp>

@Namespace("cudf::experimental::reduction") public static native @MoveUniquePtr scalar sum(
    @Const @ByRef column_view col, @Const @ByVal data_type output_dtype,
    device_memory_resource mr/*=rmm::mr::get_default_resource()*/,
    @ByVal(nullValue = "cudaStream_t(0)") cudaStream_t stream);
@Namespace("cudf::experimental::reduction") public static native @MoveUniquePtr scalar sum(
    @Const @ByRef column_view col, @Const @ByVal data_type output_dtype);
@Namespace("cudf::experimental::reduction") public static native @MoveUniquePtr scalar min(
    @Const @ByRef column_view col, @Const @ByVal data_type output_dtype,
    device_memory_resource mr/*=rmm::mr::get_default_resource()*/,
    @ByVal(nullValue = "cudaStream_t(0)") cudaStream_t stream);
@Namespace("cudf::experimental::reduction") public static native @MoveUniquePtr scalar min(
    @Const @ByRef column_view col, @Const @ByVal data_type output_dtype);
@Namespace("cudf::experimental::reduction") public static native @MoveUniquePtr scalar max(
    @Const @ByRef column_view col, @Const @ByVal data_type output_dtype,
    device_memory_resource mr/*=rmm::mr::get_default_resource()*/,
    @ByVal(nullValue = "cudaStream_t(0)") cudaStream_t stream);
@Namespace("cudf::experimental::reduction") public static native @MoveUniquePtr scalar max(
    @Const @ByRef column_view col, @Const @ByVal data_type output_dtype);
@Namespace("cudf::experimental::reduction") public static native @MoveUniquePtr scalar any(
    @Const @ByRef column_view col, @Const @ByVal data_type output_dtype,
    device_memory_resource mr/*=rmm::mr::get_default_resource()*/,
    @ByVal(nullValue = "cudaStream_t(0)") cudaStream_t stream);
@Namespace("cudf::experimental::reduction") public static native @MoveUniquePtr scalar any(
    @Const @ByRef column_view col, @Const @ByVal data_type output_dtype);
@Namespace("cudf::experimental::reduction") public static native @MoveUniquePtr scalar all(
    @Const @ByRef column_view col, @Const @ByVal data_type output_dtype,
    device_memory_resource mr/*=rmm::mr::get_default_resource()*/,
    @ByVal(nullValue = "cudaStream_t(0)") cudaStream_t stream);
@Namespace("cudf::experimental::reduction") public static native @MoveUniquePtr scalar all(
    @Const @ByRef column_view col, @Const @ByVal data_type output_dtype);
@Namespace("cudf::experimental::reduction") public static native @MoveUniquePtr scalar product(
    @Const @ByRef column_view col, @Const @ByVal data_type output_dtype,
    device_memory_resource mr/*=rmm::mr::get_default_resource()*/,
    @ByVal(nullValue = "cudaStream_t(0)") cudaStream_t stream);
@Namespace("cudf::experimental::reduction") public static native @MoveUniquePtr scalar product(
    @Const @ByRef column_view col, @Const @ByVal data_type output_dtype);
@Namespace("cudf::experimental::reduction") public static native @MoveUniquePtr scalar sum_of_squares(
    @Const @ByRef column_view col, @Const @ByVal data_type output_dtype,
    device_memory_resource mr/*=rmm::mr::get_default_resource()*/,
    @ByVal(nullValue = "cudaStream_t(0)") cudaStream_t stream);
@Namespace("cudf::experimental::reduction") public static native @MoveUniquePtr scalar sum_of_squares(
    @Const @ByRef column_view col, @Const @ByVal data_type output_dtype);

@Namespace("cudf::experimental::reduction") public static native @MoveUniquePtr scalar mean(
    @Const @ByRef column_view col, @Const @ByVal data_type output_dtype,
    device_memory_resource mr/*=rmm::mr::get_default_resource()*/,
    @ByVal(nullValue = "cudaStream_t(0)") cudaStream_t stream);
@Namespace("cudf::experimental::reduction") public static native @MoveUniquePtr scalar mean(
    @Const @ByRef column_view col, @Const @ByVal data_type output_dtype);
@Namespace("cudf::experimental::reduction") public static native @MoveUniquePtr scalar variance(
    @Const @ByRef column_view col, @Const @ByVal data_type output_dtype, @ByVal size_type ddof,
    device_memory_resource mr/*=rmm::mr::get_default_resource()*/,
    @ByVal(nullValue = "cudaStream_t(0)") cudaStream_t stream);
@Namespace("cudf::experimental::reduction") public static native @MoveUniquePtr scalar variance(
    @Const @ByRef column_view col, @Const @ByVal data_type output_dtype, @ByVal size_type ddof);
@Namespace("cudf::experimental::reduction") public static native @MoveUniquePtr scalar standard_deviation(
    @Const @ByRef column_view col, @Const @ByVal data_type output_dtype, @ByVal size_type ddof,
    device_memory_resource mr/*=rmm::mr::get_default_resource()*/,
    @ByVal(nullValue = "cudaStream_t(0)") cudaStream_t stream);
@Namespace("cudf::experimental::reduction") public static native @MoveUniquePtr scalar standard_deviation(
    @Const @ByRef column_view col, @Const @ByVal data_type output_dtype, @ByVal size_type ddof);

 // namespace reduction
 // namespace experimental
 // namespace cudf



// Parsed from <cudf/detail/scatter.cuh>

/*
 * Copyright (c) 2020, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

// #pragma once

// #include <cudf/copying.hpp>
// #include <cudf/detail/copy.hpp>
// #include <cudf/detail/gather.ch>
// #include <cudf/detail/gather.hpp>
// #include <cudf/utilities/traits.hpp>
// #include <cudf/column/column_device_view.ch>
// #include <cudf/table/table_device_view.ch>
// #include <cudf/detail/utilities/cuda.ch>
// #include <cudf/strings/detail/scatter.ch>
// #include <cudf/strings/string_view.ch>
// #include <memory>

 //namespace

/**
 * \brief Scatters the rows of the source table into a copy of the target table
 * according to a scatter map.
 *
 * Scatters values from the source table into the target table out-of-place,
 * returning a "destination table". The scatter is performed according to a
 * scatter map such that row {@code scatter_begin[i]} of the destination table gets row
 * {@code i} of the source table. All other rows of the destination table equal
 * corresponding rows of the target table.
 *
 * The number of columns in source must match the number of columns in target
 * and their corresponding datatypes must be the same.
 *
 * If the same index appears more than once in the scatter map, the result is
 * undefined. This range might have negative values, which will be modified by adding target.size()
 *
 * @throws cudf::logic_error if scatter map index is out of bounds
 * @throws cudf::logic_error if scatter_map.size() > source.num_rows()
 *
 * @param source [in] The input columns containing values to be scattered into the
 * target columns
 * @param scatter_map_begin [in] Beginning of iterator range of integer indices that has been provided.
 * @param scatter_map_end [in] End of iterator range of integer indices that has been provided.
 * source columns to rows in the target columns
 * @param target [in] The set of columns into which values from the source_table
 * are to be scattered
 * @param check_bounds [in] Optionally perform bounds checking on the values of
 * {@code scatter_map} and throw an error if any of its values are out of bounds.
 * @param mr [in] The resource to use for all allocations
 * @param stream [in] The stream to use for CUDA operations
 *
 * @return Result of scattering values from source to target
 **/
 //namespace detail
 //namespace experimental
 //namespace detail


// Parsed from <cudf/detail/iterator.cuh>

/*
 * Copyright (c) 2019, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */


/** --------------------------------------------------------------------------*
 * \brief provides column input iterator with nulls replaced with a specified value
 * \file iterator.cuh
 * 
 * The column input iterator is designed to be used as an input
 * iterator for thrust and cub.
 *
 * Usage:
 * auto iter = make_null_replacement_iterator(column, null_value);
 * 
 * The column input iterator returns only a scalar value of data at [id] or 
 * the null_replacement value passed while creating the iterator.
 * For non-null column, use 
 * auto iter = column.begin<Element>();
 * 
 * -------------------------------------------------------------------------**/

// #pragma once

// #include <cudf/column/column_device_view.ch>
// #include <cudf/scalar/scalar.hpp>

/** -------------------------------------------------------------------------*
 * \brief value accessor of column with null bitmask
 * A unary functor returns scalar value at {@code id}.
 * {@code operator() (cudf::size_type id)} computes {@code element} and valid flag at {@code id}
 * This functor is only allowed for nullable columns.
 *
 * the return value for element {@code i} will return {@code column[i]}
 * if it is valid, or {@code null_replacement} if it is null.
 *
 * @throws {@code cudf::logic_error} if the column is not nullable.
 * @throws {@code cudf::logic_error} if column datatype and Element type mismatch.
 *
 * \tparam Element The type of elements in the column
 * -------------------------------------------------------------------------**/
// Targeting ../validity_accessor.java



/**
 * \brief Constructs an iterator over a column's values that replaces null
 * elements with a specified value.
 *
 * Dereferencing the returned iterator for element {@code i} will return {@code column[i]}
 * if it is valid, or {@code null_replacement} if it is null.
 * This iterator is only allowed for nullable columns.
 *
 * @throws {@code cudf::logic_error} if the column is not nullable.
 * @throws {@code cudf::logic_error} if column datatype and Element type mismatch.
 *
 * \tparam Element The type of elements in the column
 * @param column The column to iterate
 * @param null_replacement The value to return for null elements
 * @return auto Iterator that returns valid column elements, or a null
 * replacement value for null elements.
 */


/**
 * \brief Constructs a pair iterator over a column's values and its validity.
 *
 * Dereferencing the returned iterator returns a {@code thrust::pair<Element, bool>}.
 * 
 * If an element at position {@code i} is valid (or {@code has_nulls == false}), then for {@code p = *(iter + i)}, {@code p.first} contains 
 * the value of the element at {@code i} and {@code p.second == true}.
 *
 * Else, if the element at {@code i} is null, then the value of {@code p.first} is undefined and {@code p.second == false}. 
 * {@code pair(column[i], validity)}.
 * {@code validity} is {@code true} if {@code has_nulls=false}.
 * {@code validity} is validity of the element at {@code i} if {@code has_nulls=true} and the
 * column is nullable.
 *
 * @throws {@code cudf::logic_error} if the column is nullable.
 * @throws {@code cudf::logic_error} if column datatype and Element type mismatch.
 *
 * \tparam Element The type of elements in the column
 * \tparam has_nulls boolean indicating to treat the column is nullable
 * @param column The column to iterate
 * @return auto Iterator that returns valid column elements, and validity of the
 * element in a pair
 */


/**
 * \brief Constructs an iterator over a column's validities.
 *
 * Dereferencing the returned iterator for element {@code i} will return the validity
 * of {@code column[i]}
 * This iterator is only allowed for nullable columns.
 *
 * @throws {@code cudf::logic_error} if the column is not nullable.
 *
 * @param column The column to iterate
 * @return auto Iterator that returns validities of column elements.
 */


/**
 * \brief Constructs a constant iterator over a scalar's value.
 *
 * Dereferencing the returned iterator returns a {@code Element}.
 * 
 * For {@code p = *(iter + i)}, {@code p} is the value stored in the scalar.
 *
 * @throws {@code cudf::logic_error} if scalar datatype and Element type mismatch.
 * @throws {@code cudf::logic_error} if scalar is null.
 *
 * \tparam Element The type of elements in the scalar
 * @param scalar_value The scalar to iterate
 * @return auto Iterator that returns scalar value
 */


/**
 * \brief Constructs a constant pair iterator over a scalar's value and its validity.
 *
 * Dereferencing the returned iterator returns a {@code thrust::pair<Element, bool>}.
 *  
 * If scalar is valid, then for {@code p = *(iter + i)}, {@code p.first} contains 
 * the value of the scalar and {@code p.second == true}.
 *
 * Else, if the scalar is null, then the value of {@code p.first} is undefined and {@code p.second == false}. 
 * 
 * @throws {@code cudf::logic_error} if scalar datatype and Element type mismatch.
 *
 * \tparam Element The type of elements in the scalar
 * \tparam bool unused. This template parameter exists to enforce same 
 * template interface as \ref make_pair_iterator(column_device_view const&).
 * @param scalar_value The scalar to iterate
 * @return auto Iterator that returns scalar, and validity of the scalar in a pair
 */


 //namespace detail
 //namespace experimental
 //namespace cudf

// Parsed from <cudf/detail/utilities/transform_unary_functions.cuh>

/*
 * Copyright (c) 2019, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

/** --------------------------------------------------------------------------*
 * \brief unary functions for thrust::transform_iterator
 * \file transform_unary_functions.cuh
 *
 * These are designed for using as AdaptableUnaryFunction
 * for thrust::transform_iterator.
 * For the detail of example cases,
 * @see iterator.cuh iterator_test.cu
 * -------------------------------------------------------------------------**/

// #pragma once

// #include <cudf/cudf.h>

// #include <thrust/iterator/transform_iterator.h>
// #include <thrust/pair.h>
/** -------------------------------------------------------------------------*
 * \brief intermediate struct to calculate mean and variance
 * This is an example case to output a struct from column input.
 *
 * this will be used to calculate and hold {@code sum of values}, 'sum of squares',
 * 'sum of valid count'.
 * Those will be used to compute {@code mean} (= sum / count)
 * and {@code variance} (= sum of squares / count - mean^2).
 *
 * \tparam ElementType  element data type of value and value_squared.
 * -------------------------------------------------------------------------**/

// --------------------------------------------------------------------------
// transformers

/** -------------------------------------------------------------------------*
 * \brief Transforms a scalar by first casting to another type, and then squaring the result.
 *
 * This struct transforms the output value as
 * {@code value * value}.
 *
 * This will be used to compute "sum of squares".
 *
 * \tparam  ResultType  scalar data type of output
 * -------------------------------------------------------------------------**/

/** -------------------------------------------------------------------------*
 * \brief Uses a scalar value to construct a {@code meanvar} object.
 * This transforms {@code thrust::pair<ElementType, bool>} into
 * {@code ResultType = meanvar<ElementType>} form.
 *
 * This struct transforms the value and the squared value and the count at once.
 *
 * \tparam  ElementType         scalar data type of input
 * -------------------------------------------------------------------------**/

 // namespace cudf


// Parsed from <cudf/detail/utilities/trie.cuh>

/*
 * Copyright (c) 2018, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
	 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

/**
 * \file trie.cuh  serialized trie implementation for C++/CUDA
 *
 */

// #ifndef TRIE_CUH
// #define TRIE_CUH

// #include <vector>
// #include <string>
// #include <deque>

// #include <cuda_runtime.h>
// #include <thrust/host_vector.h>

@MemberGetter public static native byte trie_terminating_character();
public static final byte trie_terminating_character = trie_terminating_character();
// Targeting ../SerialTrieNode.java




/**---------------------------------------------------------------------------*
 * \brief Create a serialized trie for cache-friendly string search
 *
 * The resulting trie is a compact array - children array size is equal to the
 * actual number of children nodes, not the size of the alphabet
 *
 * @param keys [in] Array of strings to insert into the trie
 *
 * @return A host vector of nodes representing the serialized trie
 *---------------------------------------------------------------------------**/
public static native @ByVal thrust::host_vector<SerialTrieNode> createSerializedTrie(@StdString @StdVector BytePointer keys);


/**---------------------------------------------------------------------------*
 * \brief Searches for a string in a serialized trie
 *
 * Can be executed on host or device, as long as the data is available
 *
 * @param trie [in] Pointer to the array of nodes that make up the trie
 * @param key [in] Pointer to the start of the string to find
 * @param key_len [in] Length of the string to find
 *
 * @return Boolean value, true if string is found, false otherwise
 *---------------------------------------------------------------------------**/
public static native @ByVal __host__ serializedTrieContains(@Const SerialTrieNode trie, @Cast("const char*") BytePointer key, @Cast("size_t") long key_len);
public static native @ByVal __host__ serializedTrieContains(@Const SerialTrieNode trie, String key, @Cast("size_t") long key_len);

// #endif // TRIE_CUH


// Parsed from <cudf/detail/utilities/integer_utils.hpp>

/*
 * Copyright 2019 BlazingDB, Inc.
 *     Copyright 2019 Eyal Rozenberg <eyalroz@blazingdb.com>
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

// #pragma once

/**
 * \file Utility code involving integer arithmetic
 *
 */

// #include <type_traits>
// #include <stdexcept>

/**
* Finds the smallest integer not less than {@code number_to_round} and modulo {@code S} is
* zero. This function assumes that {@code number_to_round} is non-negative and
* {@code modulus} is positive.
*/

/**
* Finds the largest integer not greater than {@code number_to_round} and modulo {@code S} is
* zero. This function assumes that {@code number_to_round} is non-negative and
* {@code modulus} is positive.
*/


/**
* Divides the left-hand-side by the right-hand-side, rounding up
* to an integral multiple of the right-hand-side, e.g. (9,5) -> 2 , (10,5) -> 2, (11,5) -> 3.
*
* @param dividend the number to divide
* @param divisor the number by which to divide
* @return The least integer multiple of {\link divisor} which is greater than or equal to
* the non-integral division dividend/divisor.
*
* \note sensitive to overflow, i.e. if dividend > std::numeric_limits<S>::max() - divisor,
* the result will be incorrect
*/



 // namespace detail

/**
* Divides the left-hand-side by the right-hand-side, rounding up
* to an integral multiple of the right-hand-side, e.g. (9,5) -> 2 , (10,5) -> 2, (11,5) -> 3.
*
* @param dividend the number to divide
* @param divisor the number of by which to divide
* @return The least integer multiple of {\link divisor} which is greater than or equal to
* the non-integral division dividend/divisor.
*
* \note will not overflow, and may _or may not_ be slower than the intuitive
* approach of using (dividend + divisor - 1) / divisor
*/


 // namespace util

 // namespace cudf


// Parsed from <cudf/detail/utilities/device_operators.cuh>

/*
 * Copyright (c) 2019, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

// #ifndef DEVICE_OPERATORS_CUH
// #define DEVICE_OPERATORS_CUH

/** ---------------------------------------------------------------------------*
 * \brief definition of the device operators
 * \file device_operators.cuh
 *
 * ---------------------------------------------------------------------------**/

// #include <cudf/types.hpp>
// #include <cudf/utilities/error.hpp>
// #include <cudf/scalar/scalar.hpp>
// #include <cudf/utilities/traits.hpp>
// #include <type_traits>
// Targeting ../DeviceSum.java


// Targeting ../DeviceCount.java



/**
 * \brief string value for sentinel which is used in min, max reduction
 * operators
 * This sentinel string value is the highest possible valid UTF-8 encoded
 * character. This serves as identity value for maximum operator on string
 * values. Also, this char pointer serves as valid device pointer of identity
 * value for minimum operator on string values.
 *
 */
@Namespace("cudf") public static native @ByRef __constant__ max_string_sentinel(int i); public static native void max_string_sentinel(int i, __constant__ setter);
@Namespace("cudf") @MemberGetter public static native __constant__ max_string_sentinel();
// Targeting ../DeviceMin.java


// Targeting ../DeviceMax.java


// Targeting ../DeviceProduct.java


// Targeting ../DeviceAnd.java


// Targeting ../DeviceOr.java


// Targeting ../DeviceXor.java



  // namespace cudf

// #endif


// Parsed from <cudf/detail/utilities/release_assert.cuh>

/*
 * Copyright (c) 2019, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

// #pragma once

// #include <cuda_runtime.h>

/**---------------------------------------------------------------------------*
 * \brief {@code assert}-like macro for device code that persists in Release builds.
 *
 * This is effectively the same as the standard {@code assert} macro, except it will
 * not be compiled out in Release builds, i.e., this macro will be present
 * regardless of the state of {@code NDEBUG}.
 *
 * Relies on the {@code __PRETTY_FUNCTION__} macro which is specific to GCC and Clang.
 *
 *---------------------------------------------------------------------------**/
// #if defined(__CUDACC_ARCH__) && (defined(__clang__) || defined(__GNUC__))
// #define __ASSERT_STR_HELPER(x) #x
// #define release_assert(e)
//   ((e) ? static_cast<void>(0)
//        : __assertfail(__ASSERT_STR_HELPER(e), __FILE__, __LINE__,
//                       __PRETTY_FUNCTION__, sizeof(char)))
// #else
// #define release_assert(e) (static_cast<void>(0))
// #endif


// Parsed from <cudf/detail/utilities/cuda.cuh>

/*
 * Copyright (c) 2019, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

// #pragma once

// #include <cudf/detail/utilities/integer_utils.hpp>
// #include <cudf/types.hpp>
// #include <cudf/utilities/error.hpp>

// #include <cub/cub.ch>
//#include <utilities/cuda_utils.hpp>

// #include <type_traits>
// #include <assert.h>
/**
 * \brief Size of a warp in a CUDA kernel.
 */
@Namespace("cudf::experimental::detail") @MemberGetter public static native @Const @ByRef size_type warp_size();
// Targeting ../grid_1d.java



/**
 * \brief Performs a sum reduction of values from the same lane across all
 * warps in a thread block and returns the result on thread 0 of the block.
 *
 * All threads in a block must call this function, but only values from the
 * threads indicated by {@code leader_lane} will contribute to the result. Similarly,
 * the returned result is only defined on {@code threadIdx.x==0}.
 *
 * \tparam block_size The number of threads in the thread block (must be less
 * than or equal to 1024)
 * \tparam leader_lane The id of the lane in the warp whose value contributes to
 * the reduction
 * \tparam T Arithmetic type
 * @param lane_value The value from the lane that contributes to the reduction
 * @return The sum reduction of the values from each lane. Only valid on
 * {@code threadIdx.x == 0}. The returned value on all other threads is undefined.
 */

/**
 * \brief for each warp in the block do a reduction (summation) of the
 * {@code __popc(bit_mask)} on a certain lane (default is lane 0).
 * @param bit_mask [in] The bit_mask to be reduced.
 * @return [out] result of each block is returned in thread 0.
 */

/**
 * \brief Get the number of elements that can be processed per thread.
 *
 * @param kernel [in] The kernel for which the elements per thread needs to be assessed
 * @param total_size [in] Number of elements
 * @param block_size [in] Expected block size
 *
 * @return cudf::size_type Elements per thread that can be processed for given specification.
 */

  // namespace detail
  // namespace experimental
  // namespace cudf


// Parsed from <cudf/detail/utilities/int_fastdiv.h>

/*
 *  Copyright 2014 Maxim Milakov
 *
 *  Licensed under the Apache License, Version 2.0 (the "License");
 *  you may not use this file except in compliance with the License.
 *  You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 *  Unless required by applicable law or agreed to in writing, software
 *  distributed under the License is distributed on an "AS IS" BASIS,
 *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 *  See the License for the specific language governing permissions and
 *  limitations under the License.
 */

// #ifndef _INT_FASTDIV_KJGIUHFG
// #define _INT_FASTDIV_KJGIUHFG
// Targeting ../int_fastdiv.java



public static native @ByVal @Name("operator /") __host__ divide(int n, @Const @ByRef int_fastdiv divisor);

public static native @ByVal @Name("operator %") __host__ mod(int n, @Const @ByRef int_fastdiv divisor);

public static native @ByVal @Name("operator /") __host__ divide(short n, @Const @ByRef int_fastdiv divisor);

public static native @ByVal @Name("operator %") __host__ mod(short n, @Const @ByRef int_fastdiv divisor);

public static native @ByVal @Name("operator /") __host__ divide(byte n, @Const @ByRef int_fastdiv divisor);

public static native @ByVal @Name("operator %") __host__ mod(byte n, @Const @ByRef int_fastdiv divisor);

// #endif


// Parsed from <cudf/detail/utilities/device_atomics.cuh>

/*
 * Copyright (c) 2019, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

// #ifndef DEVICE_ATOMICS_CUH
// #define DEVICE_ATOMICS_CUH

/** ---------------------------------------------------------------------------*
 * \brief overloads for CUDA atomic operations
 * \file device_atomics.cuh
 *
 * Provides the overloads for all of possible cudf's data types,
 * where cudf's data types are, int8_t, int16_t, int32_t, int64_t, float, double,
 * cudf::detail::timestamp_D, cudf::detail::timestamp_s, cudf::detail::timestamp_ms
 * cudf::detail::timestamp_us, cudf::detail::timestamp_ns and cudf::experimental::bool8
 * where CUDA atomic operations are, {@code atomicAdd}, {@code atomicMin}, {@code atomicMax},
 * {@code atomicCAS}.
 * {@code atomicAnd}, {@code atomicOr}, {@code atomicXor} are also supported for integer data types.
 * Also provides {@code cudf::genericAtomicOperation} which performs atomic operation
 * with the given binary operator.
 * ---------------------------------------------------------------------------**/

// #include <cudf/types.hpp>
// #include <cudf/wrappers/bool.hpp>
// #include <cudf/wrappers/timestamps.hpp>
// #include <cudf/utilities/traits.hpp>
// #include <cudf/utilities/error.hpp>
// #include <type_traits>
// #include <cudf/detail/utilities/device_operators.ch>
// #include <cudf/utilities/legacy/wrapper_types.hpp>
    // TODO: remove this if C++17 is supported.
    // `static_assert` requires a string literal at C++14.
public static final String errmsg_cast = "`long long int` has different size to `int64_t`";

    // -----------------------------------------------------------------------
    // the implementation of `genericAtomicOperation`

    // single byte atomic operation

    // 2 bytes atomic operation

    // 4 bytes atomic operation

    // 8 bytes atomic operation
// Targeting ../genericAtomicOperationImpl.java



// #if defined(__CUDA_ARCH__) && ( __CUDA_ARCH__ >= 600 )
    // `atomicAdd(double)` is supported after cuda architecture 6.0
// #endif

    // Cuda natively supports `unsigned long long int` for `atomicAdd`,
    // but doesn't supports `signed long long int`.
    // However, since the signed integer is represented as Two's complement,
    // the fundamental arithmetic operations of addition are identical to
    // those for unsigned binary numbers.
    // Then, this computes as `unsigned long long int` with `atomicAdd`
    // @sa https://en.wikipedia.org/wiki/Two%27s_complement
    // -----------------------------------------------------------------------
    // the implementation of `typesAtomicCASImpl`

    // 8 bytes atomic operation

 // namespace detail

/** -------------------------------------------------------------------------*
 * \brief compute atomic binary operation
 * reads the {@code old} located at the {@code address} in global or shared memory,
 * computes 'BinaryOp'('old', 'update_value'),
 * and stores the result back to memory at the same address.
 * These three operations are performed in one atomic transaction.
 *
 * The supported cudf types for {@code genericAtomicOperation} are:
 * int8_t, int16_t, int32_t, int64_t, float, double
 *
 * @param address [in] The address of old value in global or shared memory
 * @param val [in] The value to be computed
 * @param op [in]  The binary operator used for compute
 *
 * @return The old value at {@code address}
 * -------------------------------------------------------------------------**/

// specialization for cudf::detail::timestamp types

// specialization for cudf::experimental::bool8 types


/** -------------------------------------------------------------------------*
 * \brief Overloads for {@code atomicMin}
 * reads the {@code old} located at the {@code address} in global or shared memory,
 * computes the minimum of old and val, and stores the result back to memory
 * at the same address.
 * These three operations are performed in one atomic transaction.
 *
 * The supported cudf types for {@code atomicMin} are:
 * int8_t, int16_t, int32_t, int64_t, float, double,
 * cudf::detail::timestamp_D, cudf::detail::timestamp_s, cudf::detail::timestamp_ms
 * cudf::detail::timestamp_us, cudf::detail::timestamp_ns and cudf::experimental::bool8
 * Cuda natively supports {@code sint32}, {@code uint32}, {@code sint64}, {@code uint64}.
 * Other types are implemented by {@code atomicCAS}.
 *
 * @param address [in] The address of old value in global or shared memory
 * @param val [in] The value to be computed
 *
 * @return The old value at {@code address}
 * -------------------------------------------------------------------------**/

/** -------------------------------------------------------------------------*
 * \brief Overloads for {@code atomicMax}
 * reads the {@code old} located at the {@code address} in global or shared memory,
 * computes the maximum of old and val, and stores the result back to memory
 * at the same address.
 * These three operations are performed in one atomic transaction.
 *
 * The supported cudf types for {@code atomicMax} are:
 * int8_t, int16_t, int32_t, int64_t, float, double,
 * cudf::detail::timestamp_D, cudf::detail::timestamp_s, cudf::detail::timestamp_ms
 * cudf::detail::timestamp_us, cudf::detail::timestamp_ns and cudf::experimental::bool8
 * Cuda natively supports {@code sint32}, {@code uint32}, {@code sint64}, {@code uint64}.
 * Other types are implemented by {@code atomicCAS}.
 *
 * @param address [in] The address of old value in global or shared memory
 * @param val [in] The value to be computed
 *
 * @return The old value at {@code address}
 * -------------------------------------------------------------------------**/

/** --------------------------------------------------------------------------*
 * \brief Overloads for {@code atomicCAS}
 * reads the {@code old} located at the {@code address} in global or shared memory,
 * computes ({@code old} == {@code compare} ? {@code val} : {@code old}),
 * and stores the result back to memory at the same address.
 * These three operations are performed in one atomic transaction.
 *
 * The supported cudf types for {@code atomicCAS} are:
 * int8_t, int16_t, int32_t, int64_t, float, double,
 * cudf::detail::timestamp_D, cudf::detail::timestamp_s, cudf::detail::timestamp_ms
 * cudf::detail::timestamp_us, cudf::detail::timestamp_ns and cudf::experimental::bool8
 * Cuda natively supports {@code sint32}, {@code uint32}, {@code uint64}.
 * Other types are implemented by {@code atomicCAS}.
 *
 * @param address [in] The address of old value in global or shared memory
 * @param compare [in] The value to be compared
 * @param val [in] The value to be computed
 *
 * @return The old value at {@code address}
 * -------------------------------------------------------------------------**/

/** -------------------------------------------------------------------------*
 * \brief Overloads for {@code atomicAnd}
 * reads the {@code old} located at the {@code address} in global or shared memory,
 * computes (old & val), and stores the result back to memory at the same
 * address. These three operations are performed in one atomic transaction.
 *
 * The supported types for {@code atomicAnd} are:
 *   singed/unsigned integer 8/16/32/64 bits
 * Cuda natively supports {@code sint32}, {@code uint32}, {@code sint64}, {@code uint64}.
 *
 * @param address [in] The address of old value in global or shared memory
 * @param val [in] The value to be computed
 *
 * @return The old value at {@code address}
 * -------------------------------------------------------------------------**/

/** -------------------------------------------------------------------------*
 * \brief Overloads for {@code atomicOr}
 * reads the {@code old} located at the {@code address} in global or shared memory,
 * computes (old | val), and stores the result back to memory at the same
 * address. These three operations are performed in one atomic transaction.
 *
 * The supported types for {@code atomicOr} are:
 *   singed/unsigned integer 8/16/32/64 bits
 * Cuda natively supports {@code sint32}, {@code uint32}, {@code sint64}, {@code uint64}.
 *
 * @param address [in] The address of old value in global or shared memory
 * @param val [in] The value to be computed
 *
 * @return The old value at {@code address}
 * -------------------------------------------------------------------------**/

/** -------------------------------------------------------------------------*
 * \brief Overloads for {@code atomicXor}
 * reads the {@code old} located at the {@code address} in global or shared memory,
 * computes (old ^ val), and stores the result back to memory at the same
 * address. These three operations are performed in one atomic transaction.
 *
 * The supported types for {@code atomicXor} are:
 *   singed/unsigned integer 8/16/32/64 bits
 * Cuda natively supports {@code sint32}, {@code uint32}, {@code sint64}, {@code uint64}.
 *
 * @param address [in] The address of old value in global or shared memory
 * @param val [in] The value to be computed
 *
 * @return The old value at {@code address}
 * -------------------------------------------------------------------------**/


// #endif


// Parsed from <cudf/unary.hpp>

/*
 * Copyright (c) 2018-2020, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

// #pragma once 

// #include <memory>
// #include <cudf/types.hpp>

/** enum class cudf::experimental::unary_op */
public static final int
  SIN = 0,          // < Trigonometric sine
  COS = 1,          // < Trigonometric cosine
  TAN = 2,          // < Trigonometric tangent
  ARCSIN = 3,       // < Trigonometric sine inverse
  ARCCOS = 4,       // < Trigonometric cosine inverse
  ARCTAN = 5,       // < Trigonometric tangent inverse
  SINH = 6,         // < Hyperbolic sine
  COSH = 7,         // < Hyperbolic cosine
  TANH = 8,         // < Hyperbolic tangent
  ARCSINH = 9,      // < Hyperbolic sine inverse
  ARCCOSH = 10,      // < Hperbolic cosine inverse
  ARCTANH = 11,      // < Hyperbolic tangent inverse
  EXP = 12,          // < Exponential (base e, Euler number)
  LOG = 13,          // < Natural Logarithm (base e)
  SQRT = 14,         // < Square-root (x^0.5)
  CBRT = 15,         // < Cube-root (x^(1.0/3))
  CEIL = 16,         // < Smallest integer value not less than arg
  FLOOR = 17,        // < largest integer value not greater than arg
  ABS = 18,          // < Absolute value
  RINT = 19,         // < Rounds the floating-point argument arg to an integer value
  BIT_INVERT = 20,   // < Bitwise Not (~)
  NOT = 21;          // < Logical Not (!)

/**
 * \brief Performs unary op on all values in column
 *
 * @param input A {@code column_view} as input
 * @param op operation to perform
 * @param mr Optional, The resource to use for all allocations
 *
 * @return std::unique_ptr<cudf::column> Result of the operation
 */
@Namespace("cudf::experimental") public static native @MoveUniquePtr column unary_operation(@Const @ByRef column_view input,
                                              @Cast("cudf::experimental::unary_op") int op,
                                              device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::experimental") public static native @MoveUniquePtr column unary_operation(@Const @ByRef column_view input,
                                              @Cast("cudf::experimental::unary_op") int op);

/**
 * \brief Creates a column of {@code BOOL8} elements where for every element in {@code input} {@code true}
 * indicates the value is null and {@code false} indicates the value is valid.
 *
 * @param input A {@code column_view} as input
 * @param mr Optional, The resource to use for all allocations
 *
 * @return std::unique_ptr<cudf::column> A non-nulalble column of {@code BOOL8} elements with {@code true} representing {@code null} values.
 */
@Namespace("cudf::experimental") public static native @MoveUniquePtr column is_null(@Const @ByRef column_view input,
                                      device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::experimental") public static native @MoveUniquePtr column is_null(@Const @ByRef column_view input);

/**
 * \brief Creates a column of {@code BOOL8} elements where for every element in {@code input} {@code true}
 * indicates the value is valid and {@code false} indicates the value is null.
 *
 * @param input A {@code column_view} as input
 * @param mr Optional, The resource to use for all allocations
 *
 * @return std::unique_ptr<cudf::column> A non-nulalble column of {@code BOOL8} elements with {@code false} representing {@code null} values.
 */
@Namespace("cudf::experimental") public static native @MoveUniquePtr column is_valid(@Const @ByRef column_view input,
                                       device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::experimental") public static native @MoveUniquePtr column is_valid(@Const @ByRef column_view input);

/**
 * \brief  Casts data from dtype specified in input to dtype specified in output.
 * Supports only fixed-width types.
 *
 * @param column_view Input column
 * @param out_type Desired datatype of output column
 * @param mr Optional, The resource to use for all allocations
 *
 * @return unique_ptr<column> Result of the cast operation
 * @throws cudf::logic_error if {@code out_type} is not a fixed-width type
 */
@Namespace("cudf::experimental") public static native @UniquePtr column cast(@Const @ByRef column_view input, @ByVal data_type out_type,
                             device_memory_resource mr/*=rmm::mr::get_default_resource()*/);

/**
 * \brief Creates a column of {@code BOOL8} elements indicating the presence of {@code NaN} values
 * in a column of floating point values.
 * The output element at row {@code i} is {@code true} if the element in {@code input} at row i is {@code NAN}, else {@code false}
 *
 * @throws cudf::logic_error if {@code input} is a non-floating point type
 *
 * @param input A column of floating-point elements
 * @param mr Optional, The resource to use for allocating the device memory in the returned column.
 *
 * @return unique_ptr<column> A non-nulalble column of {@code BOOL8} elements with {@code true}
 * representing {@code NAN} values
 */
@Namespace("cudf::experimental") public static native @UniquePtr column is_nan(@Const @ByRef column_view input,
                               device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::experimental") public static native @UniquePtr column is_nan(@Const @ByRef column_view input);

/**
 * \brief Creates a column of {@code BOOL8} elements indicating the absence of {@code NaN} values
 * in a column of floating point values.
 * The output element at row {@code i} is {@code false} if the element in {@code input} at row i is {@code NAN}, else {@code true}
 *
 * @throws cudf::logic_error if {@code input} is a non-floating point type
 *
 * @param input A column of floating-point elements
 * @param mr Optional, The resource to use for allocating the device memory in the returned column.
 *
 * @return unique_ptr<column> A non-nulalble column of {@code BOOL8} elements with {@code false}
 * representing {@code NAN} values
 */
@Namespace("cudf::experimental") public static native @UniquePtr column is_not_nan(@Const @ByRef column_view input,
                                 device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::experimental") public static native @UniquePtr column is_not_nan(@Const @ByRef column_view input);

 // namespace experimental
 // namespace cudf


// Parsed from <cudf/types.hpp>

/*
 * Copyright (c) 2018-2019, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

// #pragma once

// #ifdef __CUDACC__
public static native @MemberGetter int CUDA_HOST_DEVICE_CALLABLE();
public static final int CUDA_HOST_DEVICE_CALLABLE = CUDA_HOST_DEVICE_CALLABLE();
public static native @MemberGetter int CUDA_DEVICE_CALLABLE();
public static final int CUDA_DEVICE_CALLABLE = CUDA_DEVICE_CALLABLE();
// #else
// #endif

// #include <cstddef>
// #include <cstdint>

/**---------------------------------------------------------------------------*
 * \file types.hpp
 * \brief Type declarations for libcudf.
 *
 *---------------------------------------------------------------------------**/

/**---------------------------------------------------------------------------*
 * \brief Forward declaration of cudaStream_t
 *---------------------------------------------------------------------------**/

// Targeting ../device_buffer.java


// Targeting ../device_memory_resource.java


@Namespace("rmm::mr") public static native device_memory_resource get_default_resource();
  // namespace mr

  // namespace rmm

// Forward declaration


/**---------------------------------------------------------------------------*
 * \brief Indicates an unknown null count.
 *
 * Use this value when constructing any column-like object to indicate that
 * the null count should be computed on the first invocation of {@code null_count()}.
 *---------------------------------------------------------------------------**/
@Namespace("cudf") @MemberGetter public static native @Const @ByRef size_type UNKNOWN_NULL_COUNT();

/**---------------------------------------------------------------------------*
 * \brief Indicates the order in which elements should be sorted.
 *---------------------------------------------------------------------------**/
/** enum class cudf::order */
public static final boolean
  /** Elements ordered from small to large */
  ASCENDING = 0,
  /** Elements ordered from large to small */
  DESCENDING = 1;

/**---------------------------------------------------------------------------*
 * \brief Indicates how null values compare against all other values.
 *---------------------------------------------------------------------------**/
/** enum class cudf::null_order */
public static final boolean
  /** NULL values ordered *after* all other values */
  AFTER = 0,
  /** NULL values ordered *before* all other values */
  BEFORE = 1;
// Targeting ../order_info.java



/**---------------------------------------------------------------------------*
 * \brief Controls the allocation/initialization of a null mask.
 *---------------------------------------------------------------------------**/
/** enum cudf::mask_state */
public static final int
  /** Null mask not allocated, (all elements are valid) */
  UNALLOCATED = 0,
  /** Null mask allocated, but not initialized */
  UNINITIALIZED = 1,
  /** Null mask allocated, initialized to all elements valid */
  ALL_VALID = 2,
  /** Null mask allocated, initialized to all elements NULL */
  ALL_NULL = 3;
/**
 * \brief Interpolation method to use when the desired quantile lies between
 * two data points i and j
 *
 */
/** enum class cudf::experimental::interpolation */
public static final int
    /** Linear interpolation between i and j */
    LINEAR = 0,
    /** Lower data point (i) */
    LOWER = 1,
    /** Higher data point (j) */
    HIGHER = 2,
    /** (i + j)/2 */
    MIDPOINT = 3,
    /** i or j, whichever is nearest */
    NEAREST = 4;

/**---------------------------------------------------------------------------*
 * \brief Identifies a column's logical element type
 *---------------------------------------------------------------------------**/
/** enum cudf::type_id */
public static final int
  /** Always null with no underlying data */
  EMPTY = 0,
  /** 1 byte signed integer */
  INT8 = 1,
  /** 2 byte signed integer */
  INT16 = 2,
  /** 4 byte signed integer */
  INT32 = 3,
  /** 8 byte signed integer */
  INT64 = 4,
  /** 4 byte floating point */
  FLOAT32 = 5,
  /** 8 byte floating point */
  FLOAT64 = 6,
  /** Boolean using one byte per value, 0 == false, else true */
  BOOL8 = 7,
  /** days since Unix Epoch in int32 */
  TIMESTAMP_DAYS = 8,
  /** duration of seconds since Unix Epoch in int64 */
  TIMESTAMP_SECONDS = 9,
  /** duration of milliseconds since Unix Epoch in int64 */
  TIMESTAMP_MILLISECONDS = 10,
  /** duration of microseconds since Unix Epoch in int64 */
  TIMESTAMP_MICROSECONDS = 11,
  /** duration of nanoseconds since Unix Epoch in int64 */
  TIMESTAMP_NANOSECONDS = 12,
  /** Categorial/Dictionary type */
  CATEGORY = 13,
  /** String elements */
  STRING = 14,
  // `NUM_TYPE_IDS` must be last!
  /** Total number of type ids */
  NUM_TYPE_IDS = 15;
// Targeting ../data_type.java



/**---------------------------------------------------------------------------*
 * \brief Compares two {@code data_type} objects for equality.
 *
 * // TODO Define exactly what it means for two {@code data_type}s to be equal. e.g.,
 * are two timestamps with different resolutions equal? How about decimals with
 * different scale/precision?
 *
 * @param lhs The first {@code data_type} to compare
 * @param rhs The second {@code data_type} to compare
 * @return true {@code lhs} is equal to {@code rhs}
 * @return false {@code lhs} is not equal to {@code rhs}
 *---------------------------------------------------------------------------**/
@Namespace("cudf") public static native @Cast("bool") @Name("operator ==") boolean equals(@Const @ByRef data_type lhs, @Const @ByRef data_type rhs);

/**
 * \brief Returns the size in bytes of elements of the specified {@code data_type}
 *
 * \note Only fixed-width types are supported
 *
 * @throws cudf::logic_error if {@code is_fixed_width(element_type) == false}
 *
 * @return Size in bytes of an element of the specified {@code data_type}
 */
@Namespace("cudf") public static native @ByVal size_t size_of(@ByVal data_type t);

  // namespace cudf


// Parsed from <cudf/round_robin.hpp>

/*
 * Copyright (c) 2019-2020, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

// #pragma once

// #include <vector>
// #include <cudf/cudf.h>
// #include <cudf/types.hpp>

/**
 * \brief Round-robin partition.
 * 
 * Returns a new table with rows re-arranged into partition groups and
 * a vector of row offsets to the start of each partition in the output table.
 * Rows are assigned partitions based on their row index in the table,
 * in a round robin fashion.
 *
 * @throws cudf::logic_error if num_partitions <= 1 
 * @throws cudf::logic_error if start_partition >= num_partitions.
 *
 * A good analogy for the algorithm is dealing out cards:
 *
 *  1. The deck of cards is represented as the rows in the table.
 *  2. The number of partitions is the number of players being dealt cards.
 *  3. the start_partition indicates which player starts getting cards first.
 *
 * The algorithm has two outcomes:
 *
 *  (a) Another deck of cards formed by stacking each 
 *      player's cards back into a deck again, 
 *      preserving the order of cards dealt to each player, 
 *      starting with player 0.
 *  (b) A vector into the output deck indicating where a player's cards start.
 *
 * A player's deck (partition) is the range of cards starting 
 * at the corresponding offset and ending at the next player's 
 * starting offset or the last card in the deck if it's the last player.
 *
 * When num_partitions > nrows, we have more players than cards. 
 * We start dealing to the first indicated player and continuing 
 * around the players until we run out of cards before we run out of players. 
 * Players that did not get any cards are represented by
 * offset[i] == offset[i+1] or
 * offset[i] == table.num_rows() if i == num_partitions-1
 * meaning there are no cards (rows) in their deck (partition).
 *
 * Example 1:
 * input:
 * table => col 1 {0, ..., 12}
 * num_partitions = 3
 * start_partition = 0
 * 
 * output: pair<table, partition_offsets>
 * table => col 1 {0,3,6,9,12,1,4,7,10,2,5,8,11}
 * partition_offsets => {0,5,9}
 *
 * Example 2:
 * input:
 * table => col 1 {0, ..., 12}
 * num_partitions = 3
 * start_partition = 1
 * 
 * output: pair<table, partition_offsets>
 * table => col 1 {2,5,8,11,0,3,6,9,12,1,4,7,10}
 * partition_offsets => {0,4,9}
 * 
 * Example 3:
 * input:
 * table => col 1 {0, ..., 10}
 * num_partitions = 3
 * start_partition = 0
 * 
 * output: pair<table, partition_offsets>
 * table => col 1 {0,3,6,9,1,4,7,10,2,5,8}
 * partition_offsets => {0,4,8}
 *
 * Example 4:
 * input:
 * table => col 1 {0, ..., 10}
 * num_partitions = 3
 * start_partition = 1
 * 
 * output: pair<table, partition_offsets>
 * table => col 1 {2,5,8,0,3,6,9,1,4,7,10}
 * partition_offsets => {0,3,7}
 *
 * Example 5:
 * input:
 * table => col 1 {0, ..., 10}
 * num_partitions = 3
 * start_partition = 2
 * 
 * output: pair<table, partition_offsets>
 * table => col 1 {1,4,7,10,2,5,8,0,3,6,9}
 * partition_offsets => {0,4,7}
 *
 * Example 6:
 * input:
 * table => col 1 {0, ..., 10}
 * num_partitions = 15 > num_rows = 11
 * start_partition = 2
 * 
 * output: pair<table, partition_offsets>
 * table => col 1 {0,1,2,3,4,5,6,7,8,9,10}
 * partition_offsets => {0,0,0,1,2,3,4,5,6,7,8,9,10,11,11}
 *
 * Example 7:
 * input:
 * table => col 1 {0, ..., 10}
 * num_partitions = 15 > num_rows = 11
 * start_partition = 10
 * 
 * output: pair<table, partition_offsets>
 * table => col 1 {5,6,7,8,9,10,0,1,2,3,4}
 * partition_offsets => {0,1,2,3,4,5,6,6,6,6,6,7,8,9,10}
 *
 * Example 8:
 * input:
 * table => col 1 {0, ..., 10}
 * num_partitions = 15 > num_rows = 11
 * start_partition = 14
 * 
 * output: pair<table, partition_offsets>
 * table => col 1 {1,2,3,4,5,6,7,8,9,10,0}
 * partition_offsets => {0,1,2,3,4,5,6,7,8,9,10,10,10,10,10}
 *
 * Example 9:
 * input:
 * table => col 1 {0, ..., 10}
 * num_partitions = 11 == num_rows = 11
 * start_partition = 2
 * 
 * output: pair<table, partition_offsets>
 * table => col 1 {9,10,0,1,2,3,4,5,6,7,8}
 * partition_offsets => {0,1,2,3,4,5,6,7,8,9,10}
 *
 * @param input [in] The input table to be round-robin partitioned
 * @param num_partitions [in] Number of partitions for the table
 * @param start_partition [in] Index of the 1st partition
 * @param mr [in] Device memory allocator
 *
 * @return A std::pair consisting of an unique_ptr to the partitioned table 
 * and the partition offsets for each partition within the table.
 */
@Namespace("cudf::experimental") public static native @ByVal std::pair<std::unique_ptr<cudf::experimental::table>,std::vector<cudf::size_type> > round_robin_partition(@Const @ByRef table_view input,
                      @ByVal size_type num_partitions,
                      @ByVal(nullValue = "cudf::size_type(0)") size_type start_partition,
                      device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::experimental") public static native @ByVal std::pair<std::unique_ptr<cudf::experimental::table>,std::vector<cudf::size_type> > round_robin_partition(@Const @ByRef table_view input,
                      @ByVal size_type num_partitions);
  
  // namespace experimental
  // namespace cudf


// Parsed from <cudf/transform.hpp>

/*
 * Copyright (c) 2019, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

// #pragma once

// #include <cudf/types.hpp>

// #include <memory>

/**
 * \brief Creates a new column by applying a unary function against every
 * element of an input column.
 *
 * Computes:
 * {@code out[i] = F(in[i])}
 * 
 * The output null mask is the same is the input null mask so if input[i] is 
 * null then output[i] is also null
 *
 * @param input         An immutable view of the input column to transform
 * @param unary_udf     The PTX/CUDA string of the unary function to apply
 * @param outout_type   The output type that is compatible with the output type in the UDF
 * @param is_ptx        true: the UDF is treated as PTX code; false: the UDF is treated as CUDA code
 * @param mr            The memory resource to use for for all device allocations
 * @return cudf::column The column resulting from applying the unary function to
 *                      every element of the input
 **/
@Namespace("cudf::experimental") public static native @MoveUniquePtr column transform(
  @Const @ByRef column_view input,
  @StdString BytePointer unary_udf,
  @ByVal data_type output_type,
  @Cast("bool") boolean is_ptx,
  device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::experimental") public static native @MoveUniquePtr column transform(
  @Const @ByRef column_view input,
  @StdString String unary_udf,
  @ByVal data_type output_type,
  @Cast("bool") boolean is_ptx,
  device_memory_resource mr/*=rmm::mr::get_default_resource()*/);


/**
 * \brief Creates a null_mask from {@code input} by converting {@code NaN} to null and
 * preserving existing null values and also returns new null_count.
 *
 * @throws {@code cudf::logic_error} if {@code input.type()} is a non-floating type
 *
 * @param input         An immutable view of the input column of floating-point type
 * @param mr            The memory resource to use for for all device allocations
 * @return A pair containing a {@code device_buffer} with the new bitmask and it's
 * null count obtained by replacing {@code NaN} in {@code input} with null.
 **/
@Namespace("cudf::experimental") public static native @ByVal PairOfUniquePtrRmmDeviceBufferCudfSizeType nans_to_nulls(@Const @ByRef column_view input,
              device_memory_resource mr/*=rmm::mr::get_default_resource()*/);


/**
 * \brief Creates a bitmask from a column of boolean elements.
 *
 * If element {@code i} in {@code input} is {@code true}, bit {@code i} in the resulting mask is set ({@code 1}). Else,
 * if element {@code i} is {@code false} or null, bit {@code i} is unset ({@code 0}). 
 *
 *
 * @throws {@code cudf::logic_error} if {@code input.type()} is a non-boolean type
 *
 * @param input        Boolean elements to convert to a bitmask. 
 * @param mr            The memory resource used to allocate the returned bitmask. 
 * @return A pair containing a {@code device_buffer} with the new bitmask and it's
 * null count obtained from input considering {@code true} represent {@code valid}/{@code 1} and
 * {@code false} represent {@code invalid}/{@code 0}.
 **/
@Namespace("cudf::experimental") public static native @ByVal PairOfUniquePtrRmmDeviceBufferCudfSizeType bools_to_mask(@Const @ByRef column_view input,
                  device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
  // namespace experimental
  // namespace cudf


// Parsed from <cudf/reshape.hpp>

/*
 * Copyright (c) 2020, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

// #pragma once

// #include <memory>
// #include <cudf/column/column.hpp>
// #include <cudf/table/table_view.hpp>
// #include "cudf/types.hpp"

/**
 * \brief Interleave columns of a table into a single column.
 *
 * Converts the column major table {@code input} into a row major column.
 * Example:
 * <pre>{@code
 * in     = [[A1, A2, A3], [B1, B2, B3]]
 * return = [A1, B1, A2, B2, A3, B3]
 * }</pre>
 *
 * @throws cudf::logic_error if input contains no columns.
 * @throws cudf::logic_error if input columns dtypes are not identical.
 *
 * @param input [in] Table containing columns to interleave.
 *
 * @return The interleaved columns as a single column
 */
@Namespace("cudf::experimental") public static native @MoveUniquePtr column interleave_columns(@Const @ByRef table_view input,
                   device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::experimental") public static native @MoveUniquePtr column interleave_columns(@Const @ByRef table_view input);

/*
 * @brief Repeats the rows from `input` table `count` times to form a new table.
 * 
 * `output.num_columns() == input.num_columns()`
 * `output.num_rows() == input.num_rows() * count`
 *
 * input  = [[8, 4, 7], [5, 2, 3]]
 * count  = 2
 * return = [[8, 4, 7, 8, 4, 7], [5, 2, 3, 5, 2, 3]]
 *
 * @param[in] input Table containing rows to be repeated.
 * @param[in] count Number of times to tile "rows". Must be non-negative.
 *
 * @return The table containing the tiled "rows".
 */
@Namespace("cudf::experimental") public static native @UniquePtr table tile(@Const @ByRef table_view input,
     @ByVal size_type count,
     device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::experimental") public static native @UniquePtr table tile(@Const @ByRef table_view input,
     @ByVal size_type count);

 // namespace experimental
 // namespace cudf


// Parsed from <cudf/rolling.hpp>

/*
 * Copyright (c) 2019-2020, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

// #pragma once

// #include <cudf/types.hpp>

// #include <memory>

/**
 * \brief  Applies a fixed-size rolling window function to the values in a column.
 *
 * This function aggregates values in a window around each element i of the input column, and
 * invalidates the bit mask for element i if there are not enough observations. The window size is
 * static (the same for each element). This matches Pandas' API for DataFrame.rolling with a few
 * notable differences:
 * - instead of the center flag it uses a two-part window to allow for more flexible windows.
 *   The total window size = {@code preceding_window + following_window + 1}. Element {@code i} uses elements
 *   {@code [i-preceding_window, i+following_window]} to do the window computation.
 * - instead of storing NA/NaN for output rows that do not meet the minimum number of observations
 *   this function updates the valid bitmask of the column to indicate which elements are valid.
 * 
 * The returned column for {@code op == COUNT} always has {@code INT32} type. All other operators return a 
 * column of the same type as the input. Therefore it is suggested to convert integer column types
 * (especially low-precision integers) to {@code FLOAT32} or {@code FLOAT64} before doing a rolling {@code MEAN}.
 *
 * @param input_col [in] The input column
 * @param preceding_window [in] The static rolling window size in the backward direction.
 * @param following_window [in] The static rolling window size in the forward direction.
 * @param min_periods [in] Minimum number of observations in window required to have a value,
 *                        otherwise element {@code i} is null.
 * @param op [in] The rolling window aggregation type (SUM, MAX, MIN, etc.)
 *
 * @return   A nullable output column containing the rolling window results
 **/
@Namespace("cudf::experimental") public static native @MoveUniquePtr column rolling_window(@Const @ByRef column_view input,
                                       @ByVal size_type preceding_window,
                                       @ByVal size_type following_window,
                                       @ByVal size_type min_periods,
                                       @UniquePtr aggregation aggr,
                                       device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::experimental") public static native @MoveUniquePtr column rolling_window(@Const @ByRef column_view input,
                                       @ByVal size_type preceding_window,
                                       @ByVal size_type following_window,
                                       @ByVal size_type min_periods,
                                       @UniquePtr aggregation aggr);

/**
 * \brief  Applies a variable-size rolling window function to the values in a column.
 *
 * This function aggregates values in a window around each element i of the input column, and
 * invalidates the bit mask for element i if there are not enough observations. The window size is
 * dynamic (varying for each element). This matches Pandas' API for DataFrame.rolling with a few
 * notable differences:
 * - instead of the center flag it uses a two-part window to allow for more flexible windows.
 *   The total window size = {@code preceding_window + following_window + 1}. Element {@code i} uses elements
 *   {@code [i-preceding_window, i+following_window]} to do the window computation.
 * - instead of storing NA/NaN for output rows that do not meet the minimum number of observations
 *   this function updates the valid bitmask of the column to indicate which elements are valid.
 * - support for dynamic rolling windows, i.e. window size can be specified for each element using
 *   an additional array.
 * 
 * The returned column for {@code op == COUNT} always has INT32 type. All other operators return a 
 * column of the same type as the input. Therefore it is suggested to convert integer column types
 * (especially low-precision integers) to {@code FLOAT32} or {@code FLOAT64} before doing a rolling {@code MEAN}.
 * 
 * @throws cudf::logic_error if window column type is not INT32
 *
 * @param input_col [in] The input column
 * @param preceding_window [in] A non-nullable column of INT32 window sizes in the forward direction.
 *                             {@code preceding_window[i]} specifies preceding window size for element {@code i}.
 * @param following_window [in] A non-nullable column of INT32 window sizes in the backward direction.
 *                             {@code following_window[i]} specifies following window size for element {@code i}.
 * @param min_periods [in] Minimum number of observations in window required to have a value,
 *                        otherwise element {@code i} is null.
 * @param op [in] The rolling window aggregation type (sum, max, min, etc.)
 *
 * @return   A nullable output column containing the rolling window results
 **/
@Namespace("cudf::experimental") public static native @MoveUniquePtr column rolling_window(@Const @ByRef column_view input,
                                       @Const @ByRef column_view preceding_window,
                                       @Const @ByRef column_view following_window,
                                       @ByVal size_type min_periods,
                                       @UniquePtr aggregation aggr,
                                       device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::experimental") public static native @MoveUniquePtr column rolling_window(@Const @ByRef column_view input,
                                       @Const @ByRef column_view preceding_window,
                                       @Const @ByRef column_view following_window,
                                       @ByVal size_type min_periods,
                                       @UniquePtr aggregation aggr);

 // namespace experimental 
 // namespace cudf


// Parsed from <cudf/stream_compaction.hpp>

/*
 * Copyright (c) 2019, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

// #pragma once

// #include <cudf/types.hpp>

/**
 * \brief Filters a table to remove null elements.
 *
 * Filters the rows of the {@code input} considering specified columns indicated in
 * {@code keys} for validity / null values.
 *
 * Given an input table_view, row {@code i} from the input columns is copied to
 * the output if the same row {@code i} of \p keys has at least \p keep_threshold
 * non-null fields.
 *
 * This operation is stable: the input order is preserved in the output.
 *
 * Any non-nullable column in the input is treated as all non-null.
 *
 * \example input   {col1: {1, 2,    3,    null},
 *                   col2: {4, 5,    null, null},
 *                   col3: {7, null, null, null}}
 *          keys = {0, 1, 2} // All columns
 *          keep_threshold = 2
 *
 *          output {col1: {1, 2}
 *                  col2: {4, 5}
 *                  col3: {7, null}}
 *
 * \note if \p input.num_rows() is zero, or \p keys is empty or has no nulls,
 * there is no error, and an empty {@code table} is returned
 *
 * @param input [in] The input {@code table_view} to filter.
 * @param keys [in]  vector of indices representing key columns from {@code input}
 * @param keep_threshold [in] The minimum number of non-null fields in a row
 *                           required to keep the row.
 * @param mr [in] Optional, The resource to use for all allocations
 * @return unique_ptr<table> Table containing all rows of the {@code input} with at least \p keep_threshold non-null fields in \p keys.
 */
@Namespace("cudf::experimental") public static native @UniquePtr table drop_nulls(@Const @ByRef table_view input,
               @StdVector size_type keys,
               @ByVal size_type keep_threshold,
               device_memory_resource mr/*=rmm::mr::get_default_resource()*/);

/**
 * \brief Filters a table to remove null elements.
 *
 * \example input   {col1: {1, 2,    3,    null},
 *                   col2: {4, 5,    null, null},
 *                   col3: {7, null, null, null}}
 *          keys = {0, 1, 2} //All columns
 *
 *          output {col1: {1}
 *                  col2: {4}
 *                  col3: {7}}
 *
 * \overload drop_nulls
 *
 * Same as drop_nulls but defaults keep_threshold to the number of columns in
 * \p keys.
 *
 * @param input [in] The input {@code table_view} to filter.
 * @param keys [in]  vector of indices representing key columns from {@code input}
 * @param mr [in] Optional, The resource to use for all allocations
 * @return unique_ptr<table> Table containing all rows of the {@code input} without nulls in the columns of \p keys.
 */
@Namespace("cudf::experimental") public static native @UniquePtr table drop_nulls(@Const @ByRef table_view input,
               @StdVector size_type keys,
               device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::experimental") public static native @UniquePtr table drop_nulls(@Const @ByRef table_view input,
               @StdVector size_type keys);

/**
 * \brief Filters {@code input} using {@code boolean_mask} of boolean values as a mask.
 *
 * Given an input {@code table_view} and a mask {@code column_view}, an element {@code i} from
 * each column_view of the {@code input} is copied to the corresponding output column
 * if the corresponding element {@code i} in the mask is non-null and {@code true}.
 * This operation is stable: the input order is preserved.
 *
 * \note if \p input.num_rows() is zero, there is no error, and an empty table
 * is returned.
 *
 * @throws cudf::logic_error if The {@code input} size  and {@code boolean_mask} size mismatches.
 * @throws cudf::logic_error if {@code boolean_mask} is not {@code BOOL8} type.
 *
 * @param input [in] The input table_view to filter
 * @param boolean_mask [in] A nullable column_view of type BOOL8 used
 * as a mask to filter the {@code input}.
 * @param mr [in] Optional, The resource to use for all allocations
 * @return unique_ptr<table> Table containing copy of all rows of \p input passing
 * the filter defined by \p boolean_mask.
 */
@Namespace("cudf::experimental") public static native @UniquePtr table apply_boolean_mask(@Const @ByRef table_view input,
                       @Const @ByRef column_view boolean_mask,
                       device_memory_resource mr/*=rmm::mr::get_default_resource()*/);

/**
 * \brief Choices for drop_duplicates API for retainment of duplicate rows
 */
/** enum class cudf::experimental::duplicate_keep_option */
public static final int
  /** Keeps first duplicate row and unique rows */
  KEEP_FIRST = 0,
  /** Keeps last  duplicate row and unique rows */
  KEEP_LAST = 1,
  /** Keeps only unique rows are kept */
  KEEP_NONE = 2;

/**
 * \brief Create a new table without duplicate rows
 *
 * Given an {@code input} table_view, each row is copied to output table if the corresponding
 * row of {@code keys} columns is unique, where the definition of unique depends on the value of \p keep:
 * - KEEP_FIRST: only the first of a sequence of duplicate rows is copied
 * - KEEP_LAST: only the last of a sequence of duplicate rows is copied
 * - KEEP_NONE: no duplicate rows are copied
 *
 * @throws cudf::logic_error if The {@code input} row size mismatches with {@code keys}.
 *
 * @param input [in]           input table_view to copy only unique rows
 * @param keys [in]            vector of indices representing key columns from {@code input}
 * @param keep [in]            keep first entry, last entry, or no entries if duplicates found
 * @param nulls_are_equal [in] flag to denote nulls are equal if true,
 * nulls are not equal if false
 * @param mr [in] Optional, The resource to use for all allocations
 *
 * @return unique_ptr<table> Table with unique rows as per specified {@code keep}.
 */
@Namespace("cudf::experimental") public static native @UniquePtr table drop_duplicates(@Const @ByRef table_view input,
                    @StdVector size_type keys,
                    @Cast("const cudf::experimental::duplicate_keep_option") int keep,
                    @Cast("const bool") boolean nulls_are_equal/*=true*/,
                    device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::experimental") public static native @UniquePtr table drop_duplicates(@Const @ByRef table_view input,
                    @StdVector size_type keys,
                    @Cast("const cudf::experimental::duplicate_keep_option") int keep);

/**
 * \brief Count the unique elements in the column_view
 *
 * Given an input column_view, number of unique elements in this column_view is returned
 *
 * If both {@code ignore_nulls} and {@code nan_as_null} are true, both {@code NaN} and {@code null}
 * values are ignored.
 * If {@code ignore_nulls} is true and {@code nan_as_null} is false, only {@code null} is
 * ignored, {@code NaN} is considered in unique count.
 *
 * @param input [in]         The column_view whose unique elements will be counted.
 * @param ignore_nulls [in]  flag to ignore {@code null} in unique count if true
 * @param nan_as_null [in]   flag to consider {@code NaN==null} if true.
 * @param mr [in] Optional, The resource to use for all allocations
 *
 * @return number of unique elements
 */
@Namespace("cudf::experimental") public static native @ByVal size_type unique_count(@Const @ByRef column_view input,
                             @Cast("const bool") boolean ignore_nulls,
                             @Cast("const bool") boolean nan_as_null,
                             device_memory_resource mr/*=rmm::mr::get_default_resource()*/);

 // namespace experimental
 // namespace cudf


// Parsed from <cudf/binaryop.hpp>

/*
 * Copyright (c) 2019, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

// #pragma once

// #include <cudf/column/column.hpp>
// #include <cudf/scalar/scalar.hpp>

// #include <memory>

/**
 * \brief Types of binary operations that can be performed on data.
 */
/** enum class cudf::experimental::binary_operator */
public static final int
  /** operator + */
  ADD = 0,
  /** operator - */
  SUB = 1,
  /** operator * */
  MUL = 2,
  /** operator / using common type of lhs and rhs */
  DIV = 3,
  /** operator / after promoting type to floating point */
  TRUE_DIV = 4,
  /** operator / after promoting to 64 bit floating point and then
 *  flooring the result */
  FLOOR_DIV = 5,
  /** operator % */
  MOD = 6,
  /** operator % but following python's sign rules for negatives */
  PYMOD = 7,
  /** lhs ^ rhs */
  POW = 8,
  /** operator == */
  EQUAL = 9,
  /** operator != */
  NOT_EQUAL = 10,
  /** operator < */
  LESS = 11,
  /** operator > */
  GREATER = 12,
  /** operator <= */
  LESS_EQUAL = 13,
  /** operator >= */
  GREATER_EQUAL = 14,
  /** operator & */
  BITWISE_AND = 15,
  /** operator | */
  BITWISE_OR = 16,
  /** operator ^ */
  BITWISE_XOR = 17,
  /** operator && */
  LOGICAL_AND = 18,
  /** operator || */
  LOGICAL_OR = 19,
  /** operator x,y  x is null ? y : x */
  COALESCE = 20,
  /** generic binary operator to be generated with input
 *  ptx code */
  GENERIC_BINARY = 21,
  /** invalid operation */
  INVALID_BINARY = 22;

/**
 * \brief Performs a binary operation between a scalar and a column.
 *
 * The output contains the result of op(lhs, rhs[i]) for all 0 <= i < rhs.size()
 * The scalar is the left operand and the column elements are the right operand.
 * This distinction is significant in case of non-commutative binary operations
 *
 * Regardless of the operator, the validity of the output value is the logical
 * AND of the validity of the two operands
 *
 * @param lhs         The left operand scalar
 * @param rhs         The right operand column
 * @param output_type The desired data type of the output column
 * @param mr          Memory resource for allocating output column
 * @return std::unique_ptr<column> Output column
 * @throws cudf::logic_error if \p lhs and \p rhs dtypes aren't numeric
 * @throws cudf::logic_error if \p output_type dtype isn't numeric
 */
@Namespace("cudf::experimental") public static native @MoveUniquePtr column binary_operation(
    @Const @ByRef scalar lhs,
    @Const @ByRef column_view rhs,
    @Cast("cudf::experimental::binary_operator") int op,
    @ByVal data_type output_type,
    device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::experimental") public static native @MoveUniquePtr column binary_operation(
    @Const @ByRef scalar lhs,
    @Const @ByRef column_view rhs,
    @Cast("cudf::experimental::binary_operator") int op,
    @ByVal data_type output_type);

/**
 * \brief Performs a binary operation between a column and a scalar.
 *
 * The output contains the result of op(lhs[i], rhs) for all 0 <= i < lhs.size()
 * The column elements are the left operand and the scalar is the right operand.
 * This distinction is significant in case of non-commutative binary operations
 *
 * Regardless of the operator, the validity of the output value is the logical
 * AND of the validity of the two operands
 *
 * @param lhs         The left operand column
 * @param rhs         The right operand scalar
 * @param output_type The desired data type of the output column
 * @param mr          Memory resource for allocating output column
 * @return std::unique_ptr<column> Output column
 * @throws cudf::logic_error if \p lhs and \p rhs dtypes aren't numeric
 * @throws cudf::logic_error if \p output_type dtype isn't numeric
 */
@Namespace("cudf::experimental") public static native @MoveUniquePtr column binary_operation(
    @Const @ByRef column_view lhs,
    @Const @ByRef scalar rhs,
    @Cast("cudf::experimental::binary_operator") int op,
    @ByVal data_type output_type,
    device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::experimental") public static native @MoveUniquePtr column binary_operation(
    @Const @ByRef column_view lhs,
    @Const @ByRef scalar rhs,
    @Cast("cudf::experimental::binary_operator") int op,
    @ByVal data_type output_type);

/**
 * \brief Performs a binary operation between two columns.
 *
 * The output contains the result of op(lhs[i], rhs[i]) for all 0 <= i <
 * lhs.size()
 *
 * Regardless of the operator, the validity of the output value is the logical
 * AND of the validity of the two operands
 *
 * @param lhs         The left operand column
 * @param rhs         The right operand column
 * @param output_type The desired data type of the output column
 * @param mr          Memory resource for allocating output column
 * @return std::unique_ptr<column> Output column
 * @throws cudf::logic_error if \p lhs and \p rhs are different sizes
 * @throws cudf::logic_error if \p lhs and \p rhs dtypes aren't fixed-width
 * @throws cudf::logic_error if \p output_type dtype isn't numeric
 */
@Namespace("cudf::experimental") public static native @MoveUniquePtr column binary_operation(
    @Const @ByRef column_view lhs,
    @Const @ByRef column_view rhs,
    @Cast("cudf::experimental::binary_operator") int op,
    @ByVal data_type output_type,
    device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::experimental") public static native @MoveUniquePtr column binary_operation(
    @Const @ByRef column_view lhs,
    @Const @ByRef column_view rhs,
    @Cast("cudf::experimental::binary_operator") int op,
    @ByVal data_type output_type);

/**
 * \brief Performs a binary operation between two columns using a
 * user-defined PTX function.
 *
 * The output contains the result of op(lhs[i], rhs[i]) for all 0 <= i <
 * lhs.size()
 *
 * Regardless of the operator, the validity of the output value is the logical
 * AND of the validity of the two operands
 *
 * @param lhs         The left operand column
 * @param rhs         The right operand column
 * @param ptx         String containing the PTX of a binary function
 * @param output_type The desired data type of the output column. It is assumed
 *                    that output_type is compatible with the output data type
 *                    of the function in the PTX code
 * @param mr          Memory resource for allocating output column
 * @return std::unique_ptr<column> Output column
 * @throws cudf::logic_error if \p lhs and \p rhs are different sizes
 * @throws cudf::logic_error if \p lhs and \p rhs dtypes aren't numeric
 * @throws cudf::logic_error if \p output_type dtype isn't numeric
 */
@Namespace("cudf::experimental") public static native @MoveUniquePtr column binary_operation(
    @Const @ByRef column_view lhs,
    @Const @ByRef column_view rhs,
    @StdString BytePointer ptx,
    @ByVal data_type output_type,
    device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::experimental") public static native @MoveUniquePtr column binary_operation(
    @Const @ByRef column_view lhs,
    @Const @ByRef column_view rhs,
    @StdString String ptx,
    @ByVal data_type output_type,
    device_memory_resource mr/*=rmm::mr::get_default_resource()*/);

  // namespace experimental
  // namespace cudf


// Parsed from <cudf/aggregation.hpp>

/*
 * Copyright (c) 2019-2020, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

// #pragma once

// #include <cudf/types.hpp>

// #include <memory>
// #include <vector>

/**
 * \file aggregation.hpp
 * \brief Representation for specifying desired aggregations from
 * aggregation-based APIs, e.g., groupby, reductions, rolling, etc.
 *
 * \note Not all aggregation APIs support all aggregation operations. See
 * individual function documentation to see what aggregations are supported.
 *
 */
/**
 * \brief Base class for abstract representation of an aggregation.
 */

/** enum class cudf::experimental::udf_type */
public static final boolean
   CUDA = 0,
   PTX = 1;

/** Factory to create a SUM aggregation */
@Namespace("cudf::experimental") public static native @UniquePtr aggregation make_sum_aggregation();

/** Factory to create a MIN aggregation */
@Namespace("cudf::experimental") public static native @UniquePtr aggregation make_min_aggregation();

/** Factory to create a MAX aggregation */
@Namespace("cudf::experimental") public static native @UniquePtr aggregation make_max_aggregation();

/** Factory to create a COUNT aggregation */
@Namespace("cudf::experimental") public static native @UniquePtr aggregation make_count_aggregation();

/** Factory to create a MEAN aggregation */
@Namespace("cudf::experimental") public static native @UniquePtr aggregation make_mean_aggregation();

/**
 * \brief Factory to create a VARIANCE aggregation
 * 
 * @param ddof Delta degrees of freedom. The divisor used in calculation of 
 *             {@code variance} is {@code N - ddof}, where {@code N} is the population size.
 */
@Namespace("cudf::experimental") public static native @UniquePtr aggregation make_variance_aggregation(@ByVal(nullValue = "cudf::size_type(1)") size_type ddof);
@Namespace("cudf::experimental") public static native @UniquePtr aggregation make_variance_aggregation();

/**
 * \brief Factory to create a STD aggregation
 * 
 * @param ddof Delta degrees of freedom. The divisor used in calculation of 
 *             {@code std} is {@code N - ddof}, where {@code N} is the population size.
 */
@Namespace("cudf::experimental") public static native @UniquePtr aggregation make_std_aggregation(@ByVal(nullValue = "cudf::size_type(1)") size_type ddof);
@Namespace("cudf::experimental") public static native @UniquePtr aggregation make_std_aggregation();

/** Factory to create a MEDIAN aggregation */
@Namespace("cudf::experimental") public static native @UniquePtr aggregation make_median_aggregation();

/**
 * \brief Factory to create a QUANTILE aggregation
 *
 * @param quantiles The desired quantiles
 * @param interpolation The desired interpolation
 */
@Namespace("cudf::experimental") public static native @UniquePtr aggregation make_quantile_aggregation(
    @StdVector DoublePointer q, @Cast("cudf::experimental::interpolation") int i/*=cudf::experimental::interpolation::LINEAR*/);
@Namespace("cudf::experimental") public static native @UniquePtr aggregation make_quantile_aggregation(
    @StdVector DoublePointer q);
@Namespace("cudf::experimental") public static native @UniquePtr aggregation make_quantile_aggregation(
    @StdVector DoubleBuffer q, @Cast("cudf::experimental::interpolation") int i/*=cudf::experimental::interpolation::LINEAR*/);
@Namespace("cudf::experimental") public static native @UniquePtr aggregation make_quantile_aggregation(
    @StdVector DoubleBuffer q);
@Namespace("cudf::experimental") public static native @UniquePtr aggregation make_quantile_aggregation(
    @StdVector double[] q, @Cast("cudf::experimental::interpolation") int i/*=cudf::experimental::interpolation::LINEAR*/);
@Namespace("cudf::experimental") public static native @UniquePtr aggregation make_quantile_aggregation(
    @StdVector double[] q);

/**
 * \brief Factory to create an {@code argmax} aggregation
 * 
 * {@code argmax} returns the index of the maximum element.
*/
@Namespace("cudf::experimental") public static native @UniquePtr aggregation make_argmax_aggregation();

/**
 * \brief Factory to create an {@code argmin} aggregation
 * 
 * {@code argmin} returns the index of the minimum element.
*/
@Namespace("cudf::experimental") public static native @UniquePtr aggregation make_argmin_aggregation();

/**
 * \brief Factory to create a aggregation base on UDF for PTX or CUDA
 *
 * @param type [in] : either udf_type::PTX or udf_type::CUDA
 * @param user_defined_aggregator [in] A string containing the aggregator code
 * @param output_type [in] expected output type
 *
 * @return aggregation unique pointer housing user_defined_aggregator string.
 */
@Namespace("cudf::experimental") public static native @UniquePtr aggregation make_udf_aggregation(@Cast("cudf::experimental::udf_type") boolean type,
                                                  @StdString BytePointer user_defined_aggregator,
                                                  @ByVal data_type output_type);
@Namespace("cudf::experimental") public static native @UniquePtr aggregation make_udf_aggregation(@Cast("cudf::experimental::udf_type") boolean type,
                                                  @StdString String user_defined_aggregator,
                                                  @ByVal data_type output_type);

  // namespace experimental
  // namespace cudf


// Parsed from <cudf/reduction.hpp>

/*
 * Copyright (c) 2019-2020, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

// #pragma once

// #include <cudf/cudf.h>
// #include <cudf/scalar/scalar.hpp>

/**
 * \brief These enums indicate the supported operations of prefix scan that can
 * be performed on a column
 */
/** enum class cudf::experimental::scan_op */
public static final int
  /** Computes the prefix scan of     sum operation of all values for the column */
  SUM = 0,
  /** Computes the prefix scan of maximum operation of all values for the column */
  MIN = 1,
  /** Computes the prefix scan of maximum operation of all values for the column */
  MAX = 2,
  /** Computes the prefix scan of multiplicative product operation of all values for the column */
  PRODUCT = 3;

/**
 * \brief These enums indicate the supported reduction operations that can be
 * performed on a column
 */
/** enum class cudf::experimental::reduction_op */
public static final int
  /** Computes the sum of all values in the column */
  SUM = 0,
  /** Computes the minimum of all values in the column */
  MIN = 1,
  /** Computes the maximum of all values in the column */
  MAX = 2,
  /** Computes the multiplicative product of all values in the column */
  PRODUCT = 3,
  /** Computes the sum of squares of the values in the column */
  SUMOFSQUARES = 4,
  /** Computes the arithmetic mean of the values in the column */
  MEAN = 5,
  /** Computes the variance of the values in the column */
  VAR = 6,
  /** Computes the standard deviation of the values in the column */
  STD = 7,
  /** Computes to true if any of the values are non-zero/true */
  ANY = 8,
  /** Computes to true if all of the values are non-zero/true */
  ALL = 9;

/** --------------------------------------------------------------------------*
 * \brief  Computes the reduction of the values in all rows of a column.
 * This function does not detect overflows in reductions.
 * Using a higher precision {@code data_type} may prevent overflow.
 * Only {@code min} and {@code max} ops are supported for reduction of non-arithmetic
 * types (timestamp, string...).
 * The null values are skipped for the operation.
 * If the column is empty, the member {@code is_valid()} of the output scalar
 * will contain {@code false}.
 *
 * @throws {@code cudf::logic_error} if reduction is called for non-arithmetic output
 * type and operator other than {@code min} and {@code max}.
 * @throws {@code cudf::logic_error} if input column data type is not convertible to
 * output data type.
 * If the input column has arithmetic type, output_dtype can be any arithmetic
 * type. For {@code mean}, {@code var} and {@code std} ops, a floating point output type must be 
 * specified. If the input column has non-arithmetic type
 *   eg.(timestamp, string...), the same type must be specified.
 *
 * @param col [in] Input column view
 * @param op [in]  The operator applied by the reduction
 * @param output_dtype [in]  The computation and output precision.
 * \params[in] mr The resource to use for all allocations
 * @param ddof [in] Delta Degrees of Freedom: the divisor used in calculation of
 * {@code std} and {@code var} is {@code N - ddof}, where {@code N} is the population size.{@code 
 * @returns  cudf::scalar the result value
 * If the reduction fails, the member is_valid of the output scalar
 * will contain }false{@code .
 * ----------------------------------------------------------------------------**/
@Namespace("cudf::experimental") public static native @MoveUniquePtr scalar reduce(
    @Const @ByRef column_view col, @Cast("cudf::experimental::reduction_op") int op, @ByVal data_type output_dtype,
    @ByVal(nullValue = "cudf::size_type(1)") size_type ddof,
    device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::experimental") public static native @MoveUniquePtr scalar reduce(
    @Const @ByRef column_view col, @Cast("cudf::experimental::reduction_op") int op, @ByVal data_type output_dtype);

/** --------------------------------------------------------------------------*
 * \brief  Computes the scan of a column.
 * The null values are skipped for the operation, and if an input element
 * at {@code i} is null, then the output element at {@code i} will also be null.
 *
 * @throws {@code cudf::logic_error} if column datatype is not numeric type.
 *
 * @param input [in] The input column view for the scan
 * @param op [in] The operation of the scan
 * @param inclusive [in] The flag for applying an inclusive scan if true,
 *            an exclusive scan if false.
 * \params[in] mr The resource to use for all allocations
 * @return unique pointer to new output column
 * ----------------------------------------------------------------------------**/
@Namespace("cudf::experimental") public static native @MoveUniquePtr column scan(
    @Const @ByRef column_view input, @Cast("cudf::experimental::scan_op") int op, @Cast("bool") boolean inclusive,
    device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::experimental") public static native @MoveUniquePtr column scan(
    @Const @ByRef column_view input, @Cast("cudf::experimental::scan_op") int op, @Cast("bool") boolean inclusive);

  // namespace experimental
  // namespace cudf



// Parsed from <cudf/merge.hpp>

/*
 * Copyright (c) 2018-2019, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

// #pragma once

// #include <vector>
// #include <cudf/cudf.h>
// #include <cudf/types.hpp>

/**
 * \brief Merge sorted tables.
 * 
 * Merges two sorted tables into one sorted table
 * containing data from both tables.
 *
 * Example 1:
 * input:
 * table 1 => col 1 {0, 1, 2, 3}
 *            col 2 {4, 5, 6, 7}
 * table 2 => col 1 {1, 2}
 *            col 2 {8, 9}
 * output:
 * table => col 1 {0, 1, 1, 2, 2, 3}
 *          col 2 {4, 5, 8, 6, 9, 7}
 *
 * Example 2: 
 * input:
 * table 1 => col 0 {1, 0}
 *            col 1 {'c', 'b'}
 *            col 2 {RED, GREEN}
 *
 *
 * table 2 => col 0 {1}
 *            col 1 {'a'}
 *            col 2 {NULL}
 *
 *  with key_cols[] = {0,1}
 *  and  asc_desc[] = {ASC, ASC};
 *
 *  Lex-sorting is on columns {0,1}; hence, lex-sorting of ((L0 x L1) V (R0 x R1)) is:
 *  (0,'b', GREEN), (1,'a', NULL), (1,'c', RED)
 *
 *  (third column, the "color", just "goes along for the ride"; 
 *   meaning is permutted according to the data movements dictated 
 *   by lexicographic ordering of columns 0 and 1);
 *
 *   with result columns:
 *
 *   Res0 = {0,1,1}
 *   Res1 = {'b', 'a', 'c'}
 *   Res2 = {GREEN, NULL, RED}
 *
 * \Param[in] left_table A sorted table to be merged
 * \Param[in] right_table A sorted table to be merged
 * \Param[in] key_cols Indices of left_cols and right_cols to be used
 *                     for comparison criteria
 * \Param[in] column_order Sort order types of columns indexed by key_cols
 * \Param[in] null_precedence Array indicating the order of nulls with respect to non-nulls for the indexing columns (key_cols)
 *
 * \Returns A table containing sorted data from left_table and right_table
 */
@Namespace("cudf::experimental") public static native @UniquePtr table merge(@Const @ByRef table_view left_table,
                                                 @Const @ByRef table_view right_table,
                                                 @StdVector size_type key_cols,
                                                 @Cast("cudf::order*") @StdVector BoolPointer column_order,
                                                 @Cast("cudf::null_order*") @StdVector BoolPointer null_precedence/*={}*/,
                                                 device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::experimental") public static native @UniquePtr table merge(@Const @ByRef table_view left_table,
                                                 @Const @ByRef table_view right_table,
                                                 @StdVector size_type key_cols,
                                                 @Cast("cudf::order*") @StdVector BoolPointer column_order);
@Namespace("cudf::experimental") public static native @UniquePtr table merge(@Const @ByRef table_view left_table,
                                                 @Const @ByRef table_view right_table,
                                                 @StdVector size_type key_cols,
                                                 @Cast("cudf::order*") @StdVector boolean[] column_order,
                                                 @Cast("cudf::null_order*") @StdVector boolean[] null_precedence/*={}*/,
                                                 device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::experimental") public static native @UniquePtr table merge(@Const @ByRef table_view left_table,
                                                 @Const @ByRef table_view right_table,
                                                 @StdVector size_type key_cols,
                                                 @Cast("cudf::order*") @StdVector boolean[] column_order);

  // namespace experimental
  // namespace cudf



// Parsed from <cudf/search.hpp>

/*
 * Copyright (c) 2019, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

// #pragma once

// #include <cudf/types.hpp>
// #include <cudf/column/column.hpp>
// #include <cudf/scalar/scalar.hpp>
// #include <cudf/table/table.hpp>

// #include <vector>

/**
 * \brief Find smallest indices in a sorted table where values should be 
 *  inserted to maintain order
 * 
 * For each row v in \p values, find the first index in \p t where
 *  inserting the row will maintain the sort order of \p t
 * 
 * Example:
 * 
 *  Single column:
 *      idx      0   1   2   3   4
 *   column = { 10, 20, 20, 30, 50 }
 *   values = { 20 }
 *   result = {  1 }
 * 
 *  Multi Column:
 *      idx        0    1    2    3    4
 *   t      = {{  10,  20,  20,  20,  20 },
 *             { 5.0,  .5,  .5,  .7,  .7 },
 *             {  90,  77,  78,  61,  61 }}
 *   values = {{ 20 },
 *             { .7 },
 *             { 61 }}
 *   result =  {  3 }
 * 
 * @param t               Table to search
 * @param values          Find insert locations for these values
 * @param column_order    Vector of column sort order
 * @param null_precedence Vector of null_precedence enums
 * values
 * @param mr              Device memory resource to use for device memory allocation
 * @return std::unique_ptr<column> A non-nullable column of cudf::size_type elements
 * containing the insertion points.
 */
@Namespace("cudf::experimental") public static native @MoveUniquePtr column lower_bound(@Const @ByRef table_view t,
                                    @Const @ByRef table_view values,
                                    @Cast("cudf::order*") @StdVector BoolPointer column_order,
                                    @Cast("cudf::null_order*") @StdVector BoolPointer null_precedence,
                                    device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::experimental") public static native @MoveUniquePtr column lower_bound(@Const @ByRef table_view t,
                                    @Const @ByRef table_view values,
                                    @Cast("cudf::order*") @StdVector BoolPointer column_order,
                                    @Cast("cudf::null_order*") @StdVector BoolPointer null_precedence);
@Namespace("cudf::experimental") public static native @MoveUniquePtr column lower_bound(@Const @ByRef table_view t,
                                    @Const @ByRef table_view values,
                                    @Cast("cudf::order*") @StdVector boolean[] column_order,
                                    @Cast("cudf::null_order*") @StdVector boolean[] null_precedence,
                                    device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::experimental") public static native @MoveUniquePtr column lower_bound(@Const @ByRef table_view t,
                                    @Const @ByRef table_view values,
                                    @Cast("cudf::order*") @StdVector boolean[] column_order,
                                    @Cast("cudf::null_order*") @StdVector boolean[] null_precedence);

/**
 * \brief Find largest indices in a sorted table where values should be 
 *  inserted to maintain order
 * 
 * For each row v in \p values, find the last index in \p t where
 *  inserting the row will maintain the sort order of \p t
 * 
 * Example:
 * 
 *  Single Column:
 *      idx      0   1   2   3   4
 *   column = { 10, 20, 20, 30, 50 }
 *   values = { 20 }
 *   result = {  3 }
 * 
 *  Multi Column:
 *    idx        0    1    2    3    4
 *   t      = {{  10,  20,  20,  20,  20 },
 *             { 5.0,  .5,  .5,  .7,  .7 },
 *             {  90,  77,  78,  61,  61 }}
 *   values = {{ 20 },
 *             { .7 },
 *             { 61 }}
 *   result =  {  5  *   * 
 * @param column          Table to search
 * @param values          Find insert locations for these values
 * @param column_order    Vector of column sort order
 * @param null_precedence Vector of null_precedence enums
 * values
 * @param mr              Device memory resource to use for device memory allocation
 * @return std::unique_ptr<column> A non-nullable column of cudf::size_type elements
 * containing the insertion points.
 */
@Namespace("cudf::experimental") public static native @MoveUniquePtr column upper_bound(@Const @ByRef table_view t,
                                    @Const @ByRef table_view values,
                                    @Cast("cudf::order*") @StdVector BoolPointer column_order,
                                    @Cast("cudf::null_order*") @StdVector BoolPointer null_precedence,
                                    device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::experimental") public static native @MoveUniquePtr column upper_bound(@Const @ByRef table_view t,
                                    @Const @ByRef table_view values,
                                    @Cast("cudf::order*") @StdVector BoolPointer column_order,
                                    @Cast("cudf::null_order*") @StdVector BoolPointer null_precedence);
@Namespace("cudf::experimental") public static native @MoveUniquePtr column upper_bound(@Const @ByRef table_view t,
                                    @Const @ByRef table_view values,
                                    @Cast("cudf::order*") @StdVector boolean[] column_order,
                                    @Cast("cudf::null_order*") @StdVector boolean[] null_precedence,
                                    device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::experimental") public static native @MoveUniquePtr column upper_bound(@Const @ByRef table_view t,
                                    @Const @ByRef table_view values,
                                    @Cast("cudf::order*") @StdVector boolean[] column_order,
                                    @Cast("cudf::null_order*") @StdVector boolean[] null_precedence);

/**
 * \brief Find if the {@code value} is present in the {@code col}
 *
 * @throws cudf::logic_error
 * If {@code col.type() != values.type()}
 *
 * \example:
 *
 *  Single Column:
 *      idx      0   1   2   3   4
 *      col = { 10, 20, 20, 30, 50 }
 *  Scalar:
 *   value = { 20 }
 *   result = true
 *
 * @param col      A column object
 * @param value    A scalar value to search for in {@code col}
 * @param mr       Device memory resource to use for device memory allocation
 *
 * @return bool    If {@code value} is found in {@code column} true, else false.
 */
@Namespace("cudf::experimental") public static native @Cast("bool") boolean contains(@Const @ByRef column_view col, @Const @ByRef scalar value,
              device_memory_resource mr/*=rmm::mr::get_default_resource()*/);

/**
 * \brief  Returns a new column of type bool8 identifying for each element of \p haystack column,
 *         if that element is contained in \p needles column.
 *
 * The new column will have the same dimension and null status as the \p haystack column.  That is,
 * any element that is invalid in the \p haystack column will be invalid in the returned column.
 *
 * @throws cudf::logic_error
 * If {@code haystack.type() != needles.type()}
 *
 * \example:
 *
 *   haystack = { 10, 20, 30, 40, 50 }
 *   needles  = { 20, 40, 60, 80 }
 *
 *   result = { false, true, false, true, false }
 *
 * @param haystack  A column object
 * @param needles   A column of values to search for in {@code col}
 * @param mr         Device memory resource to use for device memory allocation
 *
 * @return std::unique_ptr<column> A column of bool8 elements containing
 * true if the corresponding entry in haystack is contained in needles and false
 * if it is not.
 */
@Namespace("cudf::experimental") public static native @MoveUniquePtr column contains(@Const @ByRef column_view haystack, @Const @ByRef column_view needles,
                                 device_memory_resource mr/*=rmm::mr::get_default_resource()*/);

 // namespace experimental
 // namespace cudf




// Parsed from <cudf/null_mask.hpp>

/*
 * Copyright (c) 2019, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
// #pragma once

// #include <cudf/column/column_view.hpp>
// #include <cudf/types.hpp>

// #include <rmm/device_buffer.hpp>
// #include <rmm/mr/device_memory_resource.hpp>

/**---------------------------------------------------------------------------*
 * \brief Returns the null count for a null mask of the specified {@code state}
 * representing {@code size} elements.
 *
 * @param state The state of the null mask
 * @param size The number of elements represented by the mask
 * @return size_type The count of null elements
 *---------------------------------------------------------------------------**/
@Namespace("cudf") public static native @ByVal size_type state_null_count(@Cast("cudf::mask_state") int state, @ByVal size_type size);

/**---------------------------------------------------------------------------*
 * \brief Computes the required bytes necessary to represent the specified
 * number of bits with a given padding boundary.
 *
 * \note The Arrow specification for the null bitmask requires a 64B padding
 * boundary.
 *
 * @param number_of_bits The number of bits that need to be represented
 * @param padding_boundary The value returned will be rounded up to a multiple
 * of this value
 * @return std::size_t The necessary number of bytes
 *---------------------------------------------------------------------------**/
@Namespace("cudf") public static native @ByVal size_t bitmask_allocation_size_bytes(@ByVal size_type number_of_bits,
                                          @ByVal(nullValue = "std::size_t(64)") size_t padding_boundary);
@Namespace("cudf") public static native @ByVal size_t bitmask_allocation_size_bytes(@ByVal size_type number_of_bits);

/**
 * \brief Returns the number of {@code bitmask_type} words required to represent the
 * specified number of bits.
 *
 * Unlike {@code bitmask_allocation_size_bytes}, which returns the number of *bytes*
 * needed for a bitmask allocation (including padding), this function returns
 * the *actual* number {@code bitmask_type} elements necessary to represent
 * {@code number_of_bits}. This is useful when one wishes to process all of the bits
 * in a bitmask and ignore the padding/slack bits.
 *
 * @param number_of_bits The number of bits that need to be represented
 * @return size_type The necessary number of {@code bitmask_type} elements
 */
@Namespace("cudf") public static native @ByVal size_type num_bitmask_words(@ByVal size_type number_of_bits);

/**---------------------------------------------------------------------------*
 * \brief Creates a {@code device_buffer} for use as a null value indicator bitmask of
 * a {@code column}.
 *
 * @param size The number of elements to be represented by the mask
 * @param state The desired state of the mask
 * @param stream Optional, stream on which all memory allocations/operations
 * will be submitted
 * @param mr Device memory resource to use for device memory allocation
 * @return rmm::device_buffer A {@code device_buffer} for use as a null bitmask
 * satisfying the desired size and state
 *---------------------------------------------------------------------------**/
@Namespace("cudf") public static native @ByVal device_buffer create_null_mask(
    @ByVal size_type size, @Cast("cudf::mask_state") int state, @Cast("cudaStream_t") CUstream_st stream/*=0*/,
    device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf") public static native @ByVal device_buffer create_null_mask(
    @ByVal size_type size, @Cast("cudf::mask_state") int state);

 /**---------------------------------------------------------------------------*
 * \brief Sets a pre-allocated bitmask buffer to a given state
 *
 * @param bitmask Pointer to bitmask (e.g. returned by {@code column_view.null_mask()})
 * @param size The number of elements represented by the mask (e.g.,
   number of rows in a column)
 * @param valid If true set all entries to valid; otherwise, set all to null.
 * @param stream Optional, stream on which all memory allocations/operations
 * will be submitted
 *---------------------------------------------------------------------------**/
  @Namespace("cudf") public static native void set_null_mask(@Cast("cudf::bitmask_type*") IntPointer bitmask,
                       @ByVal size_type size, @Cast("bool") boolean valid, @Cast("cudaStream_t") CUstream_st stream/*=0*/);
  @Namespace("cudf") public static native void set_null_mask(@Cast("cudf::bitmask_type*") IntPointer bitmask,
                       @ByVal size_type size, @Cast("bool") boolean valid);
  @Namespace("cudf") public static native void set_null_mask(@Cast("cudf::bitmask_type*") IntBuffer bitmask,
                       @ByVal size_type size, @Cast("bool") boolean valid, @Cast("cudaStream_t") CUstream_st stream/*=0*/);
  @Namespace("cudf") public static native void set_null_mask(@Cast("cudf::bitmask_type*") IntBuffer bitmask,
                       @ByVal size_type size, @Cast("bool") boolean valid);
  @Namespace("cudf") public static native void set_null_mask(@Cast("cudf::bitmask_type*") int[] bitmask,
                       @ByVal size_type size, @Cast("bool") boolean valid, @Cast("cudaStream_t") CUstream_st stream/*=0*/);
  @Namespace("cudf") public static native void set_null_mask(@Cast("cudf::bitmask_type*") int[] bitmask,
                       @ByVal size_type size, @Cast("bool") boolean valid);
  
/**---------------------------------------------------------------------------*
 * \brief Given a bitmask, counts the number of set (1) bits in the range
 * {@code [start, stop)}
 *
 * Returns {@code 0} if {@code bitmask == nullptr}.
 *
 * @throws {@code cudf::logic_error} if {@code start > stop}
 * @throws {@code cudf::logic_error} if {@code start < 0}
 *
 * @param bitmask Bitmask residing in device memory whose bits will be counted
 * @param start_bit Index of the first bit to count (inclusive)
 * @param stop_bit Index of the last bit to count (exclusive)
 * @return The number of non-zero bits in the specified range
 *---------------------------------------------------------------------------**/
@Namespace("cudf") public static native @ByVal size_type count_set_bits(@Cast("const cudf::bitmask_type*") IntPointer bitmask, @ByVal size_type start,
                               @ByVal size_type stop);
@Namespace("cudf") public static native @ByVal size_type count_set_bits(@Cast("const cudf::bitmask_type*") IntBuffer bitmask, @ByVal size_type start,
                               @ByVal size_type stop);
@Namespace("cudf") public static native @ByVal size_type count_set_bits(@Cast("const cudf::bitmask_type*") int[] bitmask, @ByVal size_type start,
                               @ByVal size_type stop);

/**---------------------------------------------------------------------------*
 * \brief Given a bitmask, counts the number of unset (0) bits  in the range
 *{@code [start, stop)}.
 *
 * Returns {@code 0} if {@code bitmask == nullptr}.
 *
 * @throws {@code cudf::logic_error} if {@code start > stop}
 * @throws {@code cudf::logic_error} if {@code start < 0}
 *
 * @param bitmask Bitmask residing in device memory whose bits will be counted
 * @param start_bit Index of the first bit to count (inclusive)
 * @param stop_bit Index of the last bit to count (exclusive)
 * @return The number of zero bits in the specified range
 *---------------------------------------------------------------------------**/
@Namespace("cudf") public static native @ByVal size_type count_unset_bits(@Cast("const cudf::bitmask_type*") IntPointer bitmask, @ByVal size_type start,
                                 @ByVal size_type stop);
@Namespace("cudf") public static native @ByVal size_type count_unset_bits(@Cast("const cudf::bitmask_type*") IntBuffer bitmask, @ByVal size_type start,
                                 @ByVal size_type stop);
@Namespace("cudf") public static native @ByVal size_type count_unset_bits(@Cast("const cudf::bitmask_type*") int[] bitmask, @ByVal size_type start,
                                 @ByVal size_type stop);

/**
 * \brief Given a bitmask, counts the number of set (1) bits in every range
 * {@code [indices[2*i], indices[(2*i)+1])} (where 0 <= i < indices.size() / 2).
 *
 * Returns an empty vector if {@code bitmask == nullptr}.
 * @throws cudf::logic_error if indices.size() % 2 != 0
 * @throws cudf::logic_error if indices[2*i] < 0 or
 * indices[2*i] > indices[(2*i)+1]
 *
 * @param bitmask [in] Bitmask residing in device memory whose bits will be
 * counted
 * @param indices [in] A vector of indices used to specify ranges to count the
 * number of set bits
 * @return std::vector<size_type> A vector storing the number of non-zero bits
 * in the specified ranges
 */
@Namespace("cudf") public static native @StdVector size_type segmented_count_set_bits(@Cast("const cudf::bitmask_type*") IntPointer bitmask,
                         @StdVector size_type indices);
@Namespace("cudf") public static native @StdVector size_type segmented_count_set_bits(@Cast("const cudf::bitmask_type*") IntBuffer bitmask,
                         @StdVector size_type indices);
@Namespace("cudf") public static native @StdVector size_type segmented_count_set_bits(@Cast("const cudf::bitmask_type*") int[] bitmask,
                         @StdVector size_type indices);

/**
 * \brief Given a bitmask, counts the number of unset (0) bits in every range
 * {@code [indices[2*i], indices[(2*i)+1])} (where 0 <= i < indices.size() / 2).
 *
 * Returns an empty vector if {@code bitmask == nullptr}.
 * @throws cudf::logic_error if indices.size() % 2 != 0
 * @throws cudf::logic_error if indices[2*i] < 0 or
 * indices[2*i] > indices[(2*i)+1]
 *
 * @param bitmask [in] Bitmask residing in device memory whose bits will be
 * counted
 * @param indices [in] A vector of indices used to specify ranges to count the
 * number of unset bits
 * @return std::vector<size_type> A vector storing the number of zero bits in
 * the specified ranges
 */
@Namespace("cudf") public static native @StdVector size_type segmented_count_unset_bits(@Cast("const cudf::bitmask_type*") IntPointer bitmask,
                           @StdVector size_type indices);
@Namespace("cudf") public static native @StdVector size_type segmented_count_unset_bits(@Cast("const cudf::bitmask_type*") IntBuffer bitmask,
                           @StdVector size_type indices);
@Namespace("cudf") public static native @StdVector size_type segmented_count_unset_bits(@Cast("const cudf::bitmask_type*") int[] bitmask,
                           @StdVector size_type indices);

/**---------------------------------------------------------------------------*
 * \brief Creates a {@code device_buffer} from a slice of bitmask defined by a range
 * of indices {@code [begin_bit, end_bit)}.
 *
 * Returns empty {@code device_buffer} if {@code bitmask == nullptr}.
 *
 * @throws {@code cudf::logic_error} if {@code begin_bit > end_bit}
 * @throws {@code cudf::logic_error} if {@code begin_bit < 0}
 *
 * @param mask Bitmask residing in device memory whose bits will be copied
 * @param begin_bit Index of the first bit to be copied (inclusive)
 * @param end_bit Index of the last bit to be copied (exclusive)
 * @param stream Optional, stream on which all memory allocations and copies
 * will be performed
 * @param mr Optional, the memory resource that will be used for allocating
 * the device memory for the new device_buffer
 * @return rmm::device_buffer A {@code device_buffer} containing the bits
 * {@code [begin_bit, end_bit)} from {@code mask}.
 *---------------------------------------------------------------------------**/
@Namespace("cudf") public static native @ByVal device_buffer copy_bitmask(
    @Cast("const cudf::bitmask_type*") IntPointer mask, @ByVal size_type begin_bit, @ByVal size_type end_bit,
    @Cast("cudaStream_t") CUstream_st stream/*=0*/,
    device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf") public static native @ByVal device_buffer copy_bitmask(
    @Cast("const cudf::bitmask_type*") IntPointer mask, @ByVal size_type begin_bit, @ByVal size_type end_bit);
@Namespace("cudf") public static native @ByVal device_buffer copy_bitmask(
    @Cast("const cudf::bitmask_type*") IntBuffer mask, @ByVal size_type begin_bit, @ByVal size_type end_bit,
    @Cast("cudaStream_t") CUstream_st stream/*=0*/,
    device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf") public static native @ByVal device_buffer copy_bitmask(
    @Cast("const cudf::bitmask_type*") IntBuffer mask, @ByVal size_type begin_bit, @ByVal size_type end_bit);
@Namespace("cudf") public static native @ByVal device_buffer copy_bitmask(
    @Cast("const cudf::bitmask_type*") int[] mask, @ByVal size_type begin_bit, @ByVal size_type end_bit,
    @Cast("cudaStream_t") CUstream_st stream/*=0*/,
    device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf") public static native @ByVal device_buffer copy_bitmask(
    @Cast("const cudf::bitmask_type*") int[] mask, @ByVal size_type begin_bit, @ByVal size_type end_bit);

/**---------------------------------------------------------------------------*
 * \brief Copies {@code view}'s bitmask from the bits
 * {@code [view.offset(), view.offset() + view.size())} into a {@code device_buffer}
 *
 * Returns empty {@code device_buffer} if the column is not nullable
 *
 * @param view Column view whose bitmask needs to be copied
 * @param stream Optional, stream on which all memory allocations and copies
 * will be performed
 * @param mr Optional, the memory resource that will be used for allocating
 * the device memory for the new device_buffer
 * @return rmm::device_buffer A {@code device_buffer} containing the bits
 * {@code [view.offset(), view.offset() + view.size())} from {@code view}'s bitmask.
 *---------------------------------------------------------------------------**/
@Namespace("cudf") public static native @ByVal device_buffer copy_bitmask(@Const @ByRef column_view view,
    @Cast("cudaStream_t") CUstream_st stream/*=0*/,
    device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf") public static native @ByVal device_buffer copy_bitmask(@Const @ByRef column_view view);

/**---------------------------------------------------------------------------*
 * \brief Concatenates {@code views[i]}'s bitmask from the bits
 * {@code [views[i].offset(), views[i].offset() + views[i].size())} for all elements
 * views[i] in views into a {@code device_buffer}
 *
 * Returns empty {@code device_buffer} if the column is not nullable
 *
 * @param views Vector of column views whose bitmask will to be concatenated
 * @param mr Optional, the memory resource that will be used for allocating
 * the device memory for the new device_buffer
 * @param stream Optional, stream on which all memory allocations and copies
 * will be performed
 * @return rmm::device_buffer A {@code device_buffer} containing the bitmasks of all
 * the column views in the views vector
 *---------------------------------------------------------------------------**/
@Namespace("cudf") public static native @ByVal device_buffer concatenate_masks(@StdVector column_view views,
    device_memory_resource mr/*=rmm::mr::get_default_resource()*/,
    @Cast("cudaStream_t") CUstream_st stream/*=0*/);
@Namespace("cudf") public static native @ByVal device_buffer concatenate_masks(@StdVector column_view views);

/**
 * \brief Returns a bitwise AND of the bitmasks of columns of a table
 * 
 * If any of the columns isn't nullable, it is considered all valid. 
 * If no column in the table is nullable, an empty bitmask is returned.
 * 
 * @param view The table of columns
 * @param stream CUDA stream on which to execute kernels 
 * @param mr Memory resource for allocating output bitmask
 * @return rmm::device_buffer Output bitmask
 */
@Namespace("cudf") public static native @ByVal device_buffer bitmask_and(
    @Const @ByRef table_view view,
    device_memory_resource mr/*=rmm::mr::get_default_resource()*/,
    @Cast("cudaStream_t") CUstream_st stream/*=0*/);
@Namespace("cudf") public static native @ByVal device_buffer bitmask_and(
    @Const @ByRef table_view view);

  // namespace cudf


// Parsed from <cudf/hashing.hpp>

/*
 * Copyright (c) 2019, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
// #pragma once

// #include <cudf/table/table.hpp>
// #include <cudf/table/table_view.hpp>

/** --------------------------------------------------------------------------*
 * \brief Partitions rows from the input table into multiple output tables.
 *
 * Partitions rows of {@code input} into {@code num_partitions} bins based on the hash
 * value of the columns specified by {@code columns_to_hash}. Rows partitioned into
 * the same bin are grouped consecutively in the output table. Returns a vector
 * of row offsets to the start of each partition in the output table.
 * 
 * @throws std::out_of_range if index is {@code columns_to_hash} is invalid
 *
 * @param input The table to partition
 * @param columns_to_hash Indices of input columns to hash
 * @param num_partitions The number of partitions to use
 * @param mr Optional resource to use for device memory allocation
 *
 * @return An output table and a vector of row offsets to each partition
 * -------------------------------------------------------------------------**/
@Namespace("cudf") public static native @ByVal std::pair<std::unique_ptr<cudf::experimental::table>,std::vector<cudf::size_type> > hash_partition(@Const @ByRef table_view input,
               @StdVector size_type columns_to_hash,
               int num_partitions,
               device_memory_resource mr/*=rmm::mr::get_default_resource()*/);

/** --------------------------------------------------------------------------*
 * \brief Computes the hash value of each row in the input set of columns.
 *
 * @param input The table of columns to hash
 * @param initial_hash Optional vector of initial hash values for each column.
 * If this vector is empty then each element will be hashed as-is.
 * @param mr Optional resource to use for device memory allocation
 *
 * @return A column where each row is the hash of a column from the input
 * -------------------------------------------------------------------------**/
@Namespace("cudf") public static native @MoveUniquePtr column hash(@Const @ByRef table_view input,
                             @Cast("uint32_t*") @StdVector IntPointer initial_hash/*={}*/,
                             device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf") public static native @MoveUniquePtr column hash(@Const @ByRef table_view input,
                             @Cast("uint32_t*") @StdVector IntBuffer initial_hash/*={}*/,
                             device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf") public static native @MoveUniquePtr column hash(@Const @ByRef table_view input,
                             @Cast("uint32_t*") @StdVector int[] initial_hash/*={}*/,
                             device_memory_resource mr/*=rmm::mr::get_default_resource()*/);

  // namespace cudf


// Parsed from <cudf/datetime.hpp>

/*
 * Copyright (c) 2019, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

// #pragma once

// #include <cudf/column/column.hpp>
// #include <cudf/column/column_view.hpp>
// #include <rmm/mr/default_memory_resource.hpp>

/** enum class cudf::datetime::detail::datetime_component */
public static final int
  INVALID = 0,
  YEAR = 1,
  MONTH = 2,
  DAY = 3,
  WEEKDAY = 4,
  HOUR = 5,
  MINUTE = 6,
  SECOND = 7;

/**
 * \brief  Extracts the supplied datetime component from any date time type
 * and returns an int16_t cudf::column.
 *
 * @param cudf [in] ::column_view of the input datetime values
 * @return cudf::column of the extracted int16_t datetime component
 * @throws cudf::logic_error if input column datatype is not TIMESTAMP
 */
  // namespace detail

/**
 * \brief  Extracts year from any date time type and returns an int16_t
 * cudf::column.
 *
 * @param cudf [in] ::column_view of the input datetime values
 *
 * @return cudf::column of the extracted int16_t years
 * @throws cudf::logic_error if input column datatype is not TIMESTAMP
 */
@Namespace("cudf::datetime") public static native @MoveUniquePtr column extract_year(
    @Const @ByRef column_view column,
    device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::datetime") public static native @MoveUniquePtr column extract_year(
    @Const @ByRef column_view column);

/**
 * \brief  Extracts month from any date time type and returns an int16_t
 * cudf::column.
 *
 * @param cudf [in] ::column_view of the input datetime values
 *
 * @return cudf::column of the extracted int16_t months
 * @throws cudf::logic_error if input column datatype is not TIMESTAMP
 */
@Namespace("cudf::datetime") public static native @MoveUniquePtr column extract_month(
    @Const @ByRef column_view column,
    device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::datetime") public static native @MoveUniquePtr column extract_month(
    @Const @ByRef column_view column);

/**
 * \brief  Extracts day from any date time type and returns an int16_t
 * cudf::column.
 *
 * @param cudf [in] ::column_view of the input datetime values
 *
 * @return cudf::column of the extracted int16_t days
 * @throws cudf::logic_error if input column datatype is not TIMESTAMP
 */
@Namespace("cudf::datetime") public static native @MoveUniquePtr column extract_day(
    @Const @ByRef column_view column,
    device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::datetime") public static native @MoveUniquePtr column extract_day(
    @Const @ByRef column_view column);

/**
 * \brief  Extracts day from any date time type and returns an int16_t
 * cudf::column.
 *
 * @param cudf [in] ::column_view of the input datetime values
 *
 * @return cudf::column of the extracted int16_t days
 * @throws cudf::logic_error if input column datatype is not TIMESTAMP
 */
@Namespace("cudf::datetime") public static native @MoveUniquePtr column extract_weekday(
    @Const @ByRef column_view column,
    device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::datetime") public static native @MoveUniquePtr column extract_weekday(
    @Const @ByRef column_view column);

/**
 * \brief  Extracts hour from any date time type and returns an int16_t
 * cudf::column.
 *
 * @param cudf [in] ::column_view of the input datetime values
 *
 * @return cudf::column of the extracted int16_t hours
 * @throws cudf::logic_error if input column datatype is not TIMESTAMP
 */
@Namespace("cudf::datetime") public static native @MoveUniquePtr column extract_hour(
    @Const @ByRef column_view column,
    device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::datetime") public static native @MoveUniquePtr column extract_hour(
    @Const @ByRef column_view column);

/**
 * \brief  Extracts minute from any date time type and returns an int16_t
 * cudf::column.
 *
 * @param cudf [in] ::column_view of the input datetime values
 *
 * @return cudf::column of the extracted int16_t minutes
 * @throws cudf::logic_error if input column datatype is not TIMESTAMP
 */
@Namespace("cudf::datetime") public static native @MoveUniquePtr column extract_minute(
    @Const @ByRef column_view column,
    device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::datetime") public static native @MoveUniquePtr column extract_minute(
    @Const @ByRef column_view column);

/**
 * \brief  Extracts second from any date time type and returns an int16_t
 * cudf::column.
 *
 * @param cudf [in] ::column_view of the input datetime values
 *
 * @return cudf::column of the extracted int16_t seconds
 * @throws cudf::logic_error if input column datatype is not TIMESTAMP
 */
@Namespace("cudf::datetime") public static native @MoveUniquePtr column extract_second(
    @Const @ByRef column_view column,
    device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::datetime") public static native @MoveUniquePtr column extract_second(
    @Const @ByRef column_view column);

  // namespace datetime
  // namespace cudf


// Parsed from <cudf/ipc.hpp>

// #include <arrow/api.h>
// #include <arrow/ipc/api.h>
// #include <arrow/gpu/cuda_api.h>
// Targeting ../CudaMessageReader.java




// Parsed from <cudf/sorting.hpp>

/*
 * Copyright (c) 2019, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

// #pragma once

// #include <cudf/types.hpp>

// #include <memory>
// #include <vector>

/**---------------------------------------------------------------------------*
 * \brief Computes the row indices that would produce {@code input}  in a
 * lexicographical sorted order.
 *
 * @param input The table to sort
 * @param column_order The desired sort order for each column. Size must be
 * equal to {@code input.num_columns()} or empty. If empty, all columns will be sorted
 * in ascending order.
 * @param null_precedence The desired order of null compared to other elements
 * for each column.  Size must be equal to {@code input.num_columns()} or empty.
 * If empty, all columns will be sorted in {@code null_order::BEFORE}.
 * @return std::unique_ptr<column> A non-nullable column of INT32 elements
 * containing the permuted row indices of {@code input} if it were sorted
 *---------------------------------------------------------------------------**/
@Namespace("cudf::experimental") public static native @MoveUniquePtr column sorted_order(
    @ByVal table_view input, @Cast("cudf::order*") @StdVector BoolPointer column_order/*={}*/,
    @Cast("cudf::null_order*") @StdVector BoolPointer null_precedence/*={}*/,
    device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::experimental") public static native @MoveUniquePtr column sorted_order(
    @ByVal table_view input, @Cast("cudf::order*") @StdVector boolean[] column_order/*={}*/,
    @Cast("cudf::null_order*") @StdVector boolean[] null_precedence/*={}*/,
    device_memory_resource mr/*=rmm::mr::get_default_resource()*/);

/**---------------------------------------------------------------------------*
 * \brief Checks whether the rows of a {@code table} are sorted in a lexicographical
 *        order.
 *
 * @param in [in]                table whose rows need to be compared for ordering
 * @param column_order [in]      The expected sort order for each column. Size
 *                              must be equal to {@code in.num_columns()} or empty. If
 *                              empty, it is expected all columns are in
 *                              ascending order.
 * @param null_precedence [in]   The desired order of null compared to other
 *                              elements for each column. Size must be equal to
 *                              {@code input.num_columns()} or empty. If empty,
 *                              {@code null_order::BEFORE} is assumed for all columns.
 *
 * @return bool                true if sorted as expected, false if not.
 *---------------------------------------------------------------------------**/
@Namespace("cudf::experimental") public static native @Cast("bool") boolean is_sorted(@Const @ByRef table_view table,
               @Cast("cudf::order*") @StdVector BoolPointer column_order,
               @Cast("cudf::null_order*") @StdVector BoolPointer null_precedence);
@Namespace("cudf::experimental") public static native @Cast("bool") boolean is_sorted(@Const @ByRef table_view table,
               @Cast("cudf::order*") @StdVector boolean[] column_order,
               @Cast("cudf::null_order*") @StdVector boolean[] null_precedence);

/**
 * \brief Performs a lexicographic sort of the rows of a table
 *
 * @param input The table to sort
 * @param column_order The desired order for each column. Size must be
 * equal to {@code input.num_columns()} or empty. If empty, all columns are sorted in
 * ascending order.
 * @param null_precedence The desired order of a null element compared to other
 * elements for each column in {@code input}. Size must be equal to
 * {@code input.num_columns()} or empty. If empty, all columns will be sorted with
 * {@code null_order::BEFORE}.
 * @param mr The device memory resource used to allocate the returned table
 * @return New table containing the desired sorted order of {@code input}
 */
@Namespace("cudf::experimental") public static native @UniquePtr table sort(
    @ByVal table_view input, @Cast("cudf::order*") @StdVector BoolPointer column_order/*={}*/,
    @Cast("cudf::null_order*") @StdVector BoolPointer null_precedence/*={}*/,
    device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::experimental") public static native @UniquePtr table sort(
    @ByVal table_view input);
@Namespace("cudf::experimental") public static native @UniquePtr table sort(
    @ByVal table_view input, @Cast("cudf::order*") @StdVector boolean[] column_order/*={}*/,
    @Cast("cudf::null_order*") @StdVector boolean[] null_precedence/*={}*/,
    device_memory_resource mr/*=rmm::mr::get_default_resource()*/);


/**
 * \brief Performs a key-value sort.
 *
 * Creates a new table that reorders the rows of {@code values} according to the
 * lexicographic ordering of the rows of {@code keys}.
 *
 * @throws {@code cudf::logic_error} if {@code values.num_rows() != keys.num_rows()}.
 *
 * @param values The table to reorder
 * @param keys The table that determines the ordering
 * @param column_order The desired order for each column in {@code keys}. Size must be
 * equal to {@code input.num_columns()} or empty. If empty, all columns are sorted in
 * ascending order.
 * @param null_precedence The desired order of a null element compared to other
 * elements for each column in {@code keys}. Size must be equal to
 * {@code keys.num_columns()} or empty. If empty, all columns will be sorted with
 * {@code null_order::BEFORE}.
 * @param mr The device memory resource used to allocate the returned table
 * @return The reordering of {@code values} determined by the lexicographic order of
 * the rows of {@code keys}.
 */
@Namespace("cudf::experimental") public static native @UniquePtr table sort_by_key(
    @Const @ByRef table_view values, @Const @ByRef table_view keys,
    @Cast("cudf::order*") @StdVector BoolPointer column_order/*={}*/,
    @Cast("cudf::null_order*") @StdVector BoolPointer null_precedence/*={}*/,
    device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::experimental") public static native @UniquePtr table sort_by_key(
    @Const @ByRef table_view values, @Const @ByRef table_view keys,
    @Cast("cudf::order*") @StdVector boolean[] column_order/*={}*/,
    @Cast("cudf::null_order*") @StdVector boolean[] null_precedence/*={}*/,
    device_memory_resource mr/*=rmm::mr::get_default_resource()*/);

  // namespace experimental
  // namespace cudf


// Parsed from <cudf/table/table.hpp>

/*
 * Copyright (c) 2019, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
// #pragma once

// #include <cudf/column/column.hpp>
// #include <cudf/table/table_view.hpp>

// #include <memory>
// #include <vector>
// Targeting ../table.java




/**---------------------------------------------------------------------------*
 * \brief Columns of {@code tables_to_concat} are concatenated vertically to return a
 * single table_view
 *
 * example:
 * <pre>{@code
 * column_view c0; //Contains {0,1,2,3}
 * column_view c1; //Contains {4,5,6,7}
 * table_view t0{{c0, c0}};
 * table_view t1{{c1, c1}};
 * ...
 * auto t = concatenate({t0.view(), t1.view()});
 * column_view tc0 = (t->view()).column(0); //Contains {0,1,2,3,4,5,6,7}
 * column_view tc1 = (t->view()).column(1); //Contains {0,1,2,3,4,5,6,7}
 * }</pre>
 *
 * @throws cudf::logic_error
 * If number of columns mismatch
 *
 * @param tables_to_concat The table views to be concatenated into a single
 * table
 * @param mr Optional The resource to use for all allocations
 * @param stream Optional The stream on which to execute all allocations and copies
 * @return Unique pointer to a single table having all the rows from the
 * elements of {@code tables_to_concat} respectively in the same order.
 *---------------------------------------------------------------------------**/
@Namespace("cudf::experimental") public static native @UniquePtr table concatenate(@StdVector table_view tables_to_concat,
            device_memory_resource mr/*=rmm::mr::get_default_resource()*/,
            @Cast("cudaStream_t") CUstream_st stream/*=0*/);

  // namespace experimental
  // namespace cudf


// Parsed from <cudf/table/table_view.hpp>

/*
 * Copyright (c) 2019, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
// #pragma once

// #include <cudf/column/column_view.hpp>
// #include <cudf/types.hpp>

// #include <algorithm>
// #include <vector>

/**---------------------------------------------------------------------------*
 * \file table_view.hpp
 * \brief A {@code (mutable_)table_view} is a set of {@code (mutable_)column_view}s of equal
 * size.
 *
 * A {@code (mutable_)table_view} is non-owning and trivially copyable and should be
 * passed by value.
 *---------------------------------------------------------------------------**/
// Targeting ../TableViewBaseColumnView.java


// Targeting ../TableViewBaseMutableColumnView.java



// Targeting ../table_view.java


// Targeting ../mutable_table_view.java



@Namespace("cudf") public static native @Cast("bool") boolean has_nulls(@ByVal table_view view);

/**---------------------------------------------------------------------------*
   * \brief Checks if two {@code table_view}s have columns of same types
   *
   * @param lhs left-side table_view operand
   * @param rhs right-side table_view operand
   * @return boolean comparison result
   *---------------------------------------------------------------------------**/
@Namespace("cudf") public static native @Cast("bool") boolean have_same_types(@Const @ByRef table_view lhs, @Const @ByRef table_view rhs);
  // namespace cudf


// Parsed from <cudf/column/column_factories.hpp>

/*
 * Copyright (c) 2019, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
// #pragma once

// #include <cudf/null_mask.hpp>
// #include <cudf/types.hpp>
// #include <cudf/utilities/error.hpp>
// #include <cudf/utilities/traits.hpp>
// #include "column.hpp"

// #include <rmm/thrust_rmm_allocator.h>

/**
 * \brief Creates an empty column of the specified \p type
 *
 * An empty column does not contain any elements or a validity mask.
 *
 * @param type The desired type
 * @return Empty column with desired type
 */
@Namespace("cudf") public static native @MoveUniquePtr column make_empty_column(@ByVal data_type type);

/**
 * \brief Construct column with sufficient uninitialized storage
 * to hold {@code size} elements of the specified numeric {@code data_type} with an optional
 * null mask.
 *
 * \note {@code null_count()} is determined by the requested null mask {@code state}
 *
 * @throws std::bad_alloc if device memory allocation fails
 * @throws cudf::logic_error if {@code type} is not a numeric type
 *
 * @param type [in] The desired numeric element type
 * @param size [in] The number of elements in the column
 * @param state [in] Optional, controls allocation/initialization of the
 * column's null mask. By default, no null mask is allocated.
 * @param stream [in] Optional stream on which to issue all memory allocation and
 * device kernels
 * @param mr [in] Optional resource to use for device memory
 * allocation of the column's {@code data} and {@code null_mask}.
 */
@Namespace("cudf") public static native @MoveUniquePtr column make_numeric_column(
    @ByVal data_type type, @ByVal size_type size, @Cast("cudf::mask_state") int state/*=cudf::UNALLOCATED*/,
    @Cast("cudaStream_t") CUstream_st stream/*=0*/,
    device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf") public static native @MoveUniquePtr column make_numeric_column(
    @ByVal data_type type, @ByVal size_type size);

/**
 * \brief Construct column with sufficient uninitialized storage
 * to hold {@code size} elements of the specified numeric {@code data_type} with a
 * null mask.
 *
 * \note null_count is optional and will be computed if not provided.
 *
 * @throws std::bad_alloc if device memory allocation fails
 * @throws cudf::logic_error if {@code type} is not a numeric type
 *
 * @param type [in] The desired numeric element type
 * @param size [in] The number of elements in the column
 * @param null_mask [in] Null mask to use for this column.
 * @param null_count [in] Optional number of nulls in the null_mask.
 * @param stream [in] Optional stream on which to issue all memory allocation and
 * device kernels
 * @param mr [in] Optional resource to use for device memory
 * allocation of the column's {@code data} and {@code null_mask}.
 */

/**
 * \brief Construct column with sufficient uninitialized storage
 * to hold {@code size} elements of the specified timestamp {@code data_type} with an
 * optional null mask.
 *
 * \note {@code null_count()} is determined by the requested null mask {@code state}
 *
 * @throws std::bad_alloc if device memory allocation fails
 * @throws cudf::logic_error if {@code type} is not a timestamp type
 *
 * @param type [in] The desired timestamp element type
 * @param size [in] The number of elements in the column
 * @param state [in] Optional, controls allocation/initialization of the
 * column's null mask. By default, no null mask is allocated.
 * @param stream [in] Optional stream on which to issue all memory allocation and
 * device kernels
 * @param mr [in] Optional resource to use for device memory
 * allocation of the column's {@code data} and {@code null_mask}.
 */
@Namespace("cudf") public static native @MoveUniquePtr column make_timestamp_column(
    @ByVal data_type type, @ByVal size_type size, @Cast("cudf::mask_state") int state/*=cudf::UNALLOCATED*/,
    @Cast("cudaStream_t") CUstream_st stream/*=0*/,
    device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf") public static native @MoveUniquePtr column make_timestamp_column(
    @ByVal data_type type, @ByVal size_type size);

/**
 * \brief Construct column with sufficient uninitialized storage
 * to hold {@code size} elements of the specified timestamp {@code data_type} with a
 * null mask.
 *
 * \note null_count is optional and will be computed if not provided.
 *
 * @throws std::bad_alloc if device memory allocation fails
 * @throws cudf::logic_error if {@code type} is not a timestamp type
 *
 * @param type [in] The desired timestamp element type
 * @param size [in] The number of elements in the column
 * @param null_mask [in] Null mask to use for this column.
 * @param null_count [in] Optional number of nulls in the null_mask.
 * @param stream [in] Optional stream on which to issue all memory allocation and
 * device kernels
 * @param mr [in] Optional resource to use for device memory
 * allocation of the column's {@code data} and {@code null_mask}.
 */

/**
 * \brief Construct column with sufficient uninitialized storage
 * to hold {@code size} elements of the specified fixed width {@code data_type} with an optional
 * null mask.
 *
 * \note {@code null_count()} is determined by the requested null mask {@code state}
 *
 * @throws std::bad_alloc if device memory allocation fails
 * @throws cudf::logic_error if {@code type} is not a fixed width type
 *
 * @param type [in] The desired fixed width type
 * @param size [in] The number of elements in the column
 * @param state [in] Optional, controls allocation/initialization of the
 * column's null mask. By default, no null mask is allocated.
 * @param stream [in] Optional stream on which to issue all memory allocation and device
 * kernels
 * @param mr [in] Optional resource to use for device memory
 * allocation of the column's {@code data} and {@code null_mask}.
 */
@Namespace("cudf") public static native @MoveUniquePtr column make_fixed_width_column(
    @ByVal data_type type, @ByVal size_type size, @Cast("cudf::mask_state") int state/*=cudf::UNALLOCATED*/,
    @Cast("cudaStream_t") CUstream_st stream/*=0*/,
    device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf") public static native @MoveUniquePtr column make_fixed_width_column(
    @ByVal data_type type, @ByVal size_type size);

/**
 * \brief Construct column with sufficient uninitialized storage
 * to hold {@code size} elements of the specified fixed width {@code data_type} with a
 * null mask.
 *
 * \note null_count is optional and will be computed if not provided.
 *
 * @throws std::bad_alloc if device memory allocation fails
 * @throws cudf::logic_error if {@code type} is not a fixed width type
 *
 * @param type [in] The desired fixed width element type
 * @param size [in] The number of elements in the column
 * @param null_mask [in] Null mask to use for this column.
 * @param null_count [in] Optional number of nulls in the null_mask.
 * @param stream [in] Optional stream on which to issue all memory allocation and device
 * kernels
 * @param mr [in] Optional resource to use for device memory
 * allocation of the column's {@code data} and {@code null_mask}.
 */


/**
 * \brief Construct STRING type column given a vector of pointer/size pairs.
 * The total number of char bytes must not exceed the maximum size of size_type.
 * The string characters are expected to be UTF-8 encoded sequence of char
 * bytes. Use the strings_column_view class to perform strings operations on
 * this type of column.
 *
 * \note {@code null_count()} and {@code null_bitmask} are determined if a pair contains
 * a null string. That is, for each pair, if {@code .first} is null, that string
 * is considered null. Likewise, a string is considered empty (not null)
 * if {@code .first} is not null and {@code .second} is 0. Otherwise the {@code .first} member
 * must be a valid device address pointing to {@code .second} consecutive bytes.
 *
 * @throws std::bad_alloc if device memory allocation fails
 *
 * @param strings The vector of pointer/size pairs.
 *                Each pointer must be a device memory address or {@code nullptr}
 * (indicating a null string). The size must be the number of bytes.
 * @param stream Optional stream for use with all memory allocation
 *               and device kernels
 * @param mr Optional resource to use for device memory
 *           allocation of the column's {@code null_mask} and children.
 */
@Namespace("cudf") public static native @MoveUniquePtr column make_strings_column(
    @Const @ByRef rmm::device_vector<thrust::pair<const char*,cudf::size_type> > strings,
    @Cast("cudaStream_t") CUstream_st stream/*=0*/,
    device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf") public static native @MoveUniquePtr column make_strings_column(
    @Const @ByRef rmm::device_vector<thrust::pair<const char*,cudf::size_type> > strings);

/**
 * \brief Construct STRING type column given a device vector of chars
 * encoded as UTF-8, a device vector of byte offsets identifying individual
 * strings within the char vector, and an optional null bitmask.
 *
 * {@code offsets.front()} must always be zero.
 *
 * The total number of char bytes must not exceed the maximum size of size_type.
 * Use the strings_column_view class to perform strings operations on this type
 * of column.
 * This function makes a deep copy of the strings, offsets, null_mask to create
 * a new column.
 *
 * @throws std::bad_alloc if device memory allocation fails
 *
 * @param strings The vector of chars in device memory.
 *                This char vector is expected to be UTF-8 encoded characters.
 * @param offsets The vector of byte offsets in device memory.
 *                The number of elements is one more than the total number
 *                of strings so the {@code offsets.back()} is the total
 *                number of bytes in the strings array.
 *                {@code offsets.front()} must always be 0 to point to the beginning
 *                of {@code strings}.
 * @param null_mask Device vector containing the null element indicator bitmask.
 *                  Arrow format for nulls is used for interpeting this bitmask.
 * @param null_count The number of null string entries. If equal to
 * {@code UNKNOWN_NULL_COUNT}, the null count will be computed dynamically on the
 * first invocation of {@code column::null_count()}
 * @param stream Optional stream for use with all memory allocation
 *               and device kernels
 * @param mr Optional resource to use for device memory
 *           allocation of the column's {@code null_mask} and children.
 */
@Namespace("cudf") public static native @MoveUniquePtr column make_strings_column(
    @Const @ByRef RmmDeviceVectorChar strings,
    @Const @ByRef RmmDeviceVectorCudfSizeType offsets,
    @Const @ByRef(nullValue = "rmm::device_vector<cudf::bitmask_type>({})") rmm::device_vector<cudf::bitmask_type> null_mask,
    @ByVal(nullValue = "cudf::size_type(cudf::UNKNOWN_NULL_COUNT)") size_type null_count, @Cast("cudaStream_t") CUstream_st stream/*=0*/,
    device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf") public static native @MoveUniquePtr column make_strings_column(
    @Const @ByRef RmmDeviceVectorChar strings,
    @Const @ByRef RmmDeviceVectorCudfSizeType offsets);

/**
 * \brief Construct STRING type column given a host vector of chars
 * encoded as UTF-8, a host vector of byte offsets identifying individual
 * strings within the char vector, and an optional null bitmask.
 *
 * {@code offsets.front()} must always be zero.
 *
 * The total number of char bytes must not exceed the maximum size of size_type.
 * Use the strings_column_view class to perform strings operations on this type
 * of column.
 * This function makes a deep copy of the strings, offsets, null_mask to create
 * a new column.
 *
 * @throws std::bad_alloc if device memory allocation fails
 *
 * @param strings The contiguous array of chars in host memory.
 *                This char array is expected to be UTF-8 encoded characters.
 * @param offsets The array of byte offsets in host memory.
 *                The number of elements is one more than the total number
 *                of strings so the {@code offsets.back()} is the total
 *                number of bytes in the strings array.
 *                {@code offsets.front()} must always be 0 to point to the beginning
 *                of {@code strings}.
 * @param null_mask Host vector containing the null element indicator bitmask.
 *                  Arrow format for nulls is used for interpeting this bitmask.
 * @param null_count The number of null string entries. If equal to
 * {@code UNKNOWN_NULL_COUNT}, the null count will be computed dynamically on the
 * first invocation of {@code column::null_count()}
 * @param stream Optional stream for use with all memory allocation
 *               and device kernels
 * @param mr Optional resource to use for device memory
 *           allocation of the column's {@code null_mask} and children.
 */
@Namespace("cudf") public static native @MoveUniquePtr column make_strings_column(
    @Cast("char*") @StdVector BytePointer strings, @StdVector size_type offsets,
    @Cast("cudf::bitmask_type*") @StdVector IntPointer null_mask/*={}*/,
    @ByVal(nullValue = "cudf::size_type(cudf::UNKNOWN_NULL_COUNT)") size_type null_count, @Cast("cudaStream_t") CUstream_st stream/*=0*/,
    device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf") public static native @MoveUniquePtr column make_strings_column(
    @Cast("char*") @StdVector BytePointer strings, @StdVector size_type offsets);
@Namespace("cudf") public static native @MoveUniquePtr column make_strings_column(
    @Cast("char*") @StdVector ByteBuffer strings, @StdVector size_type offsets,
    @Cast("cudf::bitmask_type*") @StdVector IntBuffer null_mask/*={}*/,
    @ByVal(nullValue = "cudf::size_type(cudf::UNKNOWN_NULL_COUNT)") size_type null_count, @Cast("cudaStream_t") CUstream_st stream/*=0*/,
    device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf") public static native @MoveUniquePtr column make_strings_column(
    @Cast("char*") @StdVector ByteBuffer strings, @StdVector size_type offsets);
@Namespace("cudf") public static native @MoveUniquePtr column make_strings_column(
    @Cast("char*") @StdVector byte[] strings, @StdVector size_type offsets,
    @Cast("cudf::bitmask_type*") @StdVector int[] null_mask/*={}*/,
    @ByVal(nullValue = "cudf::size_type(cudf::UNKNOWN_NULL_COUNT)") size_type null_count, @Cast("cudaStream_t") CUstream_st stream/*=0*/,
    device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf") public static native @MoveUniquePtr column make_strings_column(
    @Cast("char*") @StdVector byte[] strings, @StdVector size_type offsets);

/**
 * \brief Constructs a STRING type column given offsets column, chars columns,
 * and null mask and null count. The columns and mask are moved into the
 * resulting strings column.
 *
 * @param num_strings The number of strings the column represents.
 * @param offsets The column of offset values for this column.
 *                The number of elements is one more than the total number
 *                of strings so the offset[last] - offset[0] is the total
 *                number of bytes in the strings vector.
 * @param chars The column of char bytes for all the strings for this column.
 *              Individual strings are identified by the offsets and the
 * nullmask.
 * @param null_count The number of null string entries.
 * @param null_mask The bits specifying the null strings in device memory.
 *                  Arrow format for nulls is used for interpeting this bitmask.
 * @param stream Optional stream for use with all memory allocation
 *               and device kernels
 * @param mr Optional resource to use for device memory
 *           allocation of the column's {@code null_mask} and children.
 */
@Namespace("cudf") public static native @MoveUniquePtr column make_strings_column(
    @ByVal size_type num_strings, @MoveUniquePtr column offsets_column,
    @MoveUniquePtr column chars_column, @ByVal size_type null_count,
    @ByVal device_buffer null_mask, @Cast("cudaStream_t") CUstream_st stream/*=0*/,
    device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf") public static native @MoveUniquePtr column make_strings_column(
    @ByVal size_type num_strings, @MoveUniquePtr column offsets_column,
    @MoveUniquePtr column chars_column, @ByVal size_type null_count,
    @ByVal device_buffer null_mask);

  // namespace cudf


// Parsed from <cudf/column/column.hpp>

/*
 * Copyright (c) 2019, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
// #pragma once

// #include <cudf/null_mask.hpp>
// #include <cudf/types.hpp>
// #include "column_view.hpp"

// #include <rmm/device_buffer.hpp>
// #include <rmm/mr/device_memory_resource.hpp>

// #include <memory>
// #include <type_traits>
// #include <utility>
// #include <vector>
// Targeting ../column.java



/**---------------------------------------------------------------------------*
 * \brief Concatenates multiple columns into a single column.
 *
 * @throws cudf::logic_error
 * If types of the input columns mismatch
 *
 * @param columns_to_concat The column views to be concatenated into a single
 * column
 * @param mr Optional The resource to use for all allocations
 * @param stream Optional The stream on which to execute all allocations and copies
 * @return Unique pointer to a single table having all the rows from the
 * elements of {@code columns_to_concat} respectively in the same order.
 *---------------------------------------------------------------------------**/
@Namespace("cudf") public static native @MoveUniquePtr column concatenate(@StdVector column_view columns_to_concat,
            device_memory_resource mr/*=rmm::mr::get_default_resource()*/,
            @Cast("cudaStream_t") CUstream_st stream/*=0*/);
@Namespace("cudf") public static native @MoveUniquePtr column concatenate(@StdVector column_view columns_to_concat);

  // namespace cudf


// Parsed from <cudf/column/column_view.hpp>

/*
 * Copyright (c) 2019, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
// #pragma once

// #include <cudf/types.hpp>
// #include <vector>
// Targeting ../column_view_base.java


// Targeting ../mutable_column_view_base.java



// Targeting ../column_view.java


// Targeting ../mutable_column_view.java



/**---------------------------------------------------------------------------*
 * \brief Counts the number of descendants of the specified parent.
 *
 * @param parent The parent whose descendants will be counted
 * @return size_type The number of descendants of the parent
 *---------------------------------------------------------------------------**/
@Namespace("cudf") public static native @ByVal size_type count_descendants(@ByVal column_view parent);

// namespace cudf


// Parsed from <cudf/join.hpp>

/*
 * Copyright (c) 2019, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

// #pragma once

// #include <memory>
// #include <type_traits>
// #include <utility>
// #include <vector>
// joins

/**
 * \brief  Performs an inner join on the specified columns of two
 * tables (left, right)
 *
 * Inner Join returns rows from both tables as long as the values
 * in the columns being joined on match.
 *
 * \example Left a: {0, 1, 2}
 *          Right b: {1, 2, 3}, a: {1, 2, 5}
 *          left_on: {0}
 *          right_on: {1}
 *          columns_in_common: { {0, 1} }
 * Result: { a: {1, 2}, b: {1, 2} }
 *
 * \example Left a: {0, 1, 2}
 *          Right b: {1, 2, 3}, c: {1, 2, 5}
 *          left_on: {0}
 *          right_on: {0}
 *          columns_in_common: { }
 * Result: { a: {1, 2}, b: {1, 2}, c: {1, 2} }
 *
 * @throws cudf::logic_error if {@code columns_in_common} contains a pair of indices
 * (L, R) if L does not exist in {@code left_on} or R does not exist in {@code right_on}.
 * @throws cudf::logic_error if {@code columns_in_common} contains a pair of indices
 * (L, R) such that the location of {@code L} within {@code left_on} is not equal to
 * location of R within {@code right_on}
 * @throws cudf::logic_error if number of elements in {@code left_on} or {@code right_on}
 * mismatch.
 * @throws cudf::logic_error if number of columns in either {@code left} or {@code right}
 * table is 0 or exceeds MAX_JOIN_SIZE
 * @throws std::out_of_range if element of {@code left_on} or {@code right_on} exceed the
 * number of columns in the left or right table.
 *
 * @param left [in] The left table
 * @param right [in] The right table
 * @param left_on [in] The column indices from {@code left} to join on.
 * The column from {@code left} indicated by {@code left_on[i]} will be compared against the column
 * from {@code right} indicated by {@code right_on[i]}.
 * @param right_on [in] The column indices from {@code right} to join on.
 * The column from {@code right} indicated by {@code right_on[i]} will be compared against the column
 * from {@code left} indicated by {@code left_on[i]}.
 * @param columns_in_common [in] is a vector of pairs of column indices into
 * {@code left} and {@code right}, respectively, that are "in common". For "common"
 * columns, only a single output column will be produced, which is gathered
 * from {@code left_on} columns. Else, for every column in {@code left_on} and {@code right_on},
 * an output column will be produced.  For each of these pairs (L, R), L
 * should exist in {@code left_on} and R should exist in {@code right_on}.
 * @param mr Memory resource used to allocate the returned table and columns
 *
 * @return Result of joining {@code left} and {@code right} tables on the columns
 * specified by {@code left_on} and {@code right_on}. The resulting table will be joined columns of
 * {@code left(including common columns)+right(excluding common columns)}.
 */
@Namespace("cudf::experimental") public static native @UniquePtr table inner_join(
                         @Const @ByRef table_view left,
                         @Const @ByRef table_view right,
                         @StdVector size_type left_on,
                         @StdVector size_type right_on,
                         @StdVector std::pair<cudf::size_type,cudf::size_type> columns_in_common,
                         device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::experimental") public static native @UniquePtr table inner_join(
                         @Const @ByRef table_view left,
                         @Const @ByRef table_view right,
                         @StdVector size_type left_on,
                         @StdVector size_type right_on,
                         @StdVector std::pair<cudf::size_type,cudf::size_type> columns_in_common);

/**
 * \brief  Performs a left join (also known as left outer join) on the
 * specified columns of two tables (left, right)
 *
 * Left Join returns all the rows from the left table and those rows from the
 * right table that match on the joined columns.
 * For rows from the right table that do not have a match, the corresponding
 * values in the left columns will be null.
 *
 * \example Left a: {0, 1, 2}
 *          Right b: {1, 2, 3}, a: {1 ,2 ,5}
 *          left_on: {0}
 *          right_on: {1}
 *          columns_in_common: { {0, 1} }
 * Result: { a: {0, 1, 2}, b: {NULL, 1, 2} }
 *
 * \example Left a: {0, 1, 2}
 *          Right b: {1, 2, 3}, c: {1, 2, 5}
 *          left_on: {0}
 *          right_on: {0}
 *          columns_in_common: { }
 * Result: { a: {0, 1, 2}, b: {NULL, 1, 2}, c: {NULL, 1, 2} }
 *
 * @throws cudf::logic_error if {@code columns_in_common} contains a pair of indices
 * (L, R) if L does not exist in {@code left_on} or R does not exist in {@code right_on}.
 * @throws cudf::logic_error if {@code columns_in_common} contains a pair of indices
 * (L, R) such that the location of {@code L} within {@code left_on} is not equal to
 * location of R within {@code right_on}
 * @throws cudf::logic_error if number of elements in {@code left_on} or {@code right_on}
 * mismatch.
 * @throws cudf::logic_error if number of columns in either {@code left} or {@code right}
 * table is 0 or exceeds MAX_JOIN_SIZE
 * @throws std::out_of_range if element of {@code left_on} or {@code right_on} exceed the
 * number of columns in the left or right table.
 *
 * @param left [in] The left table
 * @param right [in] The right table
 * @param left_on [in] The column indices from {@code left} to join on.
 * The column from {@code left} indicated by {@code left_on[i]} will be compared against the column
 * from {@code right} indicated by {@code right_on[i]}.
 * @param right_on [in] The column indices from {@code right} to join on.
 * The column from {@code right} indicated by {@code right_on[i]} will be compared against the column
 * from {@code left} indicated by {@code left_on[i]}.
 * @param columns_in_common [in] is a vector of pairs of column indices into
 * {@code left} and {@code right}, respectively, that are "in common". For "common"
 * columns, only a single output column will be produced, which is gathered
 * from {@code left_on} columns. Else, for every column in {@code left_on} and {@code right_on},
 * an output column will be produced.  For each of these pairs (L, R), L
 * should exist in {@code left_on} and R should exist in {@code right_on}.
 * @param mr Memory resource used to allocate the returned table and columns
 *
 * @return Result of joining {@code left} and {@code right} tables on the columns
 * specified by {@code left_on} and {@code right_on}. The resulting table will be joined columns of
 * {@code left(including common columns)+right(excluding common columns)}.
 */
@Namespace("cudf::experimental") public static native @UniquePtr table left_join(
                         @Const @ByRef table_view left,
                         @Const @ByRef table_view right,
                         @StdVector size_type left_on,
                         @StdVector size_type right_on,
                         @StdVector std::pair<cudf::size_type,cudf::size_type> columns_in_common,
                         device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::experimental") public static native @UniquePtr table left_join(
                         @Const @ByRef table_view left,
                         @Const @ByRef table_view right,
                         @StdVector size_type left_on,
                         @StdVector size_type right_on,
                         @StdVector std::pair<cudf::size_type,cudf::size_type> columns_in_common);

/**
 * \brief  Performs a full join (also known as full outer join) on the
 * specified columns of two tables (left, right)
 *
 * Full Join returns the rows that would be returned by a left join and those
 * rows from the right table that do not have a match.
 * For rows from the right table that do not have a match, the corresponding
 * values in the left columns will be null.
 *
 * \example Left a: {0, 1, 2}
 *          Right b: {1, 2, 3}, c: {1, 2, 5}
 *          left_on: {0}
 *          right_on: {1}
 *          columns_in_common: { {0, 1} }
 * Result: { a: {0, 1, 2, NULL}, b: {NULL, 1, 2, 3}, c: {NULL, 1, 2, 5} }
 *
 * \example Left a: {0, 1, 2}
 *          Right b: {1, 2, 3}, c: {1, 2, 5}
 *          left_on: {0}
 *          right_on: {0}
 *          columns_in_common: { }
 * Result: { a: {0, 1, 2, NULL}, b: {NULL, 1, 2, 3}, c: {NULL, 1, 2, 5} }
 *
 * @throws cudf::logic_error if {@code columns_in_common} contains a pair of indices
 * (L, R) if L does not exist in {@code left_on} or R does not exist in {@code right_on}.
 * @throws cudf::logic_error if {@code columns_in_common} contains a pair of indices
 * (L, R) such that the location of {@code L} within {@code left_on} is not equal to
 * location of R within {@code right_on}
 * @throws cudf::logic_error if number of elements in {@code left_on} or {@code right_on}
 * mismatch.
 * @throws cudf::logic_error if number of columns in either {@code left} or {@code right}
 * table is 0 or exceeds MAX_JOIN_SIZE
 * @throws std::out_of_range if element of {@code left_on} or {@code right_on} exceed the
 * number of columns in the left or right table.
 *
 * @param left [in] The left table
 * @param right [in] The right table
 * @param left_on [in] The column indices from {@code left} to join on.
 * The column from {@code left} indicated by {@code left_on[i]} will be compared against the column
 * from {@code right} indicated by {@code right_on[i]}.
 * @param right_on [in] The column indices from {@code right} to join on.
 * The column from {@code right} indicated by {@code right_on[i]} will be compared against the column
 * from {@code left} indicated by {@code left_on[i]}.
 * @param columns_in_common [in] is a vector of pairs of column indices into
 * {@code left} and {@code right}, respectively, that are "in common". For "common"
 * columns, only a single output column will be produced, which is gathered
 * from {@code left_on} columns. Else, for every column in {@code left_on} and {@code right_on},
 * an output column will be produced.  For each of these pairs (L, R), L
 * should exist in {@code left_on} and R should exist in {@code right_on}.
 * @param mr Memory resource used to allocate the returned table and columns
 *
 * @return Result of joining {@code left} and {@code right} tables on the columns
 * specified by {@code left_on} and {@code right_on}. The resulting table will be joined columns of
 * {@code left(including common columns)+right(excluding common columns)}.
 */
@Namespace("cudf::experimental") public static native @UniquePtr table full_join(
                         @Const @ByRef table_view left,
                         @Const @ByRef table_view right,
                         @StdVector size_type left_on,
                         @StdVector size_type right_on,
                         @StdVector std::pair<cudf::size_type,cudf::size_type> columns_in_common,
                         device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::experimental") public static native @UniquePtr table full_join(
                         @Const @ByRef table_view left,
                         @Const @ByRef table_view right,
                         @StdVector size_type left_on,
                         @StdVector size_type right_on,
                         @StdVector std::pair<cudf::size_type,cudf::size_type> columns_in_common);
/** 
 * \brief  Performs a left semi join on the specified columns of two 
 * tables (left, right)
 *
 * A left semi join only returns data from the left table, and only 
 * returns rows that exist in the right table.
 *
 * \example TableA a: {0, 1, 2}
 *          TableB b: {1, 2, 3}, a: {1, 2, 5}
 *          left_on: {0}
 *          right_on: {1}
 *          return_columns: { 0 }
 * Result: { a: {1, 2} }
 *
 * \example TableA a: {0, 1, 2}, c: {1, 2, 5}
 *          TableB b: {1, 2, 3}
 *          left_on: {0}
 *          right_on: {0}
 *          return_columns: { 1 }
 * Result: { c: {1, 2} }
 *
 * @throws cudf::logic_error if number of columns in either {@code left} or {@code right} table is 0
 * @throws cudf::logic_error if number of returned columns is 0
 * @throws cudf::logic_error if number of elements in {@code right_on} and {@code left_on} are not equal
 *
 * @param left [in]             The left table
 * @param right [in]            The right table
 * @param left_on [in]          The column indices from {@code left} to join on.
 *                             The column from {@code left} indicated by {@code left_on[i]}
 *                             will be compared against the column from {@code right}
 *                             indicated by {@code right_on[i]}.
 * @param right_on [in]         The column indices from {@code right} to join on.
 *                             The column from {@code right} indicated by {@code right_on[i]}
 *                             will be compared against the column from {@code left}
 *                             indicated by {@code left_on[i]}.
 * @param return_columns [in]   A vector of column indices from {@code left} to
 *                             include in the returned table.
 * @param mr [in]               Device memory resource to use for device memory allocation
 *
 * @return                    Result of joining {@code left} and {@code right} tables on the columns
 *                             specified by {@code left_on} and {@code right_on}. The resulting table
 *                             will contain {@code return_columns} from {@code left} that match in right.
 */
@Namespace("cudf::experimental") public static native @UniquePtr table left_semi_join(@Const @ByRef table_view left,
                                                          @Const @ByRef table_view right,
                                                          @StdVector size_type left_on,
                                                          @StdVector size_type right_on,
                                                          @StdVector size_type return_columns,
                                                          device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::experimental") public static native @UniquePtr table left_semi_join(@Const @ByRef table_view left,
                                                          @Const @ByRef table_view right,
                                                          @StdVector size_type left_on,
                                                          @StdVector size_type right_on,
                                                          @StdVector size_type return_columns);

/** 
 * \brief  Performs a left anti join on the specified columns of two 
 * tables (left, right)
 *
 * A left anti join only returns data from the left table, and only 
 * returns rows that do not exist in the right table.
 *
 * \example TableA a: {0, 1, 2}
 *          TableB b: {1, 2, 3}, a: {1, 2, 5}
 *          left_on: {0}
 *          right_on: {1}
 *          return_columns: { 0 }
 * Result: { a: {0} }
 *
 * \example TableA a: {0, 1, 2}, c: {1, 2, 5}
 *          TableB b: {1, 2, 3}
 *          left_on: {0}
 *          right_on: {0}
 *          return_columns: { 1 }
 * Result: { c: {1} }
 *
 * @throws cudf::logic_error if number of columns in either {@code left} or {@code right} table is 0
 * @throws cudf::logic_error if number of returned columns is 0
 * @throws cudf::logic_error if number of elements in {@code right_on} and {@code left_on} are not equal
 *
 * @param left [in]             The left table
 * @param right [in]            The right table
 * @param left_on [in]          The column indices from {@code left} to join on.
 *                             The column from {@code left} indicated by {@code left_on[i]}
 *                             will be compared against the column from {@code right}
 *                             indicated by {@code right_on[i]}.
 * @param right_on [in]         The column indices from {@code right} to join on.
 *                             The column from {@code right} indicated by {@code right_on[i]}
 *                             will be compared against the column from {@code left}
 *                             indicated by {@code left_on[i]}.
 * @param return_columns [in]   A vector of column indices from {@code left} to
 *                             include in the returned table.
 * @param mr [in]               Device memory resource to use for device memory allocation
 *
 * @return                    Result of joining {@code left} and {@code right} tables on the columns
 *                             specified by {@code left_on} and {@code right_on}. The resulting table
 *                             will contain {@code return_columns} from {@code left} that match in right.
 */
@Namespace("cudf::experimental") public static native @UniquePtr table left_anti_join(@Const @ByRef table_view left,
                                                          @Const @ByRef table_view right,
                                                          @StdVector size_type left_on,
                                                          @StdVector size_type right_on,
                                                          @StdVector size_type return_columns,
                                                          device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::experimental") public static native @UniquePtr table left_anti_join(@Const @ByRef table_view left,
                                                          @Const @ByRef table_view right,
                                                          @StdVector size_type left_on,
                                                          @StdVector size_type right_on,
                                                          @StdVector size_type return_columns);
 //namespace experimental

 //namespace cudf


// Parsed from <cudf/filling.hpp>

/*
 * Copyright (c) 2019, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

// #pragma once

// #include <cudf/types.hpp>
// #include <rmm/mr/default_memory_resource.hpp>
// #include <rmm/mr/device_memory_resource.hpp>

// #include <memory>

/**---------------------------------------------------------------------------*
 * \brief Fills a range of elements in-place in a column with a scalar value.
 * 
 * Fills N elements of \p destination starting at \p begin with \p value, where
 * N = (\p end - \p begin).
 *
 * Overwrites the range of elements in \p destination indicated by the indices
 * [\p begin, \p end) with \p value. Use the out-of-place fill function
 * returning std::unique_ptr<column> for use cases requiring memory
 * reallocation.
 *
 * @throws {@code cudf::logic_error} if memory reallocation is required (e.g. for
 * variable width types).
 * @throws {@code cudf::logic_error} for invalid range (if \p begin < 0,
 * \p begin > \p end, \p begin >= \p destination.size(), or
 * \p end > \p destination.size()).
 * @throws {@code cudf::logic_error} if \p destination and \p value have different
 * types.
 * @throws {@code cudf::logic_error} if \p value is invalid but \p destination is not
 * nullable.
 *
 * @param destination The preallocated column to fill into
 * @param begin The starting index of the fill range (inclusive)
 * @param end The index of the last element in the fill range (exclusive)
 * @param value The scalar value to fill
 * @return void
 *---------------------------------------------------------------------------**/

/**---------------------------------------------------------------------------*
 * \brief Fills a range of elements in a column out-of-place with a scalar
 * value.
 * 
 * Creates a new column as-if an in-place fill was performed into \p input;
 * i.e. it is as if a copy of \p input was created first and then the elements
 * indicated by the indices [\p begin, \p end) were overwritten by \p value.
 *
 * @throws {@code cudf::logic_error} for invalid range (if \p begin < 0,
 * \p begin > \p end, \p begin >= \p destination.size(), or
 * \p end > \p destination.size()).
 * @throws {@code cudf::logic_error} if \p destination and \p value have different
 * types.
 *
 * @param input The input column used to create a new column. The new column
 * is created by replacing the values of \p input in the specified range with
 * \p value.
 * @param begin The starting index of the fill range (inclusive)
 * @param end The index of the last element in the fill range (exclusive)
 * @param value The scalar value to fill
 * @param mr Memory resource to allocate the result output column
 * @return std::unique_ptr<column> The result output column
 *---------------------------------------------------------------------------**/
@Namespace("cudf::experimental") public static native @Name("fill") @MoveUniquePtr column _fill(
    @Const @ByRef column_view input, @ByVal size_type begin, @ByVal size_type end,
    @Const @ByRef scalar value,
    device_memory_resource mr/*=rmm::mr::get_default_resource()*/);

/**---------------------------------------------------------------------------*
 * \brief Repeat rows of a Table.
 * 
 * Creates a new table by repeating the rows of \p input_table. The number of 
 * repetitions of each element is defined by the value at the corresponding 
 * index of \p count
 * Example:
 * <pre>{@code
 * in = [4,5,6]
 * count = [1,2,3]
 * return = [4,5,5,6,6,6]
 * }</pre>
 * \p count should not have null values; should not contain negative values;
 * and the sum of count elements should not overflow the size_type's limit.
 * It is undefined behavior if \p count has negative values or the sum overflows
 * and \p check_count is set to false.
 *
 * @throws {@code cudf::logic_error} if the data type of \p count is not size_type.
 * @throws {@code cudf::logic_error} if \p input_table and \p count have different
 * number of rows.
 * @throws {@code cudf::logic_error} if \p count has null values.
 * @throws {@code cudf::logic_error} if \p check_count is set to true and \p count
 * has negative values or the sum of \p count elements overflows.
 *
 * @param input_table Input table
 * @param count Non-nullable column of a integral type
 * @param check_count Whether to check count (negative values and overflow)
 * @param mr Memory resource to allocate the result output table
 * @return std::unique_ptr<table> The result table containing the repetitions
 *---------------------------------------------------------------------------**/
@Namespace("cudf::experimental") public static native @UniquePtr table repeat(
    @Const @ByRef table_view input_table, @Const @ByRef column_view count,
    @Cast("bool") boolean check_count/*=false*/,
    device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::experimental") public static native @UniquePtr table repeat(
    @Const @ByRef table_view input_table, @Const @ByRef column_view count);

/**---------------------------------------------------------------------------*
 * \brief Repeat rows of a Table.
 * 
 * Creates a new table by repeating \p count times the rows of \p input_table.
 * Example:
 * <pre>{@code
 * in = [4,5,6]
 * count = 2
 * return = [4,4,5,5,6,6]
 * }</pre>
 * @throws {@code cudf::logic_error} if the data type of \p count is not size_type.
 * @throws {@code cudf::logic_error} if \p count is invalid or \p count is negative.
 * @throws {@code cudf::logic_error} if \p input_table.num_rows() * \p count overflows
 * size_type.
 * 
 * @param input_table Input table
 * @param count Non-null scalar of a integral type
 * @param mr Memory resource to allocate the result output table
 * @return std::unique_ptr<table> The result table containing the repetitions
 *---------------------------------------------------------------------------**/
@Namespace("cudf::experimental") public static native @UniquePtr table repeat(
    @Const @ByRef table_view input_table, @Const @ByRef scalar count,
    device_memory_resource mr/*=rmm::mr::get_default_resource()*/);

  // namespace experimental
  // namespace cudf


// Parsed from <cudf/io/writers.hpp>

/*
 * Copyright (c) 2019, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

/**
 * \file readers.hpp
 * \brief cuDF-IO writer classes API
 */

// #pragma once

// #include "types.hpp"

// #include <cudf/table/table_view.hpp>
// #include <cudf/types.hpp>

// #include <memory>
// #include <utility>

/** cuDF interfaces */
/** In-development features */
/** IO interfaces */
/** Inner interfaces and implementations */

/** ORC format */
// Targeting ../writer_options.java


// Targeting ../writer.java



  // namespace orc


/** Parquet format */

/**
 * \brief Options for the parquet writer.
 */

/**
 * \brief Class to write parquet dataset data into columns.
 */

  // namespace parquet


  // namespace detail
  // namespace io
  // namespace experimental
  // namespace cudf


// Parsed from <cudf/io/functions.hpp>

/*
 * Copyright (c) 2019, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

/**
 * \file functions.hpp
 * \brief cuDF-IO freeform API
 */

// #pragma once

// #include "types.hpp"

// #include <cudf/table/table_view.hpp>
// #include <cudf/types.hpp>

// #include <memory>
// #include <string>
// #include <unordered_map>
// #include <vector>

/** cuDF interfaces */
/** In-development features */
/** IO interfaces */
// Targeting ../read_avro_args.java



/**
 * \brief Reads an Avro dataset into a set of columns
 *
 * The following code snippet demonstrates how to read a dataset from a file:
 * <pre>{@code
 *  #include <cudf.h>
 *  ...
 *  std::string filepath = "dataset.avro";
 *  cudf::read_avro_args args{cudf::source_info(filepath)};
 *  ...
 *  auto result = cudf::read_avro(args);
 * }</pre>
 *
 * @param args Settings for controlling reading behavior
 * @param mr Optional resource to use for device memory allocation
 *
 * @return The set of columns along with metadata
 */
@Namespace("cudf::experimental::io") public static native @ByVal table_with_metadata read_avro(
    @Const @ByRef read_avro_args args,
    device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::experimental::io") public static native @ByVal table_with_metadata read_avro(
    @Const @ByRef read_avro_args args);
// Targeting ../read_csv_args.java



/**
 * \brief Reads a CSV dataset into a set of columns
 *
 * The following code snippet demonstrates how to read a dataset from a file:
 * <pre>{@code
 *  #include <cudf.h>
 *  ...
 *  std::string filepath = "dataset.csv";
 *  cudf::read_csv_args args{cudf::source_info(filepath)};
 *  ...
 *  auto result = cudf::read_csv(args);
 * }</pre>
 *
 * @param args Settings for controlling reading behavior
 * @param mr Optional resource to use for device memory allocation
 *
 * @return The set of columns along with metadata
 */
@Namespace("cudf::experimental::io") public static native @ByVal table_with_metadata read_csv(
    @Const @ByRef read_csv_args args,
    device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::experimental::io") public static native @ByVal table_with_metadata read_csv(
    @Const @ByRef read_csv_args args);
// Targeting ../read_orc_args.java



/**
 * \brief Reads an ORC dataset into a set of columns
 *
 * The following code snippet demonstrates how to read a dataset from a file:
 * <pre>{@code
 *  #include <cudf.h>
 *  ...
 *  std::string filepath = "dataset.orc";
 *  cudf::read_orc_args args{cudf::source_info(filepath)};
 *  ...
 *  auto result = cudf::read_orc(args);
 * }</pre>
 *
 * @param args Settings for controlling reading behavior
 * @param mr Optional resource to use for device memory allocation
 *
 * @return The set of columns
 */
@Namespace("cudf::experimental::io") public static native @ByVal table_with_metadata read_orc(
    @Const @ByRef read_orc_args args,
    device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::experimental::io") public static native @ByVal table_with_metadata read_orc(
    @Const @ByRef read_orc_args args);
// Targeting ../write_orc_args.java



/**
 * \brief Writes a set of columns to ORC format
 *
 * The following code snippet demonstrates how to write columns to a file:
 * <pre>{@code
 *  #include <cudf.h>
 *  ...
 *  std::string filepath = "dataset.orc";
 *  cudf::write_orc_args args{cudf::sink_info(filepath), table->view()};
 *  ...
 *  cudf::write_orc(args);
 * }</pre>
 *
 * @param args Settings for controlling reading behavior
 * @param mr Optional resource to use for device memory allocation
 */
@Namespace("cudf::experimental::io") public static native void write_orc(@Const @ByRef write_orc_args args, device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::experimental::io") public static native void write_orc(@Const @ByRef write_orc_args args);
// Targeting ../read_parquet_args.java



/**
 * \brief Reads a Parquet dataset into a set of columns
 *
 * The following code snippet demonstrates how to read a dataset from a file:
 * <pre>{@code
 *  #include <cudf.h>
 *  ...
 *  std::string filepath = "dataset.parquet";
 *  cudf::read_parquet_args args{cudf::source_info(filepath)};
 *  ...
 *  auto result = cudf::read_parquet(args);
 * }</pre>
 *
 * @param args Settings for controlling reading behavior
 * @param mr Optional resource to use for device memory allocation
 *
 * @return The set of columns along with metadata
 */
@Namespace("cudf::experimental::io") public static native @ByVal table_with_metadata read_parquet(
    @Const @ByRef read_parquet_args args,
    device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::experimental::io") public static native @ByVal table_with_metadata read_parquet(
    @Const @ByRef read_parquet_args args);
// Targeting ../write_parquet_args.java



/**
 * \brief Writes a set of columns to parquet format
 *
 * The following code snippet demonstrates how to write columns to a file:
 * <pre>{@code
 *  #include <cudf.h>
 *  ...
 *  std::string filepath = "dataset.parquet";
 *  cudf::experimental::io::write_parquet_args args{cudf::sink_info(filepath), table->view()};
 *  ...
 *  cudf::write_parquet(args);
 * }</pre>
 *
 * @param args Settings for controlling writing behavior
 * @param mr Optional resource to use for device memory allocation
 */
@Namespace("cudf::experimental::io") public static native void write_parquet(@Const @ByRef write_parquet_args args, device_memory_resource mr/*=rmm::mr::get_default_resource()*/);
@Namespace("cudf::experimental::io") public static native void write_parquet(@Const @ByRef write_parquet_args args);


  // namespace io
  // namespace experimental
  // namespace cudf


// Parsed from <cudf/io/types.hpp>

/*
 * Copyright (c) 2019, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

/**
 * \file types.hpp
 * \brief cuDF-IO API type definitions
 */

// #pragma once

// #include <memory>
// #include <vector>
// #include <string>
// #include <map>
// #include <cudf/types.hpp>
// Targeting ../RandomAccessFile.java



  // namespace arrow

/** cuDF interfaces */
/** In-development features */
/** IO interfaces */

/**
 * \brief Compression algorithms
 */
/** enum class cudf::experimental::io::compression_type */
public static final int
  /** No compression */
  NONE = 0,
  /** Automatically detect or select compression format */
  AUTO = 1,
  /** Snappy format, using byte-oriented LZ77 */
  SNAPPY = 2,
  /** GZIP format, using DEFLATE algorithm */
  GZIP = 3,
  /** BZIP2 format, using Burrows-Wheeler transform */
  BZIP2 = 4,
  /** BROTLI format, using LZ77 + Huffman + 2nd order context modeling */
  BROTLI = 5,
  /** ZIP format, using DEFLATE algorithm */
  ZIP = 6,
  /** XZ format, using LZMA(2) algorithm */
  XZ = 7;

/**
 * \brief Data source or destination types
 */
/** enum class cudf::experimental::io::io_type */
public static final int
  /** Input/output is a file path */
  FILEPATH = 0,
  /** Input/output is a buffer in host memory, */
  HOST_BUFFER = 1,
  /** Input/output is an arrow::io::RandomAccessFile */
  ARROW_RANDOM_ACCESS_FILE = 2;

/**
 * \brief Behavior when handling quotations in field data
 */
/** enum class cudf::experimental::io::quote_style */
public static final int
  /** Quote only fields which contain special characters */
  MINIMAL = 0,
  /** Quote all fields */
  ALL = 1,
  /** Quote all non-numeric fields */
  NONNUMERIC = 2,
  /** Never quote fields; disable quotation parsing */
  NONE = 3;

/**
 * \brief Column statistics granularity type for parquet/orc writers
 */
/** enum cudf::experimental::io::statistics_freq */
public static final int
  /** No column statistics */
  STATISTICS_NONE = 0,
  /** Per-Rowgroup column statistics */
  STATISTICS_ROWGROUP = 1,
  /** Per-page column statistics */
  STATISTICS_PAGE = 2;
// Targeting ../table_metadata.java


// Targeting ../table_with_metadata.java


// Targeting ../source_info.java


// Targeting ../sink_info.java



  // namespace io
  // namespace experimental
  // namespace cudf


// Parsed from <cudf/io/readers.hpp>

/*
 * Copyright (c) 2019, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

/**
 * \file readers.hpp
 * \brief cuDF-IO reader classes API
 */

// #pragma once

// #include "types.hpp"

// #include <cudf/types.hpp>

// #include <memory>
// #include <string>
// #include <unordered_map>
// #include <utility>
// #include <vector>

// Forward declarations

  // namespace arrow

/** cuDF interfaces */
/** In-development features */
/** IO interfaces */
/** Inner interfaces and implementations */

/** Avro format */
// Targeting ../reader_options.java


// Targeting ../reader.java



  // namespace avro

/** CSV format */

/**
 * \brief Options for the CSV reader.
 */

/**
 * \brief Class to read CSV dataset data into columns.
 */

  // namespace csv

/** ORC format */

/**
 * \brief Options for the ORC reader.
 */

/**
 * \brief Class to read ORC dataset data into columns.
 */

  // namespace orc

/** Parquet format */

/**
 * \brief Options for the Parquet reader.
 */

/**
 * \brief Class to read Parquet dataset data into columns.
 */

  // namespace parquet

  // namespace detail
  // namespace io
  // namespace experimental
  // namespace cudf


// Parsed from <cudf/convert_types.h>


// #pragma once
// Targeting ../csr_gdf.java







// Parsed from <cudf/utilities/nvtx_utils.hpp>

// #pragma once

// #include <cstdint>

/** enum class cudf::nvtx::color */
public static final int
  GREEN = 0xff00ff00, 
  BLUE = 0xff0000ff,
  YELLOW = 0xffffff00,
  PURPLE = 0xffff00ff,
  CYAN = 0xff00ffff,
  RED = 0xffff0000,
  WHITE = 0xffffffff,
  DARK_GREEN = 0xff006600,
  ORANGE = 0xffffa500;

@Namespace("cudf::nvtx") @MemberGetter public static native @Cast("const cudf::nvtx::color") int JOIN_COLOR();
@Namespace("cudf::nvtx") @MemberGetter public static native @Cast("const cudf::nvtx::color") int GROUPBY_COLOR();
@Namespace("cudf::nvtx") @MemberGetter public static native @Cast("const cudf::nvtx::color") int BINARY_OP_COLOR();
@Namespace("cudf::nvtx") @MemberGetter public static native @Cast("const cudf::nvtx::color") int PARTITION_COLOR();
@Namespace("cudf::nvtx") @MemberGetter public static native @Cast("const cudf::nvtx::color") int READ_CSV_COLOR();

/**---------------------------------------------------------------------------*
 * \brief  Start an NVTX range.
 *
 * This function is useful only for profiling with nvvp or Nsight Systems. It
 * demarcates the begining of a user-defined range with a specified name and
 * color that will show up in the timeline view of nvvp/Nsight Systems. Can be
 * nested within other ranges.
 *
 * @throws cudf::logic_error if {@code name} is null
 *
 * @param name [in] The name of the NVTX range
 * @param color [in] The color to use for the range
 *---------------------------------------------------------------------------**/
@Namespace("cudf::nvtx") public static native void range_push(@Cast("const char*") BytePointer name, @Cast("cudf::nvtx::color") int color);
@Namespace("cudf::nvtx") public static native void range_push(String name, @Cast("cudf::nvtx::color") int color);

/**---------------------------------------------------------------------------*
 * \brief  Start a NVTX range with a custom ARGB color code.
 *
 * This function is useful only for profiling with nvvp or Nsight Systems. It
 * demarcates the begining of a user-defined range with a specified name and
 * color that will show up in the timeline view of nvvp/Nsight Systems. Can be
 * nested within other ranges.
 *
 * @throws cudf::logic_error if {@code name} is null
 *
 * @param name [in] The name of the NVTX range
 * @param color [in] The ARGB hex color code to use to color this range (e.g., 0xFF00FF00)
 *---------------------------------------------------------------------------**/
@Namespace("cudf::nvtx") public static native void range_push_hex(@Cast("const char*") BytePointer name, @Cast("uint32_t") int color);
@Namespace("cudf::nvtx") public static native void range_push_hex(String name, @Cast("uint32_t") int color);

/**---------------------------------------------------------------------------*
 * \brief Ends the inner-most NVTX range.
 *
 * This function is useful only for profiling with nvvp or Nsight Systems. It
 * will demarcate the end of the inner-most range, i.e., the most recent call to
 * range_push.
 *---------------------------------------------------------------------------**/
@Namespace("cudf::nvtx") public static native void range_pop();

  // namespace nvtx
  // namespace cudf


// Parsed from <cudf/utilities/bit.hpp>

/*
 * Copyright (c) 2019, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

// #pragma once

// #include <cudf/types.hpp>

// #include <cassert>

/**
 * \file bit.hpp
 * \brief Utilities for bit and bitmask operations.
 *
 */


/**---------------------------------------------------------------------------*
 * \brief Returns the position within a word of the specified bit.
 *---------------------------------------------------------------------------**/
@Namespace("cudf") public static native int intra_word_index(@ByVal size_type bit_index);

/**---------------------------------------------------------------------------*
 * \brief Sets the specified bit to {@code 1}
 *
 * This function is not thread-safe, i.e., attempting to update bits within the
 * same word concurrently from multiple threads results in undefined behavior.
 *
 * @param bitmask The bitmask containing the bit to set
 * @param bit_index Index of the bit to set
 *---------------------------------------------------------------------------**/
@Namespace("cudf") public static native int set_bit_unsafe(@Cast("cudf::bitmask_type*") IntPointer bitmask,
                                              @ByVal size_type bit_index);
@Namespace("cudf") public static native int set_bit_unsafe(@Cast("cudf::bitmask_type*") IntBuffer bitmask,
                                              @ByVal size_type bit_index);
@Namespace("cudf") public static native int set_bit_unsafe(@Cast("cudf::bitmask_type*") int[] bitmask,
                                              @ByVal size_type bit_index);

/**---------------------------------------------------------------------------*
 * \brief Sets the specified bit to {@code 0}
 *
 * This function is not thread-safe, i.e., attempting to update bits within the
 * same word concurrently from multiple threads results in undefined behavior.
 *
 * @param bitmask The bitmask containing the bit to clear
 * @param bit_index The index of the bit to clear
 *---------------------------------------------------------------------------**/
@Namespace("cudf") public static native int clear_bit_unsafe(@Cast("cudf::bitmask_type*") IntPointer bitmask,
                                                @ByVal size_type bit_index);
@Namespace("cudf") public static native int clear_bit_unsafe(@Cast("cudf::bitmask_type*") IntBuffer bitmask,
                                                @ByVal size_type bit_index);
@Namespace("cudf") public static native int clear_bit_unsafe(@Cast("cudf::bitmask_type*") int[] bitmask,
                                                @ByVal size_type bit_index);

/**---------------------------------------------------------------------------*
 * \brief Indicates whether the specified bit is set to {@code 1}
 *
 * @param bit_index Index of the bit to test
 * @return true The specified bit is {@code 1}
 * @return false  The specified bit is {@code 0}
 *---------------------------------------------------------------------------**/
@Namespace("cudf") public static native int bit_is_set(@Cast("const cudf::bitmask_type*") IntPointer bitmask,
                                                 @ByVal size_type bit_index);
@Namespace("cudf") public static native int bit_is_set(@Cast("const cudf::bitmask_type*") IntBuffer bitmask,
                                                 @ByVal size_type bit_index);
@Namespace("cudf") public static native int bit_is_set(@Cast("const cudf::bitmask_type*") int[] bitmask,
                                                 @ByVal size_type bit_index);

/**---------------------------------------------------------------------------*
 * \brief Returns a bitmask word with the {@code n} least significant bits set.
 *
 * Behavior is undefined if {@code n < 0} or if {@code n >= size_in_bits<bitmask_type>()}
 *
 * @param n The number of least significant bits to set
 * @return A bitmask word with {@code n} least significant bits set
 *---------------------------------------------------------------------------**/
@Namespace("cudf") public static native int set_least_significant_bits(@ByVal size_type n);

/**---------------------------------------------------------------------------*
 * \brief Returns a bitmask word with the {@code n} most significant bits set.
 *
 * Behavior is undefined if {@code n < 0} or if {@code n >= size_in_bits<bitmask_type>()}
 *
 * @param n The number of most significant bits to set
 * @return A bitmask word with {@code n} most significant bits set
 *---------------------------------------------------------------------------**/
@Namespace("cudf") public static native int set_most_significant_bits(@ByVal size_type n);

// #ifdef __CUDACC__

/**---------------------------------------------------------------------------*
 * \brief Sets the specified bit to {@code 1}
 *
 * \note This operation requires a global atomic operation. Therefore, it is
 * not recommended to use this function in performance critical regions. When
 * possible, it is more efficient to compute and update an entire word at
 * once using {@code set_word}.
 *
 * This function is thread-safe.
 *
 * @param bitmask The bitmask containing the bit to set
 * @param bit_index  Index of the bit to set
 *---------------------------------------------------------------------------**/
@Namespace("cudf") public static native @ByVal __device__ set_bit(@Cast("cudf::bitmask_type*") IntPointer bitmask, @ByVal size_type bit_index);
@Namespace("cudf") public static native @ByVal __device__ set_bit(@Cast("cudf::bitmask_type*") IntBuffer bitmask, @ByVal size_type bit_index);
@Namespace("cudf") public static native @ByVal __device__ set_bit(@Cast("cudf::bitmask_type*") int[] bitmask, @ByVal size_type bit_index);

/**---------------------------------------------------------------------------*
 * \brief Sets the specified bit to {@code 0}
 *
 * \note This operation requires a global atomic operation. Therefore, it is
 * not reccomended to use this function in performance critical regions. When
 * possible, it is more efficient to compute and update an entire element at
 * once using {@code set_element}.
 <p>
 * This function is thread-safe.
 *
 * @param bit_index  Index of the bit to clear
 *---------------------------------------------------------------------------**/
@Namespace("cudf") public static native @ByVal __device__ clear_bit(@Cast("cudf::bitmask_type*") IntPointer bitmask, @ByVal size_type bit_index);
@Namespace("cudf") public static native @ByVal __device__ clear_bit(@Cast("cudf::bitmask_type*") IntBuffer bitmask, @ByVal size_type bit_index);
@Namespace("cudf") public static native @ByVal __device__ clear_bit(@Cast("cudf::bitmask_type*") int[] bitmask, @ByVal size_type bit_index);
// #endif
  // namespace cudf


// Parsed from <cudf/utilities/traits.hpp>

/*
 * Copyright (c) 2019, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

// #pragma once

// #include <cudf/types.hpp>
// #include <cudf/wrappers/timestamps.hpp>
// #include <cudf/utilities/type_dispatcher.hpp>
// #include <cudf/strings/string_view.ch>

// #include <type_traits>
// Targeting ../void_t.java



/**---------------------------------------------------------------------------*
 * \brief Indicates whether objects of types {@code L} and {@code R} can be relationally
 *compared.
 *
 * Given two objects {@code L l}, and {@code R r}, returns true if {@code l < r} and {@code l > r} are
 * well-formed expressions.
 *
 * \tparam L Type of the first object
 * \tparam R Type of the second object
 * @return true Objects of types {@code L} and {@code R} can be relationally be compared
 * @return false Objects of types {@code L} and {@code R} cannot be compared
 *---------------------------------------------------------------------------**/
// Targeting ../is_numeric_impl.java



/**---------------------------------------------------------------------------*
 * \brief Indicates whether {@code type} is a numeric {@code data_type}.
 *
 * "Numeric" types are fundamental integral/floating point types such as {@code INT*}
 * or {@code FLOAT*}. Types that wrap a numeric type are not considered numeric, e.g.,
 *{@code TIMESTAMP}.
 *
 * @param type The {@code data_type} to verify
 * @return true {@code type} is numeric
 * @return false {@code type} is not numeric
 *---------------------------------------------------------------------------**/
@Namespace("cudf") public static native @Cast("const bool") boolean is_numeric(@ByVal data_type type);
// Targeting ../is_boolean_impl.java



/**---------------------------------------------------------------------------*
 * \brief Indicates whether {@code type} is a Boolean {@code data_type}.
 *
 * {@code cudf::bool8} is cudf's Boolean type.
 *
 * @param type The {@code data_type} to verify
 * @return true {@code type} is a Boolean
 * @return false {@code type} is not a Boolean
 *---------------------------------------------------------------------------**/
@Namespace("cudf") public static native @Cast("const bool") boolean is_boolean(@ByVal data_type type);
// Targeting ../is_timestamp_impl.java



/**---------------------------------------------------------------------------*
 * \brief Indicates whether {@code type} is a timestamp {@code data_type}.
 *
 * "Timestamp" types are int32_t or int64_t durations since the unix epoch.
 *
 * @param type The {@code data_type} to verify
 * @return true {@code type} is a timestamp
 * @return false {@code type} is not a timestamp
 *---------------------------------------------------------------------------**/
@Namespace("cudf") public static native @Cast("const bool") boolean is_timestamp(@ByVal data_type type);
// Targeting ../is_fixed_width_impl.java



/**---------------------------------------------------------------------------*
 * \brief Indicates whether elements of {@code type} are fixed-width.
 *
 * Elements of a fixed-width type all have the same size in bytes.
 *
 * @param type The {@code data_type} to verify
 * @return true {@code type} is fixed-width
 * @return false  {@code type} is variable-width
 *---------------------------------------------------------------------------**/
@Namespace("cudf") public static native @Cast("const bool") boolean is_fixed_width(@ByVal data_type type);
// Targeting ../is_compound_impl.java



/**---------------------------------------------------------------------------*
 * \brief Indicates whether elements of {@code type} are compound.
 *
 * {@code column}s with "compound" elements are logically a single column of elements,
 * but may be concretely implemented with two or more {@code column}s. For example, a
 * {@code STRING} column could contain a {@code column} of offsets and a child {@code column} of
 * characters.
 *
 * @param type The {@code data_type} to verify
 * @return true {@code type} is a compound type
 * @return false {@code type} is a simple type
 *---------------------------------------------------------------------------**/
@Namespace("cudf") public static native @Cast("const bool") boolean is_compound(@ByVal data_type type);
// Targeting ../is_simple_impl.java



/**---------------------------------------------------------------------------*
 * \brief Indicates whether elements of {@code type} are simple.
 *
 * "Simple" element types are implemented with only a single column, i.e.,
 * {@code num_children() == 0} for columns of "simple" elements
 *
 * @param type The {@code data_type} to verify
 * @return true {@code type} is a simple type
 * @return false {@code type} is a compound type
 *---------------------------------------------------------------------------**/
@Namespace("cudf") public static native @Cast("const bool") boolean is_simple(@ByVal data_type type);

  // namespace cudf


// Parsed from <cudf/utilities/error.hpp>

// #pragma once

// #include <cuda.h>
// #include <cuda_runtime_api.h>
// #include <string>
// #include <stdexcept>

// #include <rmm/rmm.h>

// #define RMM_TRY(call)
//   do {
//     rmmError_t const status = (call);
//     if (RMM_SUCCESS != status) {
//       cudf::detail::throw_rmm_error(status, __FILE__, __LINE__);
//     }
//   } while (0);

// #define RMM_TRY_CUDAERROR(x)
//   if ((x) != RMM_SUCCESS) CUDA_TRY(cudaPeekAtLastError());
// Targeting ../logic_error.java


// Targeting ../cuda_error.java


  // namespace cudf

// #define STRINGIFY_DETAIL(x) #x
// #define CUDF_STRINGIFY(x) STRINGIFY_DETAIL(x)

/**---------------------------------------------------------------------------*
 * \brief Macro for checking (pre-)conditions that throws an exception when  
 * a condition is violated.
 * 
 * Example usage:
 * 
 * <pre>{@code
 * CUDF_EXPECTS(lhs->dtype == rhs->dtype, "Column type mismatch");
 * }</pre>
 *
 * @param cond [in] Expression that evaluates to true or false
 * @param reason [in] String literal description of the reason that cond is
 * expected to be true
 * @throws cudf::logic_error if the condition evaluates to false.
 *---------------------------------------------------------------------------**/
// #define CUDF_EXPECTS(cond, reason)
//   (!!(cond))
//       ? static_cast<void>(0)
//       : throw cudf::logic_error("cuDF failure at: " __FILE__
//                                 ":" CUDF_STRINGIFY(__LINE__) ": " reason)

/**---------------------------------------------------------------------------*
 * \brief Indicates that an erroneous code path has been taken.
 *
 * In host code, throws a {@code cudf::logic_error}.
 *
 *
 * Example usage:
 * <pre>{@code
 * CUDF_FAIL("Non-arithmetic operation is not supported");
 * }</pre>
 * 
 * @param reason [in] String literal description of the reason
 *---------------------------------------------------------------------------**/
// #define CUDF_FAIL(reason)
//   throw cudf::logic_error("cuDF failure at: " __FILE__
//                           ":" CUDF_STRINGIFY(__LINE__) ": " reason)

@Namespace("cudf::detail") public static native void throw_rmm_error(@ByVal rmmError_t error, @Cast("const char*") BytePointer file,
                             @Cast("unsigned int") int line);
@Namespace("cudf::detail") public static native void throw_rmm_error(@ByVal rmmError_t error, String file,
                             @Cast("unsigned int") int line);

@Namespace("cudf::detail") public static native void throw_cuda_error(@ByVal cudaError_t error, @Cast("const char*") BytePointer file,
                             @Cast("unsigned int") int line);
@Namespace("cudf::detail") public static native void throw_cuda_error(@ByVal cudaError_t error, String file,
                             @Cast("unsigned int") int line);
  // namespace detail
  // namespace cudf

/**---------------------------------------------------------------------------*
 * \brief Error checking macro for CUDA runtime API functions.
 *
 * Invokes a CUDA runtime API function call, if the call does not return
 * cudaSuccess, invokes cudaGetLastError() to clear the error and throws an
 * exception detailing the CUDA error that occurred
 *
 * This macro supersedes GDF_REQUIRE and should be preferred in all instances.
 * GDF_REQUIRE should be considered deprecated.
 *
 *---------------------------------------------------------------------------**/
// #define CUDA_TRY(call)
//   do {
//     cudaError_t const status = (call);
//     if (cudaSuccess != status) {
//       cudaGetLastError();
//       cudf::detail::throw_cuda_error(status, __FILE__, __LINE__);
//     }
//   } while (0);

/**---------------------------------------------------------------------------*
 * \brief Debug macro to check for CUDA errors
 *
 * In a non-release build, this macro will synchronize the specified stream
 * before error checking. In both release and non-release builds, this macro
 * checks for any pending CUDA errors from previous calls. If an error is
 * reported, an exception is thrown detailing the CUDA error that occurred.
 *
 * The intent of this macro is to provide a mechanism for synchronous and
 * deterministic execution for debugging asynchronous CUDA execution. It should
 * be used after any asynchronous CUDA call, e.g., cudaMemcpyAsync, or an
 * asynchronous kernel launch.
 *
 *---------------------------------------------------------------------------**/
// #ifndef NDEBUG
// #define CHECK_CUDA(stream)
//   CUDA_TRY(cudaStreamSynchronize(stream));
// #else
// #define CHECK_CUDA(stream)
//   CUDA_TRY(cudaPeekAtLastError());
// #endif


// Parsed from <cudf/utilities/legacy/nvcategory_util.hpp>

// #ifndef NVCATEGORY_UTIL_H
// #define NVCATEGORY_UTIL_H

// #include <cudf/cudf.h>
// #include <vector>
// Targeting ../NVCategory.java




@MemberGetter public static native @Cast("const bool") boolean DEVICE_ALLOCATED();
@MemberGetter public static native @Cast("const bool") boolean HOST_ALLOCATED();
/**
 * \brief Create a condensed copy of an nvcategory using a column of indices
 *
 * This function abstracts the usecase of gathering indices from an NVCategory.
 *
 * @param column [in,out] the column for which we are generating a new NVCategory
 * @param nv_category [in] the category that contains the data these indices map to
 * @return a gdf_error indicating success or failure type
 */
public static native @Cast("gdf_error") int nvcategory_gather(gdf_column column, NVCategory nv_category);

/**
 * \brief Takes an array of input_columns and concatenates them into one long column.
 *
 * @param input_columns [in] The Columns to concat.
 * @param Concatted [out] output
 * @param number [in] of input columns
 */
public static native @Cast("gdf_error") int concat_categories(@Cast("const gdf_column*const*") PointerPointer input_columns, gdf_column output_column, int num_columns);
public static native @Cast("gdf_error") int concat_categories(@Const @ByPtrPtr gdf_column input_columns, gdf_column output_column, int num_columns);

/**
 * \brief Takes an array of input_columns and makes it so that they all share the same keys in NVCategory
 *
 * @param input_columns [in] the columns whose categories must be synchronized
 * @param output_columns [out] same data as input_columns but with categories syncrhonized
 * @param num_columns [in] number of input columns
 */
public static native @Cast("gdf_error") int sync_column_categories(@Cast("const gdf_column*const*") PointerPointer input_columns, @Cast("gdf_column**") PointerPointer output_columns, int num_columns);
public static native @Cast("gdf_error") int sync_column_categories(@Const @ByPtrPtr gdf_column input_columns, @ByPtrPtr gdf_column output_columns, int num_columns);

/**
 * \brief Takes two tables and gathers the destination table's data interpreted as int32 from the dictionary of the source table's NVCategory.
 *
 * @param source_table [in] Contains columns that contain dictionaries used for gathering.
 * @param destination_table [in,out] Contains columns that contain indices that map into source_table dictionaries.
 */
public static native @Cast("gdf_error") int nvcategory_gather_table(@ByVal table source_table, @ByVal table destination_table);

// #endif


// Parsed from <cudf/utilities/legacy/type_dispatcher.hpp>

/*
 * Copyright (c) 2019, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
// #ifndef TYPE_DISPATCHER_HPP
// #define TYPE_DISPATCHER_HPP

// #include <cudf/utilities/legacy/wrapper_types.hpp>
// #include <cudf/detail/utilities/release_assert.ch>


// #include <cudf/types.h>
// Targeting ../NVStrings.java



// #include <cassert>
// #include <utility>

/* --------------------------------------------------------------------------*/
/**
 * \brief  Invokes an instance of a functor template with the appropriate type
 * determined by a gdf_dtype enum value.
 *
 * This helper function accepts any object with an "operator()" template,
 * e.g., a functor. It will invoke an instance of the template by passing
 * in as the template argument an appropriate type determined by the value of
 * the gdf_dtype argument.
 *
 * The template may have 1 or more template parameters, but the first parameter
 * must be the type dispatched from the gdf_dtype enum.  The remaining template
 * parameters must be able to be automatically deduced.
 *
 * There is a 1-to-1 mapping of gdf_dtype enum values and dispatched types.
 * However, different gdf_dtype values may have the same underlying type.
 * Therefore, in order to provide the 1-to-1 mapping, a wrapper struct may be
 * dispatched for certain gdf_dtype enum values in order to emulate a "strong
 * typedef".
 *
 * A strong typedef  provides a new, concrete type unlike a normal C++ typedef
 * which is simply a type alias. These "strong typedef" structs simply wrap a
 * single member variable of a fundamental type called 'value'.
 *
 * The standard arithmetic operators are defined for the wrapper structs and
 * therefore the wrapper struct types can be used as if they were fundamental
 * types.
 *
 * See wrapper_types.hpp for more detail.
 *
 * Example usage with a functor that returns the size of the dispatched type:
 *
 * <pre>{@code
 * struct example_functor{
 *  template <typename T>
 *  int operator()(){
 *    return sizeof(T);
 *  }
 * };
 *
 * cudf::type_dispatcher(GDF_INT8, example_functor{});  // returns 1
 * cudf::type_dispatcher(GDF_INT64, example_functor{}); // returns 8
 * }</pre>
 *
 * Example usage of a functor for checking if element "i" in column "lhs" is
 * equal to element "j" in column "rhs":
 *
 * <pre>{@code
 * struct elements_are_equal{
 *   template <typename ColumnType>
 *   bool operator()(void const * lhs, int i,
 *                   void const * rhs, int j)
 *   {
 *     // Cast the void* data buffer to the dispatched type and retrieve
 * elements
 *     // "i" and "j" from the respective columns
 *     ColumnType const i_elem = static_cast<ColumnType const*>(lhs)[i];
 *     ColumnType const j_elem = static_cast<ColumnType const*>(rhs)[j];
 *
 *     // operator== is defined for wrapper structs such that it performs the
 *     // operator== on the underlying values. Therefore, the wrapper structs
 *     // can be used as if they were fundamental arithmetic types
 *     return i_elem == j_elem;
 *   }
 * };
 * }</pre>
 *
 * It is sometimes neccessary to customize the dispatched functor's
 * {@code operator()} for different types.  This can be done in several ways.
 *
 * The first method is to use explicit template specialization. This is useful
 * for specializing behavior for single types. For example, a functor that
 * prints {@code int32_t} or {@code double} when invoked with either of those types, else it
 * prints {@code unhandled type}:
 *
 * <pre>{@code
 * struct type_printer {
 *   template <typename ColumnType>
 *   void operator()() { std::cout << "unhandled type\n"; }
 * };
 *
 * // Due to a bug in g++, explicit member function specializations need to be
 * // defined outside of the class definition
 * template <>
 * void type_printer::operator()<int32_t>() { std::cout << "int32_t\n"; }
 *
 * template <>
 * void type_printer::operator()<double>() { std::cout << "double\n"; }
 * }</pre>
 *
 * A second method is to use SFINAE with {@code std::enable_if_t}. This is useful for
 * specializing for a set of types that share some property. For example, a
 * functor that prints {@code integral} or {@code floating point} for integral or floating
 * point types:
 * 
 * <pre>{@code
 * struct integral_or_floating_point {
 *   template <typename ColumnType,
 *             std::enable_if_t<not std::is_integral<ColumnType>::value and
 *                              not std::is_floating_point<ColumnType>::value>* = nullptr>
 *   void operator()() { std::cout << "neither integral nor floating point\n"; }
 * 
 *   template <typename ColumnType,
 *             std::enable_if_t<std::is_integral<ColumnType>::value>* = nullptr>
 *   void operator()() { std::cout << "integral\n"; }
 * 
 *   template < typename ColumnType,
 *              std::enable_if_t<std::is_floating_point<ColumnType>::value>* = nullptr>
 *   void operator()() { std::cout << "floating point\n"; }
 * };
 * }</pre>
 * 
 * For more info on SFINAE and {@code std::enable_if}, see 
 * https://eli.thegreenplace.net/2014/sfinae-and-enable_if/ 
 *
 * The return type for all template instantiations of the functor's "operator()"
 * lambda must be the same, else there will be a compiler error as you would be
 * trying to return different types from the same function.
 *
 * NOTE: It is undefined behavior if an unsupported or invalid {@code gdf_dtype} is
 * supplied.
 *
 * @param dtype The gdf_dtype enum that determines which type will be dispatched
 * @param f The functor with a templated "operator()" that will be invoked with
 * the dispatched type
 * @param args A parameter-pack (i.e., arbitrary number of arguments) that will
 * be perfectly-forwarded as the arguments of the functor's "operator()".
 *
 * @return Whatever is returned by the functor's "operator()".
 *
 */
/* ----------------------------------------------------------------------------*/


// This pragma disables a compiler warning that complains about the valid usage
// of calling a __host__ functor from this function which is __host__ __device__
// #pragma hd_warning_disable
// #pragma nv_exec_check_disable

/**---------------------------------------------------------------------------*
 * \brief Maps a C++ type to it's corresponding gdf_dtype.
 *
 * When explicitly passed a template argument of a given type, returns the
 * appropriate {@code gdf_dtype} for the specified C++ type.
 *
 * For example:
 * <pre>{@code
 * return gdf_dtype_of<int32_t>();        // Returns GDF_INT32
 * return gdf_dtype_of<cudf::category>(); // Returns GDF_CATEGORY
 * }</pre>
 *
 * \tparam T The type to map to a {@code gdf_dtype}
 *---------------------------------------------------------------------------**/

@Namespace("cudf") public static native @Cast("const gdf_dtype") @Name("gdf_dtype_of<int8_t>") int gdf_dtype_of<int8_t>();

@Namespace("cudf") public static native @Cast("const gdf_dtype") @Name("gdf_dtype_of<int16_t>") int gdf_dtype_of<int16_t>();

@Namespace("cudf") public static native @Cast("const gdf_dtype") @Name("gdf_dtype_of<int32_t>") int gdf_dtype_of<int32_t>();

@Namespace("cudf") public static native @Cast("const gdf_dtype") @Name("gdf_dtype_of<int64_t>") int gdf_dtype_of<int64_t>();

@Namespace("cudf") public static native @Cast("const gdf_dtype") @Name("gdf_dtype_of<float>") int gdf_dtype_of<float>();

@Namespace("cudf") public static native @Cast("const gdf_dtype") @Name("gdf_dtype_of<double>") int gdf_dtype_of<double>();

@Namespace("cudf") public static native @Cast("const gdf_dtype") @Name("gdf_dtype_of<cudf::bool8>") int gdf_dtype_of<cudf::bool8>();

@Namespace("cudf") public static native @Cast("const gdf_dtype") @Name("gdf_dtype_of<cudf::date32>") int gdf_dtype_of<cudf::date32>();

@Namespace("cudf") public static native @Cast("const gdf_dtype") @Name("gdf_dtype_of<cudf::date64>") int gdf_dtype_of<cudf::date64>();

@Namespace("cudf") public static native @Cast("const gdf_dtype") @Name("gdf_dtype_of<cudf::timestamp>") int gdf_dtype_of<cudf::timestamp>();

@Namespace("cudf") public static native @Cast("const gdf_dtype") @Name("gdf_dtype_of<cudf::category>") int gdf_dtype_of<cudf::category>();

@Namespace("cudf") public static native @Cast("const gdf_dtype") @Name("gdf_dtype_of<cudf::nvstring_category>") int gdf_dtype_of<cudf::nvstring_category>();

@Namespace("cudf") public static native @Cast("const gdf_dtype") @Name("gdf_dtype_of<NVStrings>") int gdf_dtype_of<NVStrings>();

  // namespace cudf

// #endif


// Parsed from <cudf/utilities/type_dispatcher.hpp>

/*
 * Copyright (c) 2019, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

// #pragma once

// #include <cudf/types.hpp>
// #include <cudf/utilities/error.hpp>
// #include <cudf/detail/utilities/release_assert.ch>
// #include <cudf/wrappers/bool.hpp>
// #include <cudf/wrappers/timestamps.hpp>
// #include <string>

/**---------------------------------------------------------------------------*
 * \file type_dispatcher.hpp
 * \brief Defines the mapping between {@code cudf::type_id} runtime type information
 * and concrete C++ types.
 *---------------------------------------------------------------------------**/
// Targeting ../type_to_name.java


/**---------------------------------------------------------------------------*
 * \brief Maps a {@code cudf::type_id} to it's corresponding concrete C++ type
 *
 * Example:
 * <pre>{@code
 * static_assert(std::is_same<int32_t, id_to_type<INT32>);
 * }</pre>
 * \tparam t The {@code cudf::type_id} to map
 *---------------------------------------------------------------------------**/

/**---------------------------------------------------------------------------*
 * \brief Macro used to define a mapping between a concrete C++ type and a
 *{@code cudf::type_id} enum.
 <p>
 * @param Type The concrete C++ type
 * @param Id The {@code cudf::type_id} enum
 *---------------------------------------------------------------------------**/
// #ifndef CUDF_TYPE_MAPPING
// #define CUDF_TYPE_MAPPING(Type, Id)
//   template <>
//   constexpr inline type_id type_to_id<Type>() {
//     return Id;
//   }
//   template <>
//   inline std::string
//   type_to_name::operator()<Type>() {
//     return CUDF_STRINGIFY(Type);
//   }
//   template <>
//   struct id_to_type_impl<Id> {
//     using type = Type;
//   }
// #endif

/**---------------------------------------------------------------------------*
 * \brief Defines all of the mappings between C++ types and their corresponding
 * {@code cudf::type_id} values.
 *---------------------------------------------------------------------------**/
@Namespace("cudf::experimental") public static native @Cast("const cudf::type_id") @Name("type_to_id<cudf::experimental::bool8>") int type_to_id<cudf::experimental::bool8>();
  
// Targeting ../id_to_type_impl.java


@Namespace("cudf::experimental") public static native @Cast("const cudf::type_id") @Name("type_to_id<int8_t>") int type_to_id<int8_t>();
  
@Namespace("cudf::experimental") public static native @Cast("const cudf::type_id") @Name("type_to_id<int16_t>") int type_to_id<int16_t>();
  
@Namespace("cudf::experimental") public static native @Cast("const cudf::type_id") @Name("type_to_id<int32_t>") int type_to_id<int32_t>();
  
@Namespace("cudf::experimental") public static native @Cast("const cudf::type_id") @Name("type_to_id<int64_t>") int type_to_id<int64_t>();
  
@Namespace("cudf::experimental") public static native @Cast("const cudf::type_id") @Name("type_to_id<float>") int type_to_id<float>();
  
@Namespace("cudf::experimental") public static native @Cast("const cudf::type_id") @Name("type_to_id<double>") int type_to_id<double>();
  
@Namespace("cudf::experimental") public static native @Cast("const cudf::type_id") @Name("type_to_id<cudf::string_view>") int type_to_id<cudf::string_view>();
  
@Namespace("cudf::experimental") public static native @Cast("const cudf::type_id") @Name("type_to_id<cudf::timestamp_D>") int type_to_id<cudf::timestamp_D>();
  
@Namespace("cudf::experimental") public static native @Cast("const cudf::type_id") @Name("type_to_id<cudf::timestamp_s>") int type_to_id<cudf::timestamp_s>();
  
@Namespace("cudf::experimental") public static native @Cast("const cudf::type_id") @Name("type_to_id<cudf::timestamp_ms>") int type_to_id<cudf::timestamp_ms>();
  
@Namespace("cudf::experimental") public static native @Cast("const cudf::type_id") @Name("type_to_id<cudf::timestamp_us>") int type_to_id<cudf::timestamp_us>();
  
@Namespace("cudf::experimental") public static native @Cast("const cudf::type_id") @Name("type_to_id<cudf::timestamp_ns>") int type_to_id<cudf::timestamp_ns>();
  

// #ifndef MAP_NUMERIC_SCALAR
// #define MAP_NUMERIC_SCALAR(Type)
// template <>
// struct type_to_scalar_type_impl<Type> {
//   using ScalarType = cudf::numeric_scalar<Type>;
//   using ScalarDeviceType = cudf::numeric_scalar_device_view<Type>;
// };
// Targeting ../type_to_scalar_type_impl.java



// #ifndef MAP_TIMESTAMP_SCALAR
// #define MAP_TIMESTAMP_SCALAR(Type)
// template <>
// struct type_to_scalar_type_impl<Type> {
//   using ScalarType = cudf::timestamp_scalar<Type>;
//   using ScalarDeviceType = cudf::timestamp_scalar_device_view<Type>;
// };
// #endif

/**
 * \brief Maps a C++ type to the scalar type required to hold its value
 * 
 * \tparam T The concrete C++ type to map
 */

/**---------------------------------------------------------------------------*
 * \brief Invokes an {@code operator()} template with the type instantiation based on
 * the specified {@code cudf::data_type}'s {@code id()}.
 *
 * Example usage with a functor that returns the size of the dispatched type:
 *
 * <pre>{@code
 * struct size_of_functor{
 *  template <typename T>
 *  int operator()(){
 *    return sizeof(T);
 *  }
 * };
 * cudf::data_type t{INT32};
 * cudf::type_dispatcher(t, size_of_functor{});  // returns 4
 * }</pre>
 *
 * The {@code type_dispatcher} uses {@code cudf::type_to_id<t>} to provide a default mapping
 * of {@code cudf::type_id}s to dispatched C++ types. However, this mapping may be
 * customized by explicitly specifying a user-defined trait struct for the
 * {@code IdTypeMap}. For example, to always dispatch {@code int32_t}
 *
 * <pre>{@code
 * template<cudf::type_id t> struct always_int{ using type = int32_t; }
 *
 * // This will always invoke `operator()<int32_t>`
 * cudf::type_dispatcher<always_int>(data_type, f);
 * }</pre>
 *
 * It is sometimes necessary to customize the dispatched functor's
 * {@code operator()} for different types.  This can be done in several ways.
 *
 * The first method is to use explicit template specialization. This is useful
 * for specializing behavior for single types. For example, a functor that
 * prints {@code int32_t} or {@code double} when invoked with either of those types, else it
 * prints {@code unhandled type}:
 *
 * <pre>{@code
 * struct type_printer {
 *   template <typename ColumnType>
 *   void operator()() { std::cout << "unhandled type\n"; }
 * };
 *
 * // Due to a bug in g++, explicit member function specializations need to be
 * // defined outside of the class definition
 * template <>
 * void type_printer::operator()<int32_t>() { std::cout << "int32_t\n"; }
 *
 * template <>
 * void type_printer::operator()<double>() { std::cout << "double\n"; }
 * }</pre>
 *
 * A second method is to use SFINAE with {@code std::enable_if_t}. This is useful for
 * specializing for a set of types that share some property. For example, a
 * functor that prints {@code integral} or {@code floating point} for integral or floating
 * point types:
 *
 * <pre>{@code
 * struct integral_or_floating_point {
 *   template <typename ColumnType,
 *             std::enable_if_t<not std::is_integral<ColumnType>::value and
 *                              not std::is_floating_point<ColumnType>::value>*
 *= nullptr> void operator()() { std::cout << "neither integral nor floating
 *point\n"; }
 *
 *   template <typename ColumnType,
 *             std::enable_if_t<std::is_integral<ColumnType>::value>* = nullptr>
 *   void operator()() { std::cout << "integral\n"; }
 *
 *   template < typename ColumnType,
 *              std::enable_if_t<std::is_floating_point<ColumnType>::value>* =
 *nullptr> void operator()() { std::cout << "floating point\n"; }
 * };
 * }</pre>
 *
 * For more info on SFINAE and {@code std::enable_if}, see
 * https://eli.thegreenplace.net/2014/sfinae-and-enable_if/
 *
 * The return type for all template instantiations of the functor's "operator()"
 * lambda must be the same, else there will be a compiler error as you would be
 * trying to return different types from the same function.
 *
 * \tparam id_to_type_impl Maps a {@code cudf::type_id} its dispatched C++ type
 * \tparam Functor The callable object's type
 * \tparam Ts Variadic parameter pack type
 * @param dtype The {@code cudf::data_type} whose {@code id()} determines which template
 * instantiation is invoked
 * @param f The callable whose {@code operator()} template is invoked
 * @param args Parameter pack of arguments forwarded to the {@code operator()}
 * invocation
 * @return Whatever is returned by the callable's {@code operator()}
 *---------------------------------------------------------------------------**/
// This pragma disables a compiler warning that complains about the valid usage
// of calling a __host__ functor from this function which is __host__ __device__
// #pragma nv_exec_check_disable

  // namespace experimental
  // namespace cudf


}
